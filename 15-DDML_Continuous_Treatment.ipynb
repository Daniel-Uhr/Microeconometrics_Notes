{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Debiased Machine Learning for Difference in Differences\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conte√∫do\n",
    "\n",
    "* Double Debiased Machine Learning for Difference in Differences - Chang (2020)\n",
    "  * Artigo seminal que aplica o framework DML (Double Machine Learning) ao desenho cl√°ssico de DiD com tratamento bin√°rio em um cen√°rio 2x2.\n",
    "  * https://python.plainenglish.io/double-debiased-ml-for-did-1-fd08bebcf033\n",
    "\n",
    "* Difference-in-Differences with Continuous Treatment - Zhang, L. (2025)\n",
    "  * Extens√£o do DiD para tratamento cont√≠nuo (dose/quantidade) em 2x2, ainda sob o framework DML.\n",
    "  * DiD 2x2 cont√≠nuo\n",
    "\n",
    "* Dynamic DML\n",
    "  * O DynamicDML foi feito para tratamento sequencial geral; em staggered adoption (uma vez tratado, sempre tratado) ele pode funcionar, mas h√° armadilhas de identifica√ß√£o e de positividade.\n",
    "  * O alvo padr√£o √© um efeito contempor√¢neo $ùúÉ_0(X_0)$ do tratamento em $t$ sobre $Y_t$ condicionado ao hist√≥rico (via $W_t$, $T_{t‚àí1}$, etc.).\n",
    "  * Quer um efeito contempor√¢neo m√©dio condicional ao hist√≥rico (policy-style CATE/ATE) e h√° varia√ß√£o de switchers? ‚Üí DynamicDML pode ser adequado (idealmente com $ŒîT_t$).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Refer√™ncias\n",
    "\n",
    "https://python.plainenglish.io/double-debiased-ml-for-did-1-fd08bebcf033\n",
    "\n",
    "\n",
    "**Principais:**\n",
    "* Chang, Neng-Chieh. Double/debiased machine learning for difference-in-differences models. The Econometrics Journal, Volume 23, Issue 2, May 2020, Pages 177‚Äì191, https://doi.org/10.1093/ectj/utaa001\n",
    "* Zhang, L. (2025). Continuous difference-in-differences with double/debiased machine learning. https://arxiv.org/pdf/2408.10509\n",
    "* https://docs.doubleml.org/stable/examples/py_double_ml_did.html\n",
    "* Neng-Chieh Chang. (2023). Double Debiased Machine Learning for Difference in Differences. [arXiv:2301.11395v2](https://doi.org/10.48550/arXiv.2301.11395)\n",
    "* Colangelo and Lee (2023). Double Debiased Machine Learning Nonparametric Inference with Continuous Treatments. [arXiv:2004.03036v8 ](https://doi.org/10.48550/arXiv.2004.03036) \n",
    "* GitHub: https://github.com/KColangelo/Double-ML-Continuous-Treatment\n",
    "\n",
    "\n",
    "**Complementares:**\n",
    "* Microsoft EconML: https://econml.azurewebsites.net/\n",
    "* UBER CausalML: https://causalml.readthedocs.io/en/latest/\n",
    "* https://docs.doubleml.org/stable/index.html\n",
    "* https://github.com/MasaAsami/ReproducingDMLDiD/blob/main/notebook/Reproduction_of_DMLDiD_RO_for_NEW_SIMDATA.ipynb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Observa√ß√µes:** O material apresentado aqui √© uma adapta√ß√£o do material de aula do Prof. Daniel de Abreu Pereira Uhr, e n√£o deve ser utilizado para fins comerciais. O material √© disponibilizado para fins educacionais e de pesquisa, e n√£o deve ser reproduzido sem a devida autoriza√ß√£o do autor. Este material pode conter erros e imprecis√µes. O autor n√£o se responsabiliza por quaisquer danos ou preju√≠zos decorrentes do uso deste material. O uso deste material √© de responsabilidade exclusiva do usu√°rio. Caso voc√™ encontre erros ou imprecis√µes neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer *feedback* ou sugest√£o de melhoria.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "group",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "period",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "T",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "w1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "w2",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "x0_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x0_2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b88acfa4-82ed-4d84-87ad-7d27ddfa2574",
       "rows": [
        [
         "0",
         "0",
         "0",
         "0.7322018359208784",
         "0.0",
         "-0.748827465569452",
         "1",
         "-1.0856306033005612",
         "0.9973454465835858"
        ],
        [
         "1",
         "0",
         "1",
         "-0.3337070012861442",
         "0.0",
         "0.567594726027765",
         "1",
         "-1.0856306033005612",
         "0.9973454465835858"
        ],
        [
         "2",
         "0",
         "2",
         "-0.41140984827627775",
         "0.0",
         "0.7181505425518439",
         "0",
         "-1.0856306033005612",
         "0.9973454465835858"
        ],
        [
         "3",
         "0",
         "3",
         "-2.990265127889788",
         "1.0",
         "-0.9993807492735187",
         "1",
         "-1.0856306033005612",
         "0.9973454465835858"
        ],
        [
         "4",
         "0",
         "4",
         "-0.8341171151360032",
         "1.0",
         "0.47489832293698464",
         "1",
         "-1.0856306033005612",
         "0.9973454465835858"
        ],
        [
         "5",
         "1",
         "0",
         "0.8072067066537221",
         "0.0",
         "-1.86849981325055",
         "0",
         "0.28297849805199204",
         "-1.506294713918092"
        ],
        [
         "6",
         "1",
         "1",
         "1.11165947674399",
         "1.0",
         "-0.20265890716555396",
         "1",
         "0.28297849805199204",
         "-1.506294713918092"
        ],
        [
         "7",
         "1",
         "2",
         "0.062405947725863276",
         "0.0",
         "-1.1342480262783414",
         "0",
         "0.28297849805199204",
         "-1.506294713918092"
        ],
        [
         "8",
         "1",
         "3",
         "-0.22512612477140764",
         "-0.0",
         "-0.8076993401971515",
         "0",
         "0.28297849805199204",
         "-1.506294713918092"
        ],
        [
         "9",
         "1",
         "4",
         "-0.19332984480672455",
         "0.0",
         "-1.2760773521443496",
         "0",
         "0.28297849805199204",
         "-1.506294713918092"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>period</th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>x0_1</th>\n",
       "      <th>x0_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.748827</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>0.997345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.333707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567595</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>0.997345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.411410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718151</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>0.997345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.990265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999381</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>0.997345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.834117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.474898</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.085631</td>\n",
       "      <td>0.997345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.807207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.868500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282978</td>\n",
       "      <td>-1.506295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.111659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.202659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282978</td>\n",
       "      <td>-1.506295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.134248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282978</td>\n",
       "      <td>-1.506295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.225126</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.807699</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282978</td>\n",
       "      <td>-1.506295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.193330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.276077</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282978</td>\n",
       "      <td>-1.506295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  period         Y    T        w1  w2      x0_1      x0_2\n",
       "0      0       0  0.732202  0.0 -0.748827   1 -1.085631  0.997345\n",
       "1      0       1 -0.333707  0.0  0.567595   1 -1.085631  0.997345\n",
       "2      0       2 -0.411410  0.0  0.718151   0 -1.085631  0.997345\n",
       "3      0       3 -2.990265  1.0 -0.999381   1 -1.085631  0.997345\n",
       "4      0       4 -0.834117  1.0  0.474898   1 -1.085631  0.997345\n",
       "5      1       0  0.807207  0.0 -1.868500   0  0.282978 -1.506295\n",
       "6      1       1  1.111659  1.0 -0.202659   1  0.282978 -1.506295\n",
       "7      1       2  0.062406  0.0 -1.134248   0  0.282978 -1.506295\n",
       "8      1       3 -0.225126 -0.0 -0.807699   0  0.282978 -1.506295\n",
       "9      1       4 -0.193330  0.0 -1.276077   0  0.282978 -1.506295"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fixando seed para reprodutibilidade\n",
    "np.random.seed(123)\n",
    "\n",
    "# Par√¢metros da simula√ß√£o\n",
    "n_individuals = 500   # n√∫mero de indiv√≠duos\n",
    "n_periods = 5         # n√∫mero de per√≠odos por indiv√≠duo\n",
    "\n",
    "# Cria√ß√£o de IDs e per√≠odos\n",
    "ids = np.repeat(np.arange(n_individuals), n_periods)\n",
    "periods = np.tile(np.arange(n_periods), n_individuals)\n",
    "\n",
    "# Caracter√≠sticas fixas dos indiv√≠duos (heterogeneidade)\n",
    "X0 = np.random.normal(0, 1, size=(n_individuals, 2))\n",
    "X0 = pd.DataFrame(np.repeat(X0, n_periods, axis=0), columns=[\"x0_1\", \"x0_2\"])\n",
    "\n",
    "# Vari√°veis de estado que evoluem no tempo (W)\n",
    "W = pd.DataFrame({\n",
    "    \"w1\": np.random.normal(0, 1, size=n_individuals * n_periods),\n",
    "    \"w2\": np.random.binomial(1, 0.5, size=n_individuals * n_periods)\n",
    "})\n",
    "\n",
    "# Tratamento din√¢mico T_t: depende do tempo e das vari√°veis de estado\n",
    "T = (0.5 * W[\"w1\"] + 0.3 * W[\"w2\"] + np.random.normal(0, 1, size=len(W))).round().clip(0, 1)\n",
    "\n",
    "# Outcome Y_t: efeito heterog√™neo + controles + ru√≠do\n",
    "theta_0 = 2 * X0[\"x0_1\"] - X0[\"x0_2\"]\n",
    "Y = theta_0 * T + 0.5 * W[\"w1\"] + 0.2 * W[\"w2\"] + np.random.normal(0, 1, size=len(T))\n",
    "\n",
    "# Montando o dataframe final\n",
    "df_dyn = pd.DataFrame({\n",
    "    \"group\": ids,\n",
    "    \"period\": periods,\n",
    "    \"Y\": Y,\n",
    "    \"T\": T,\n",
    "    \"w1\": W[\"w1\"],\n",
    "    \"w2\": W[\"w2\"],\n",
    "    \"x0_1\": X0[\"x0_1\"],\n",
    "    \"x0_2\": X0[\"x0_2\"]\n",
    "})\n",
    "\n",
    "df_dyn.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.panel.dml import DynamicDML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dynamic_dml_est = DynamicDML(\n",
    "    model_y=RandomForestRegressor(),\n",
    "    model_t=RandomForestClassifier(),\n",
    "    discrete_treatment=True,\n",
    "    cv=3,  # N√∫mero de folds para cross-fitting\n",
    "    random_state=123\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<econml.panel.dml._dml.DynamicDML at 0x1e1fb008750>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_dml_est = DynamicDML(\n",
    "    model_y=RandomForestRegressor(),\n",
    "    model_t=RandomForestClassifier(),\n",
    "    discrete_treatment=True,\n",
    "    cv=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "dynamic_dml_est.fit(Y_dyn, T_dyn, X=X_dyn, W=W_dyn, groups=groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Uncertainty of Mean Point Estimate              \n",
      "===============================================================\n",
      "mean_point stderr_mean zstat pvalue ci_mean_lower ci_mean_upper\n",
      "---------------------------------------------------------------\n",
      "     0.111       0.262 0.425  0.671        -0.403         0.625\n",
      "      Distribution of Point Estimate     \n",
      "=========================================\n",
      "std_point pct_point_lower pct_point_upper\n",
      "-----------------------------------------\n",
      "    2.308          -4.466           4.414\n",
      "     Total Variance of Point Estimate     \n",
      "==========================================\n",
      "stderr_point ci_point_lower ci_point_upper\n",
      "------------------------------------------\n",
      "       2.323         -4.502          4.579\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n"
     ]
    }
   ],
   "source": [
    "ate_inf = dynamic_dml_est.ate_inference(X_dyn)\n",
    "print(ate_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DynamicDML.__init__() got an unexpected keyword argument 'model_final'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m groups \u001b[38;5;241m=\u001b[39m df_dyn[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Estimador\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m dynamic_dml_est \u001b[38;5;241m=\u001b[39m \u001b[43mDynamicDML\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscrete_treatment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Ajustando o modelo\u001b[39;00m\n\u001b[0;32m     24\u001b[0m dynamic_dml_est\u001b[38;5;241m.\u001b[39mfit(Y_dyn, T_dyn, X\u001b[38;5;241m=\u001b[39mX_dyn, W\u001b[38;5;241m=\u001b[39mW_dyn, groups\u001b[38;5;241m=\u001b[39mgroups)\n",
      "\u001b[1;31mTypeError\u001b[0m: DynamicDML.__init__() got an unexpected keyword argument 'model_final'"
     ]
    }
   ],
   "source": [
    "from econml.panel.dml import DynamicDML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Separando vari√°veis\n",
    "Y_dyn = df_dyn[\"Y\"].values\n",
    "T_dyn = df_dyn[\"T\"].values.reshape(-1, 1)\n",
    "X_dyn = df_dyn[[\"x0_1\", \"x0_2\"]].values\n",
    "W_dyn = df_dyn[[\"w1\", \"w2\"]].values\n",
    "groups = df_dyn[\"group\"].values\n",
    "\n",
    "# Estimador\n",
    "dynamic_dml_est = DynamicDML(\n",
    "    model_y=RandomForestRegressor(),\n",
    "    model_t=RandomForestClassifier(),\n",
    "    model_final=RandomForestRegressor(),\n",
    "    discrete_treatment=True,\n",
    "    cv=3,\n",
    "    n_splits=3,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Ajustando o modelo\n",
    "dynamic_dml_est.fit(Y_dyn, T_dyn, X=X_dyn, W=W_dyn, groups=groups)\n",
    "\n",
    "# Estimando o efeito causal m√©dio para todos os indiv√≠duos\n",
    "treatment_effects = dynamic_dml_est.effect(X_dyn)\n",
    "\n",
    "# Resumo das estimativas\n",
    "mean_effect = np.mean(treatment_effects)\n",
    "std_effect = np.std(treatment_effects)\n",
    "\n",
    "mean_effect, std_effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Debiased Machine Learning for Difference in Differences - Chang (2020)\n",
    "\n",
    "* average treatment effect on the treated (ATT) under the conditional parallel trend assumption.\n",
    "* based on Chang (2020), Sant‚ÄôAnna and Zhao (2020) and Zimmert et al. (2018).\n",
    "\n",
    "Nesse exmeplo a vari√°vel de tratamento e a vari√°vel de tempo $t\\in\\{0,1\\}$ ser√£o bin√°rias.\n",
    "Seja $D_i\\in\\{0,1\\}$ o status de tratamento da unidade $i$ no tempo $t=1$ (no tempo $t=0$ todas as unidades n√£o s√£o tratadas) e seja $Y_{it}$ o resultado de interesse da unidade $i$ no tempo $t$.\n",
    "Usando a nota√ß√£o de resultado potencial, podemos escrever $Y_{it}(d)$ para o resultado potencial da unidade $i$ no tempo $t$ e status de tratamento $d$. Al√©m disso, seja $X_i$ um vetor de covari√°veis pr√©-tratamento.\n",
    "Nessa configura√ß√£o de diferen√ßa em diferen√ßas, o efeito m√©dio do tratamento sobre os tratados (ATTE) √© definido como (Abadie, 2005):\n",
    "\n",
    "$$\\theta = \\mathbb{E}[Y_{i1}(1)- Y_{i1}(0)|D_i=1]$$\n",
    "\n",
    "√© identificado quando dados em painel est√£o dispon√≠veis ou sob suposi√ß√µes de estacionaridade para se√ß√µes transversais repetidas. Al√©m disso, as suposi√ß√µes b√°sicas s√£o\n",
    "\n",
    " - **Parallel Trends:** We have $\\mathbb{E}[Y_{i1}(0) - Y_{i0}(0)|X_i, D_i=1] = \\mathbb{E}[Y_{i1}(0) - Y_{i0}(0)|X_i, D_i=0]\\quad a.s.$\n",
    "\n",
    "- **Overlap:** For some $\\epsilon > 0$, $P(D_i=1) > \\epsilon$ and $P(D_i=1|X_i) \\le 1-\\epsilon$ a.s.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/bacon_example.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introdu√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de aplica√ß√£o do DDML-DiD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from differences import ATTgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/bacon_example.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtragem dos dados\n",
    "# Vamos criar identificadores estaduais\n",
    "data['id'] = data['stfips'].astype('category').cat.codes + 1\n",
    "\n",
    "# Outcome (Suicide Mortality)\n",
    "data['Y'] = data['asmrs']\n",
    "# Treatment\n",
    "data['D'] = data['post']\n",
    "# Covari√°veis - pcinc asmrh cases\n",
    "data['X1'] = data['pcinc']\n",
    "data['X2'] = data['asmrh']\n",
    "data['X3'] = data['cases']\n",
    "\n",
    "# pcinc + asmrh + cases\n",
    "# Vamos criar a vari√°vel de grupo G\n",
    "data['G']=data['_nfd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1188.000000\n",
       "mean        6.416667\n",
       "std        10.162403\n",
       "min       -21.000000\n",
       "25%        -2.000000\n",
       "50%         6.000000\n",
       "75%        15.000000\n",
       "max        27.000000\n",
       "Name: timeToTreat, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar uma vari√°vel de tempo at√© o ano do in√≠cio do tratamento (Tempo em rela√ß√£o ao in√≠cio do evento)\n",
    "data['timeToTreat'] = data['year'] - data['_nfd']\n",
    "data['timeToTreat'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O pacote precisa entender a estrutura de painel dos dados. Precisamos ajustar a vari√°vel year para int (inteiro)\n",
    "# Criando clones\n",
    "data['year1'] = data['year']\n",
    "data['id1'] = data['id']\n",
    "data['year1'] = data['year'].astype(int)\n",
    "\n",
    "# Definir os indices (estrutura de painel)\n",
    "data.set_index(['id1', 'year1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_gt = ATTgt(data=data, cohort_name=\"G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 384/384 [00:01<00:00, 198.30it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('cohort', 'base_period', 'time')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "('ATTgtResult', '', 'ATT')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'analytic', 'std_error')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'pointwise conf. band', 'lower')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'pointwise conf. band', 'upper')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'pointwise conf. band', 'zero_not_in_cband')",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4903796a-6de8-442c-97b6-5497d8d4d2a3",
       "rows": [
        [
         "(1969, 1964, 1965)",
         "-6.070418260675985",
         "8.259573255792276",
         "-22.258884369699082",
         "10.11804784834711",
         ""
        ],
        [
         "(1969, 1965, 1966)",
         "6.174148981883685",
         "9.094903014276941",
         "-11.651533368983895",
         "23.999831332751267",
         ""
        ],
        [
         "(1969, 1966, 1967)",
         "5.848175155867885",
         "3.7527048638084675",
         "-1.5069912218049994",
         "13.203341533540769",
         ""
        ],
        [
         "(1969, 1967, 1968)",
         "2.0360933880843257",
         "2.414728844585467",
         "-2.696688179733207",
         "6.768874955901858",
         ""
        ],
        [
         "(1969, 1968, 1969)",
         "1.55816902520531",
         "4.865841323532823",
         "-7.978704723405733",
         "11.095042773816353",
         ""
        ],
        [
         "(1969, 1968, 1970)",
         "-7.003285383322333",
         "7.080746002092912",
         "-20.881292531100414",
         "6.874721764455749",
         ""
        ],
        [
         "(1969, 1968, 1971)",
         "-12.439136632204773",
         "4.894401542409646",
         "-22.03198738120497",
         "-2.846285883204576",
         "*"
        ],
        [
         "(1969, 1968, 1972)",
         "-0.8087042230658548",
         "3.2482540773902637",
         "-7.175165227386152",
         "5.557756781254444",
         ""
        ],
        [
         "(1969, 1968, 1973)",
         "-1.5961036146833956",
         "6.894674119853092",
         "-15.109416574735851",
         "11.917209345369061",
         ""
        ],
        [
         "(1969, 1968, 1974)",
         "-2.0411469118933603",
         "3.0619240693318077",
         "-8.042407811180027",
         "3.9601139873933064",
         ""
        ],
        [
         "(1969, 1968, 1975)",
         "-4.102214343998987",
         "4.314656812976039",
         "-12.558786303082396",
         "4.354357615084422",
         ""
        ],
        [
         "(1969, 1968, 1976)",
         "-11.127505850498396",
         "3.2742672348183195",
         "-17.544951706501855",
         "-4.710059994494938",
         "*"
        ],
        [
         "(1969, 1968, 1977)",
         "-9.20962965185684",
         "4.563052430809795",
         "-18.153048075811984",
         "-0.26621122790169593",
         "*"
        ],
        [
         "(1969, 1968, 1978)",
         "-10.28716284996105",
         "7.299317776804775",
         "-24.593562804211384",
         "4.019237104289285",
         ""
        ],
        [
         "(1969, 1968, 1979)",
         "-13.880738456442705",
         "4.883068312071858",
         "-23.45137648215234",
         "-4.310100430733071",
         "*"
        ],
        [
         "(1969, 1968, 1980)",
         "-14.678825144496635",
         "3.3496730715355434",
         "-21.24406372468996",
         "-8.11358656430331",
         "*"
        ],
        [
         "(1969, 1968, 1981)",
         "-11.377409821722154",
         "3.7405179976518745",
         "-18.708690380643706",
         "-4.046129262800601",
         "*"
        ],
        [
         "(1969, 1968, 1982)",
         "0.8911043407733911",
         "6.063525994713638",
         "-10.993188228187746",
         "12.775396909734527",
         ""
        ],
        [
         "(1969, 1968, 1983)",
         "4.260075409211732",
         "4.487357621723202",
         "-4.534983915117056",
         "13.05513473354052",
         ""
        ],
        [
         "(1969, 1968, 1984)",
         "-6.789453808553693",
         "6.000054885278056",
         "-18.549345288962286",
         "4.970437671854901",
         ""
        ],
        [
         "(1969, 1968, 1985)",
         "-1.9015999641480887",
         "4.372546290860435",
         "-10.47163321496874",
         "6.668433286672563",
         ""
        ],
        [
         "(1969, 1968, 1986)",
         "-7.85199254422487",
         "3.3412794163392125",
         "-14.400779862534739",
         "-1.3032052259150007",
         "*"
        ],
        [
         "(1969, 1968, 1987)",
         "-7.119829433707184",
         "4.780440454946615",
         "-16.48932055564082",
         "2.2496616882264524",
         ""
        ],
        [
         "(1969, 1968, 1988)",
         "-10.133022151983456",
         "4.145365225546841",
         "-18.257788696820022",
         "-2.0082556071468893",
         "*"
        ],
        [
         "(1969, 1968, 1989)",
         "-5.8267852288535895",
         "3.4346134140818667",
         "-12.558503821272204",
         "0.904933363565025",
         ""
        ],
        [
         "(1969, 1968, 1990)",
         "-6.346446292814774",
         "4.243979698142383",
         "-14.664493652293014",
         "1.9716010666634673",
         ""
        ],
        [
         "(1969, 1968, 1991)",
         "-12.409371946051335",
         "2.942100312779883",
         "-18.175782598003934",
         "-6.642961294098737",
         "*"
        ],
        [
         "(1969, 1968, 1992)",
         "-0.921934170649941",
         "3.654072889685421",
         "-8.083785431317569",
         "6.239917090017687",
         ""
        ],
        [
         "(1969, 1968, 1993)",
         "0.6731641052149167",
         "5.093682825632669",
         "-9.31027078169533",
         "10.656598992125165",
         ""
        ],
        [
         "(1969, 1968, 1994)",
         "-7.134763062969245",
         "3.3457139161987173",
         "-13.692241841293193",
         "-0.577284284645299",
         "*"
        ],
        [
         "(1969, 1968, 1995)",
         "-10.413197054329437",
         "5.545338410789461",
         "-21.28186062156336",
         "0.45546651290448636",
         ""
        ],
        [
         "(1969, 1968, 1996)",
         "-0.9189951488226209",
         "5.797415917158085",
         "-12.281721549851712",
         "10.44373125220647",
         ""
        ],
        [
         "(1970, 1964, 1965)",
         "-2.1744742433953514",
         "4.72124644851596",
         "-11.427947244624272",
         "7.078998757833569",
         ""
        ],
        [
         "(1970, 1965, 1966)",
         "-7.528813029181201",
         "13.309852987553958",
         "-33.6156455243098",
         "18.558019465947396",
         ""
        ],
        [
         "(1970, 1966, 1967)",
         "16.317986168862323",
         "12.633653355301083",
         "-8.443519400691411",
         "41.07949173841605",
         ""
        ],
        [
         "(1970, 1967, 1968)",
         "-9.385672543184755",
         "10.348662272971314",
         "-29.668677886376948",
         "10.897332800007435",
         ""
        ],
        [
         "(1970, 1968, 1969)",
         "8.7469879592918",
         "5.851838551834187",
         "-2.722404845646233",
         "20.216380764229832",
         ""
        ],
        [
         "(1970, 1969, 1970)",
         "6.668151823770863",
         "6.597978339069168",
         "-6.2636480915801105",
         "19.599951739121835",
         ""
        ],
        [
         "(1970, 1969, 1971)",
         "4.995081760590389",
         "5.242765560571366",
         "-5.280549917516436",
         "15.270713438697214",
         ""
        ],
        [
         "(1970, 1969, 1972)",
         "6.153507970686884",
         "6.630269717996199",
         "-6.841581884372206",
         "19.148597825745973",
         ""
        ],
        [
         "(1970, 1969, 1973)",
         "-14.286973777763862",
         "2.719740383032851",
         "-19.61756697580742",
         "-8.956380579720303",
         "*"
        ],
        [
         "(1970, 1969, 1974)",
         "-7.738830623613223",
         "2.5485274654648244",
         "-12.733852669535427",
         "-2.743808577691021",
         "*"
        ],
        [
         "(1970, 1969, 1975)",
         "-15.63735578167946",
         "5.535019489587193",
         "-26.48579463499763",
         "-4.788916928361289",
         "*"
        ],
        [
         "(1970, 1969, 1976)",
         "-17.455215391958884",
         "4.059235281516511",
         "-25.411170348505554",
         "-9.499260435412214",
         "*"
        ],
        [
         "(1970, 1969, 1977)",
         "-15.095862127488934",
         "5.728137442665788",
         "-26.322805213609247",
         "-3.8689190413686205",
         "*"
        ],
        [
         "(1970, 1969, 1978)",
         "-27.25379268454305",
         "13.510312609198731",
         "-53.73351881844993",
         "-0.7740665506361708",
         "*"
        ],
        [
         "(1970, 1969, 1979)",
         "-23.23953668478795",
         "10.421539802837788",
         "-43.665379361800674",
         "-2.8136940077752293",
         "*"
        ],
        [
         "(1970, 1969, 1980)",
         "-37.663247561170216",
         "12.240053654697235",
         "-61.65331189321466",
         "-13.673183229125772",
         "*"
        ],
        [
         "(1970, 1969, 1981)",
         "-26.30510062231009",
         "9.881653644726244",
         "-45.67278587367248",
         "-6.937415370947694",
         "*"
        ],
        [
         "(1970, 1969, 1982)",
         "-28.416616407296203",
         "13.233701155188994",
         "-54.35419405363274",
         "-2.479038760959668",
         "*"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 384
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">ATTgtResult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>base_period</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1969</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <td>-6.070418</td>\n",
       "      <td>8.259573</td>\n",
       "      <td>-22.258884</td>\n",
       "      <td>10.118048</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <td>6.174149</td>\n",
       "      <td>9.094903</td>\n",
       "      <td>-11.651533</td>\n",
       "      <td>23.999831</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <td>5.848175</td>\n",
       "      <td>3.752705</td>\n",
       "      <td>-1.506991</td>\n",
       "      <td>13.203342</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <td>2.036093</td>\n",
       "      <td>2.414729</td>\n",
       "      <td>-2.696688</td>\n",
       "      <td>6.768875</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <td>1.558169</td>\n",
       "      <td>4.865841</td>\n",
       "      <td>-7.978705</td>\n",
       "      <td>11.095043</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1985</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1984</th>\n",
       "      <th>1992</th>\n",
       "      <td>19.930538</td>\n",
       "      <td>4.051701</td>\n",
       "      <td>11.989349</td>\n",
       "      <td>27.871726</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>16.124177</td>\n",
       "      <td>2.333263</td>\n",
       "      <td>11.551066</td>\n",
       "      <td>20.697287</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>11.830665</td>\n",
       "      <td>2.834945</td>\n",
       "      <td>6.274274</td>\n",
       "      <td>17.387055</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>8.493860</td>\n",
       "      <td>2.493009</td>\n",
       "      <td>3.607652</td>\n",
       "      <td>13.380068</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>20.431504</td>\n",
       "      <td>4.480529</td>\n",
       "      <td>11.649828</td>\n",
       "      <td>29.213179</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ATTgtResult                                            \\\n",
       "                                     analytic pointwise conf. band              \n",
       "                                ATT std_error                lower      upper   \n",
       "cohort base_period time                                                         \n",
       "1969   1964        1965   -6.070418  8.259573           -22.258884  10.118048   \n",
       "       1965        1966    6.174149  9.094903           -11.651533  23.999831   \n",
       "       1966        1967    5.848175  3.752705            -1.506991  13.203342   \n",
       "       1967        1968    2.036093  2.414729            -2.696688   6.768875   \n",
       "       1968        1969    1.558169  4.865841            -7.978705  11.095043   \n",
       "...                             ...       ...                  ...        ...   \n",
       "1985   1984        1992   19.930538  4.051701            11.989349  27.871726   \n",
       "                   1993   16.124177  2.333263            11.551066  20.697287   \n",
       "                   1994   11.830665  2.834945             6.274274  17.387055   \n",
       "                   1995    8.493860  2.493009             3.607652  13.380068   \n",
       "                   1996   20.431504  4.480529            11.649828  29.213179   \n",
       "\n",
       "                                           \n",
       "                                           \n",
       "                        zero_not_in_cband  \n",
       "cohort base_period time                    \n",
       "1969   1964        1965                    \n",
       "       1965        1966                    \n",
       "       1966        1967                    \n",
       "       1967        1968                    \n",
       "       1968        1969                    \n",
       "...                                   ...  \n",
       "1985   1984        1992                 *  \n",
       "                   1993                 *  \n",
       "                   1994                 *  \n",
       "                   1995                 *  \n",
       "                   1996                 *  \n",
       "\n",
       "[384 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.fit(\"Y ~ pcinc\", est_method=\"dr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('SimpleAggregation', '', 'ATT')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'analytic', 'std_error')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'lower')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'upper')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'zero_not_in_cband')",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2f64046f-3099-4c56-9749-08ce6eaf7dcb",
       "rows": [
        [
         "0",
         "-5.983104148776847",
         "3.130347169858475",
         "-12.118471860806345",
         "0.15226356325265122",
         ""
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">SimpleAggregation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.983104</td>\n",
       "      <td>3.130347</td>\n",
       "      <td>-12.118472</td>\n",
       "      <td>0.152264</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SimpleAggregation                                                           \n",
       "                     analytic pointwise conf. band                            \n",
       "                ATT std_error                lower     upper zero_not_in_cband\n",
       "0         -5.983104  3.130347           -12.118472  0.152264                  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.aggregate(\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotina para Produzir Essa Tabela\n",
    "Loop em cada G (coorte tratado).\n",
    "\n",
    "Filtrar G e never-treated/not-yet-treated.\n",
    "\n",
    "Estimar DoubleMLDiD para aquele G ao longo dos tempos ‚â• G.\n",
    "\n",
    "Agrega√ß√£o para cada G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_att_gt(df, ml_g, ml_m):\n",
    "    results = []\n",
    "    cohorts = df['_nfd'].dropna().unique()\n",
    "    times = df['year'].unique()\n",
    "\n",
    "    for g in cohorts:\n",
    "        for t in times:\n",
    "            if t < g:\n",
    "                continue  # apenas per√≠odos p√≥s-tratamento\n",
    "\n",
    "            df_t = df[(df['year'] == t) & ((df['_nfd'] == g) | (df['_nfd'] > t) | (df['_nfd'].isna()))].copy()\n",
    "            \n",
    "            if df_t.empty or df_t['post'].sum() == 0 or (1 - df_t['post']).sum() == 0:\n",
    "                continue\n",
    "\n",
    "            X = df_t[['pcinc']].values\n",
    "            Y = df_t['asmrs'].values\n",
    "            D = df_t['post'].values\n",
    "\n",
    "            dml_data = DoubleMLData.from_arrays(x=X, y=Y, d=D)\n",
    "            dml_did = DoubleMLDID(dml_data,\n",
    "                                  ml_g=ml_g,\n",
    "                                  ml_m=ml_m,\n",
    "                                  score='observational',\n",
    "                                  in_sample_normalization=True,\n",
    "                                  n_folds=5)\n",
    "            dml_did.fit()\n",
    "            summary = dml_did.summary\n",
    "\n",
    "            att = summary['coef'].values[0]\n",
    "            stderr = summary['std err'].values[0]\n",
    "            ci_lower = summary['2.5 %'].values[0]\n",
    "            ci_upper = summary['97.5 %'].values[0]\n",
    "\n",
    "            # Conta quantos tratados existem nesse (G,t)\n",
    "            n_treated = df_t['post'].sum()\n",
    "\n",
    "            results.append({'G': g, 't': t, 'ATT': att, 'StdErr': stderr,\n",
    "                            'CI Lower': ci_lower, 'CI Upper': ci_upper,\n",
    "                            'n_treated': n_treated})\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_att_gt_weighted(results_df):\n",
    "    weights = results_df['n_treated']\n",
    "    weighted_att = np.average(results_df['ATT'], weights=weights)\n",
    "    weighted_var = np.average(results_df['StdErr']**2, weights=weights)\n",
    "    weighted_se = np.sqrt(weighted_var / len(results_df))\n",
    "\n",
    "    ci_lower = weighted_att - 1.96 * weighted_se\n",
    "    ci_upper = weighted_att + 1.96 * weighted_se\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        'ATT Weighted Mean': [weighted_att],\n",
    "        'StdErr Mean': [weighted_se],\n",
    "        'CI Lower': [ci_lower],\n",
    "        'CI Upper': [ci_upper]\n",
    "    })\n",
    "\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          G       t        ATT    StdErr   CI Lower   CI Upper  n_treated\n",
      "0    1971.0  1971.0  -4.221526  5.842524 -15.672663   7.229610       15.0\n",
      "1    1971.0  1972.0  -6.282070  5.451026 -16.965885   4.401744       15.0\n",
      "2    1971.0  1973.0  10.896126  6.422436  -1.691617  23.483870       15.0\n",
      "3    1971.0  1974.0   9.245664  6.057875  -2.627552  21.118881       15.0\n",
      "4    1971.0  1975.0  14.538667  6.652929   1.499167  27.578168       15.0\n",
      "..      ...     ...        ...       ...        ...        ...        ...\n",
      "253  1985.0  1992.0  -6.892958  9.499466 -25.511570  11.725654        9.0\n",
      "254  1985.0  1993.0  10.149335  8.131817  -5.788733  26.087403        9.0\n",
      "255  1985.0  1994.0   5.064727  6.063285  -6.819093  16.948547        9.0\n",
      "256  1985.0  1995.0  13.008206  7.559949  -1.809021  27.825434        9.0\n",
      "257  1985.0  1996.0   4.121333  3.797415  -3.321463  11.564129        9.0\n",
      "\n",
      "[258 rows x 7 columns]\n",
      "   ATT Weighted Mean  StdErr Mean  CI Lower  CI Upper\n",
      "0           8.231945     0.555556  7.143055  9.320836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from doubleml import DoubleMLData, DoubleMLDID\n",
    "import numpy as np\n",
    "\n",
    "ml_g_linear = LinearRegression()\n",
    "ml_m_logit = LogisticRegression(max_iter=200)\n",
    "\n",
    "att_gt_results = estimate_att_gt(data, ml_g=ml_g_linear, ml_m=ml_m_logit)\n",
    "agg_summary = aggregate_att_gt_weighted(att_gt_results)\n",
    "\n",
    "print(att_gt_results)\n",
    "print(agg_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          G       t        ATT     StdErr   CI Lower   CI Upper\n",
      "0    1971.0  1971.0  -5.020802   6.135667 -17.046488   7.004884\n",
      "1    1971.0  1972.0  -9.813400   5.437082 -20.469886   0.843086\n",
      "2    1971.0  1973.0  10.534043   6.398119  -2.006040  23.074126\n",
      "3    1971.0  1974.0  11.216579   6.533464  -1.588774  24.021932\n",
      "4    1971.0  1975.0  12.134260   6.754665  -1.104641  25.373161\n",
      "..      ...     ...        ...        ...        ...        ...\n",
      "253  1985.0  1992.0   0.796086  10.042278 -18.886417  20.478589\n",
      "254  1985.0  1993.0   8.908715   7.161766  -5.128089  22.945518\n",
      "255  1985.0  1994.0   5.705179   7.641421  -9.271730  20.682089\n",
      "256  1985.0  1995.0  11.118021   7.309105  -3.207562  25.443605\n",
      "257  1985.0  1996.0   7.528995   4.611464  -1.509308  16.567298\n",
      "\n",
      "[258 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "ml_g_linear = LinearRegression()\n",
    "ml_m_logit = LogisticRegression(max_iter=200)\n",
    "\n",
    "att_gt_results = estimate_att_gt(df, ml_g=ml_g_linear, ml_m=ml_m_logit)\n",
    "print(att_gt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_att_gt(results_df):\n",
    "    \"\"\"\n",
    "    Aggregate ATTgt estimates by averaging over all group-time pairs,\n",
    "    and compute the empirical standard error of the mean.\n",
    "    \"\"\"\n",
    "    # M√©dia dos ATTs\n",
    "    att_mean = results_df['ATT'].mean()\n",
    "\n",
    "    # Desvio padr√£o emp√≠rico dos ATTs\n",
    "    sd_att = results_df['ATT'].std(ddof=1)\n",
    "\n",
    "    # N√∫mero de estimativas\n",
    "    n_estimates = results_df.shape[0]\n",
    "\n",
    "    # Erro padr√£o da m√©dia\n",
    "    se_mean = sd_att / np.sqrt(n_estimates)\n",
    "\n",
    "    # Intervalo de confian√ßa 95%\n",
    "    ci_lower = att_mean - 1.96 * se_mean\n",
    "    ci_upper = att_mean + 1.96 * se_mean\n",
    "\n",
    "    # Monta o resultado em DataFrame\n",
    "    summary = pd.DataFrame({\n",
    "        'ATT Mean': [att_mean],\n",
    "        'StdErr Mean': [se_mean],\n",
    "        'CI Lower': [ci_lower],\n",
    "        'CI Upper': [ci_upper]\n",
    "    })\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ATT Mean  StdErr Mean  CI Lower  CI Upper\n",
      "0  7.981915     0.385102  7.227115  8.736715\n"
     ]
    }
   ],
   "source": [
    "agg_summary = aggregate_att_gt(att_gt_results)\n",
    "print(agg_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_att_gt_weighted(results_df, df_original):\n",
    "    \"\"\"\n",
    "    Aggregate ATTgt estimates weighted by the number of treated units in each (g, t).\n",
    "    \"\"\"\n",
    "    weighted_ests = []\n",
    "    weights = []\n",
    "\n",
    "    for idx, row in results_df.iterrows():\n",
    "        g = row['G']\n",
    "        t = row['t']\n",
    "        \n",
    "        # Conta o n√∫mero de unidades tratadas em g no tempo t\n",
    "        n_treated = df_original[(df_original['_nfd'] == g) & (df_original['year'] == t)].shape[0]\n",
    "        \n",
    "        if n_treated == 0:\n",
    "            continue  # pula se n√£o houver tratados no tempo t para o grupo g\n",
    "\n",
    "        weighted_ests.append(row['ATT'] * n_treated)\n",
    "        weights.append(n_treated)\n",
    "\n",
    "    # Calcula a m√©dia ponderada\n",
    "    weighted_att_mean = np.sum(weighted_ests) / np.sum(weights)\n",
    "\n",
    "    # Calcula o erro padr√£o emp√≠rico ponderado\n",
    "    att_values = results_df['ATT']\n",
    "    sd_att = att_values.std(ddof=1)\n",
    "    n_estimates = len(att_values)\n",
    "    se_mean = sd_att / np.sqrt(n_estimates)\n",
    "\n",
    "    # Intervalo de confian√ßa 95%\n",
    "    ci_lower = weighted_att_mean - 1.96 * se_mean\n",
    "    ci_upper = weighted_att_mean + 1.96 * se_mean\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        'ATT Weighted Mean': [weighted_att_mean],\n",
    "        'StdErr Mean': [se_mean],\n",
    "        'CI Lower': [ci_lower],\n",
    "        'CI Upper': [ci_upper]\n",
    "    })\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ATT Weighted Mean  StdErr Mean  CI Lower   CI Upper\n",
      "0           9.823624     0.385102  9.068824  10.578424\n"
     ]
    }
   ],
   "source": [
    "agg_weighted_summary = aggregate_att_gt_weighted(att_gt_results, df)\n",
    "print(agg_weighted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_group_results_empirical(group_results):\n",
    "    # M√©dia dos ATTs\n",
    "    att_mean = group_results['ATT'].mean()\n",
    "\n",
    "    # Desvio padr√£o das estimativas (emp√≠rico)\n",
    "    sd_att = group_results['ATT'].std(ddof=1)\n",
    "    n_groups = group_results.shape[0]\n",
    "    se_mean = sd_att / np.sqrt(n_groups)\n",
    "\n",
    "    # Intervalo de confian√ßa 95%\n",
    "    ci_lower = att_mean - 1.96 * se_mean\n",
    "    ci_upper = att_mean + 1.96 * se_mean\n",
    "\n",
    "    # Monta o resultado\n",
    "    summary = pd.DataFrame({\n",
    "        'ATT Mean': [att_mean],\n",
    "        'StdErr Mean': [se_mean],\n",
    "        'CI Lower': [ci_lower],\n",
    "        'CI Upper': [ci_upper]\n",
    "    })\n",
    "\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ATT Mean  StdErr Mean  CI Lower  CI Upper\n",
      "0  4.035823     0.272238  3.502237  4.569409\n"
     ]
    }
   ],
   "source": [
    "summary_empirical = summarize_group_results_empirical(group_results)\n",
    "print(summary_empirical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar nova base df1 quando: G==1973 ou \"missing\"\n",
    "df1 = data[(data['G'] == 1973) | (data['G'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "d  0.11987  2.897706  0.041367  0.967003 -5.559528  5.799269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\doubleml\\utils\\_checks.py:204: UserWarning: Propensity predictions from learner RandomForestClassifier(random_state=123) for ml_m are close to zero or one (eps=1e-12).\n",
      "  warnings.warn(f'Propensity predictions from learner {str(learner)} for'\n"
     ]
    }
   ],
   "source": [
    "# Reformatar X, Y, D conforme o DoubleML espera\n",
    "X = df1[['pcinc', 'asmrh', 'cases']].values\n",
    "Y = df1['Y'].values\n",
    "D = df1['D'].values\n",
    "\n",
    "# Preparar o DoubleMLData\n",
    "dml_data = DoubleMLData.from_arrays(x=X, y=Y, d=D)\n",
    "\n",
    "# Configurar modelos de ML com RandomForest\n",
    "ml_g = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "ml_m = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "# Instanciar e ajustar o DoubleMLDID\n",
    "dml_did = DoubleMLDID(dml_data,\n",
    "                      ml_g=ml_g,\n",
    "                      ml_m=ml_m,\n",
    "                      score='observational',\n",
    "                      in_sample_normalization=True,\n",
    "                      n_folds=3)\n",
    "\n",
    "# Rodar a estima√ß√£o\n",
    "dml_did.fit()\n",
    "\n",
    "# Mostrar o resultado\n",
    "print(dml_did.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_gt = ATTgt(data=df1, cohort_name=\"G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]     0%|                    | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 71.60it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('cohort', 'base_period', 'time')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "('ATTgtResult', '', 'ATT')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'analytic', 'std_error')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'pointwise conf. band', 'lower')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'pointwise conf. band', 'upper')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('ATTgtResult', 'pointwise conf. band', 'zero_not_in_cband')",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6a07f98a-fd9e-41a1-b1d5-fb0e2cc151a4",
       "rows": [
        [
         "(1973, 1964, 1965)",
         "-13.3878105363878",
         "7.096692675362982",
         "-27.297072589448447",
         "0.5214515166728475",
         ""
        ],
        [
         "(1973, 1965, 1966)",
         "-3.6081372510273817",
         "8.672491952358461",
         "-20.605909133863424",
         "13.38963463180866",
         ""
        ],
        [
         "(1973, 1966, 1967)",
         "9.726261021650634",
         "7.509689305677896",
         "-4.992459552563647",
         "24.444981595864917",
         ""
        ],
        [
         "(1973, 1967, 1968)",
         "-6.5899256096589545",
         "7.325320295941467",
         "-20.94728956492452",
         "7.767438345606611",
         ""
        ],
        [
         "(1973, 1968, 1969)",
         "6.707202398090848",
         "4.838605493330789",
         "-2.7762901042351587",
         "16.190694900416855",
         ""
        ],
        [
         "(1973, 1969, 1970)",
         "1.4392063959306274",
         "5.826625865855646",
         "-9.980770452535946",
         "12.859183244397201",
         ""
        ],
        [
         "(1973, 1970, 1971)",
         "0.05984138899265867",
         "7.768446124270228",
         "-15.166033230416756",
         "15.285716008402074",
         ""
        ],
        [
         "(1973, 1971, 1972)",
         "1.2374567326840245",
         "7.684924943840665",
         "-13.824719381137175",
         "16.299632846505226",
         ""
        ],
        [
         "(1973, 1972, 1973)",
         "0.06351941793253812",
         "7.657225324489758",
         "-14.944366439575417",
         "15.071405275440492",
         ""
        ],
        [
         "(1973, 1972, 1974)",
         "3.4813837666687015",
         "7.333599425654464",
         "-10.892206984657674",
         "17.85497451799508",
         ""
        ],
        [
         "(1973, 1972, 1975)",
         "0.3659404681529983",
         "11.94692217941721",
         "-23.049596729607504",
         "23.781477665913503",
         ""
        ],
        [
         "(1973, 1972, 1976)",
         "0.2985835272239964",
         "7.212508458159938",
         "-13.837673288959998",
         "14.434840343407991",
         ""
        ],
        [
         "(1973, 1972, 1977)",
         "-0.5331874528310987",
         "5.966500956387103",
         "-12.227314441073608",
         "11.16093953541141",
         ""
        ],
        [
         "(1973, 1972, 1978)",
         "-4.867036124853161",
         "6.188719084098078",
         "-16.996702640121104",
         "7.262630390414781",
         ""
        ],
        [
         "(1973, 1972, 1979)",
         "-5.21857767230723",
         "6.296130455734855",
         "-17.558766607513302",
         "7.121611262898842",
         ""
        ],
        [
         "(1973, 1972, 1980)",
         "-9.889103356592504",
         "8.38404490767049",
         "-26.321529420393105",
         "6.543322707208098",
         ""
        ],
        [
         "(1973, 1972, 1981)",
         "-3.9907053041831415",
         "6.480582728029805",
         "-16.692414049953893",
         "8.711003441587609",
         ""
        ],
        [
         "(1973, 1972, 1982)",
         "3.563091719505969",
         "9.048286407851966",
         "-14.171223761687184",
         "21.297407200699123",
         ""
        ],
        [
         "(1973, 1972, 1983)",
         "1.610598538518015",
         "5.293054818081528",
         "-8.763598273117987",
         "11.984795350154018",
         ""
        ],
        [
         "(1973, 1972, 1984)",
         "-2.117688426569487",
         "7.497366088816361",
         "-16.81225593956148",
         "12.576879086422508",
         ""
        ],
        [
         "(1973, 1972, 1985)",
         "-0.7980611070256529",
         "5.225489915443156",
         "-11.039833142871492",
         "9.443710928820186",
         ""
        ],
        [
         "(1973, 1972, 1986)",
         "-1.58393203585139",
         "5.458440281855954",
         "-12.282278400051721",
         "9.114414328348941",
         ""
        ],
        [
         "(1973, 1972, 1987)",
         "-1.9148625150770777",
         "9.529503100701016",
         "-20.592345383013843",
         "16.762620352859685",
         ""
        ],
        [
         "(1973, 1972, 1988)",
         "-2.0645798136808406",
         "8.745796536850932",
         "-19.206026042023797",
         "15.076866414662117",
         ""
        ],
        [
         "(1973, 1972, 1989)",
         "-4.327468199490222",
         "5.188969697818547",
         "-14.497661924084262",
         "5.842725525103817",
         ""
        ],
        [
         "(1973, 1972, 1990)",
         "-6.890668879553045",
         "5.637113662501024",
         "-17.93920863481373",
         "4.157870875707639",
         ""
        ],
        [
         "(1973, 1972, 1991)",
         "-6.4601690822337",
         "7.222601240757775",
         "-20.616207388813248",
         "7.695869224345846",
         ""
        ],
        [
         "(1973, 1972, 1992)",
         "-9.39225275954942",
         "5.919873636111302",
         "-20.994991879355744",
         "2.2104863602569065",
         ""
        ],
        [
         "(1973, 1972, 1993)",
         "-6.705061440356231",
         "6.689963712745539",
         "-19.81714937521735",
         "6.407026494504888",
         ""
        ],
        [
         "(1973, 1972, 1994)",
         "-3.7253801299700013",
         "6.106506391973833",
         "-15.693912729602346",
         "8.243152469662341",
         ""
        ],
        [
         "(1973, 1972, 1995)",
         "-9.408144210926865",
         "5.305198776835507",
         "-19.806142744350407",
         "0.9898543224966758",
         ""
        ],
        [
         "(1973, 1972, 1996)",
         "-10.933998033885475",
         "5.361000760161802",
         "-21.441366444894456",
         "-0.42662962287649187",
         "*"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 32
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">ATTgtResult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>base_period</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"32\" valign=\"top\">1973</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <td>-13.387811</td>\n",
       "      <td>7.096693</td>\n",
       "      <td>-27.297073</td>\n",
       "      <td>0.521452</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <td>-3.608137</td>\n",
       "      <td>8.672492</td>\n",
       "      <td>-20.605909</td>\n",
       "      <td>13.389635</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <td>9.726261</td>\n",
       "      <td>7.509689</td>\n",
       "      <td>-4.992460</td>\n",
       "      <td>24.444982</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <td>-6.589926</td>\n",
       "      <td>7.325320</td>\n",
       "      <td>-20.947290</td>\n",
       "      <td>7.767438</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <td>6.707202</td>\n",
       "      <td>4.838605</td>\n",
       "      <td>-2.776290</td>\n",
       "      <td>16.190695</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <td>1.439206</td>\n",
       "      <td>5.826626</td>\n",
       "      <td>-9.980770</td>\n",
       "      <td>12.859183</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <td>0.059841</td>\n",
       "      <td>7.768446</td>\n",
       "      <td>-15.166033</td>\n",
       "      <td>15.285716</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <td>1.237457</td>\n",
       "      <td>7.684925</td>\n",
       "      <td>-13.824719</td>\n",
       "      <td>16.299633</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">1972</th>\n",
       "      <th>1973</th>\n",
       "      <td>0.063519</td>\n",
       "      <td>7.657225</td>\n",
       "      <td>-14.944366</td>\n",
       "      <td>15.071405</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>3.481384</td>\n",
       "      <td>7.333599</td>\n",
       "      <td>-10.892207</td>\n",
       "      <td>17.854975</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.365940</td>\n",
       "      <td>11.946922</td>\n",
       "      <td>-23.049597</td>\n",
       "      <td>23.781478</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.298584</td>\n",
       "      <td>7.212508</td>\n",
       "      <td>-13.837673</td>\n",
       "      <td>14.434840</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>-0.533187</td>\n",
       "      <td>5.966501</td>\n",
       "      <td>-12.227314</td>\n",
       "      <td>11.160940</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>-4.867036</td>\n",
       "      <td>6.188719</td>\n",
       "      <td>-16.996703</td>\n",
       "      <td>7.262630</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>-5.218578</td>\n",
       "      <td>6.296130</td>\n",
       "      <td>-17.558767</td>\n",
       "      <td>7.121611</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>-9.889103</td>\n",
       "      <td>8.384045</td>\n",
       "      <td>-26.321529</td>\n",
       "      <td>6.543323</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>-3.990705</td>\n",
       "      <td>6.480583</td>\n",
       "      <td>-16.692414</td>\n",
       "      <td>8.711003</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>3.563092</td>\n",
       "      <td>9.048286</td>\n",
       "      <td>-14.171224</td>\n",
       "      <td>21.297407</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1.610599</td>\n",
       "      <td>5.293055</td>\n",
       "      <td>-8.763598</td>\n",
       "      <td>11.984795</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>-2.117688</td>\n",
       "      <td>7.497366</td>\n",
       "      <td>-16.812256</td>\n",
       "      <td>12.576879</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>-0.798061</td>\n",
       "      <td>5.225490</td>\n",
       "      <td>-11.039833</td>\n",
       "      <td>9.443711</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>-1.583932</td>\n",
       "      <td>5.458440</td>\n",
       "      <td>-12.282278</td>\n",
       "      <td>9.114414</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>-1.914863</td>\n",
       "      <td>9.529503</td>\n",
       "      <td>-20.592345</td>\n",
       "      <td>16.762620</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>-2.064580</td>\n",
       "      <td>8.745797</td>\n",
       "      <td>-19.206026</td>\n",
       "      <td>15.076866</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>-4.327468</td>\n",
       "      <td>5.188970</td>\n",
       "      <td>-14.497662</td>\n",
       "      <td>5.842726</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>-6.890669</td>\n",
       "      <td>5.637114</td>\n",
       "      <td>-17.939209</td>\n",
       "      <td>4.157871</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>-6.460169</td>\n",
       "      <td>7.222601</td>\n",
       "      <td>-20.616207</td>\n",
       "      <td>7.695869</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>-9.392253</td>\n",
       "      <td>5.919874</td>\n",
       "      <td>-20.994992</td>\n",
       "      <td>2.210486</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>-6.705061</td>\n",
       "      <td>6.689964</td>\n",
       "      <td>-19.817149</td>\n",
       "      <td>6.407026</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>-3.725380</td>\n",
       "      <td>6.106506</td>\n",
       "      <td>-15.693913</td>\n",
       "      <td>8.243152</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-9.408144</td>\n",
       "      <td>5.305199</td>\n",
       "      <td>-19.806143</td>\n",
       "      <td>0.989854</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-10.933998</td>\n",
       "      <td>5.361001</td>\n",
       "      <td>-21.441366</td>\n",
       "      <td>-0.426630</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ATTgtResult                                  \\\n",
       "                                      analytic pointwise conf. band   \n",
       "                                ATT  std_error                lower   \n",
       "cohort base_period time                                               \n",
       "1973   1964        1965  -13.387811   7.096693           -27.297073   \n",
       "       1965        1966   -3.608137   8.672492           -20.605909   \n",
       "       1966        1967    9.726261   7.509689            -4.992460   \n",
       "       1967        1968   -6.589926   7.325320           -20.947290   \n",
       "       1968        1969    6.707202   4.838605            -2.776290   \n",
       "       1969        1970    1.439206   5.826626            -9.980770   \n",
       "       1970        1971    0.059841   7.768446           -15.166033   \n",
       "       1971        1972    1.237457   7.684925           -13.824719   \n",
       "       1972        1973    0.063519   7.657225           -14.944366   \n",
       "                   1974    3.481384   7.333599           -10.892207   \n",
       "                   1975    0.365940  11.946922           -23.049597   \n",
       "                   1976    0.298584   7.212508           -13.837673   \n",
       "                   1977   -0.533187   5.966501           -12.227314   \n",
       "                   1978   -4.867036   6.188719           -16.996703   \n",
       "                   1979   -5.218578   6.296130           -17.558767   \n",
       "                   1980   -9.889103   8.384045           -26.321529   \n",
       "                   1981   -3.990705   6.480583           -16.692414   \n",
       "                   1982    3.563092   9.048286           -14.171224   \n",
       "                   1983    1.610599   5.293055            -8.763598   \n",
       "                   1984   -2.117688   7.497366           -16.812256   \n",
       "                   1985   -0.798061   5.225490           -11.039833   \n",
       "                   1986   -1.583932   5.458440           -12.282278   \n",
       "                   1987   -1.914863   9.529503           -20.592345   \n",
       "                   1988   -2.064580   8.745797           -19.206026   \n",
       "                   1989   -4.327468   5.188970           -14.497662   \n",
       "                   1990   -6.890669   5.637114           -17.939209   \n",
       "                   1991   -6.460169   7.222601           -20.616207   \n",
       "                   1992   -9.392253   5.919874           -20.994992   \n",
       "                   1993   -6.705061   6.689964           -19.817149   \n",
       "                   1994   -3.725380   6.106506           -15.693913   \n",
       "                   1995   -9.408144   5.305199           -19.806143   \n",
       "                   1996  -10.933998   5.361001           -21.441366   \n",
       "\n",
       "                                                      \n",
       "                                                      \n",
       "                             upper zero_not_in_cband  \n",
       "cohort base_period time                               \n",
       "1973   1964        1965   0.521452                    \n",
       "       1965        1966  13.389635                    \n",
       "       1966        1967  24.444982                    \n",
       "       1967        1968   7.767438                    \n",
       "       1968        1969  16.190695                    \n",
       "       1969        1970  12.859183                    \n",
       "       1970        1971  15.285716                    \n",
       "       1971        1972  16.299633                    \n",
       "       1972        1973  15.071405                    \n",
       "                   1974  17.854975                    \n",
       "                   1975  23.781478                    \n",
       "                   1976  14.434840                    \n",
       "                   1977  11.160940                    \n",
       "                   1978   7.262630                    \n",
       "                   1979   7.121611                    \n",
       "                   1980   6.543323                    \n",
       "                   1981   8.711003                    \n",
       "                   1982  21.297407                    \n",
       "                   1983  11.984795                    \n",
       "                   1984  12.576879                    \n",
       "                   1985   9.443711                    \n",
       "                   1986   9.114414                    \n",
       "                   1987  16.762620                    \n",
       "                   1988  15.076866                    \n",
       "                   1989   5.842726                    \n",
       "                   1990   4.157871                    \n",
       "                   1991   7.695869                    \n",
       "                   1992   2.210486                    \n",
       "                   1993   6.407026                    \n",
       "                   1994   8.243152                    \n",
       "                   1995   0.989854                    \n",
       "                   1996  -0.426630                 *  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.fit(\"Y ~ 1 + pcinc + asmrh + cases\", est_method=\"dr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('SimpleAggregation', '', 'ATT')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'analytic', 'std_error')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'lower')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'upper')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'zero_not_in_cband')",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0d21fb71-8268-4b4e-80bd-ac745d51d0fb",
       "rows": [
        [
         "0",
         "-3.39323996278893",
         "5.373675933975803",
         "-13.92545125797114",
         "7.1389713323932815",
         ""
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">SimpleAggregation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.39324</td>\n",
       "      <td>5.373676</td>\n",
       "      <td>-13.925451</td>\n",
       "      <td>7.138971</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SimpleAggregation                                                           \n",
       "                     analytic pointwise conf. band                            \n",
       "                ATT std_error                lower     upper zero_not_in_cband\n",
       "0          -3.39324  5.373676           -13.925451  7.138971                  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.aggregate(\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err        t     P>|t|     2.5 %     97.5 %\n",
      "d  4.976907  4.938242  1.00783  0.313536 -4.701869  14.655683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\doubleml\\utils\\_checks.py:204: UserWarning: Propensity predictions from learner RandomForestClassifier(random_state=123) for ml_m are close to zero or one (eps=1e-12).\n",
      "  warnings.warn(f'Propensity predictions from learner {str(learner)} for'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from doubleml import DoubleMLDID, DoubleMLData\n",
    "\n",
    "# Reformatar X, Y, D conforme o DoubleML espera\n",
    "X = df1[['pcinc', 'asmrh', 'cases']].values\n",
    "Y = df1['Y'].values\n",
    "D = df1['D'].values\n",
    "\n",
    "# Preparar o DoubleMLData\n",
    "dml_data = DoubleMLData.from_arrays(x=X, y=Y, d=D)\n",
    "\n",
    "# Configurar modelos de ML com RandomForest\n",
    "ml_g_linear = LinearRegression()\n",
    "ml_m_logit = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Instanciar e ajustar o DoubleMLDID\n",
    "dml_did = DoubleMLDID(dml_data,\n",
    "                      ml_g=ml_g,\n",
    "                      ml_m=ml_m,\n",
    "                      score='observational',\n",
    "                      in_sample_normalization=True,\n",
    "                      n_folds=7)\n",
    "\n",
    "# Rodar a estima√ß√£o\n",
    "dml_did.fit()\n",
    "\n",
    "# Mostrar o resultado\n",
    "print(dml_did.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "n_estimators = 30\n",
    "ml_g = LGBMRegressor(n_estimators=n_estimators)\n",
    "ml_m = LGBMClassifier(n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doubleml import DoubleMLDID\n",
    "dml_did = DoubleMLDID(dml_data,\n",
    "                      ml_g=ml_g,\n",
    "                      ml_m=ml_m,\n",
    "                      score='observational',\n",
    "                      in_sample_normalization=True,\n",
    "                      n_folds=5)\n",
    "\n",
    "dml_did.fit()\n",
    "print(dml_did)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodar o DML na nova base df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DoubleMLDiDStaggered:\n",
    "    def __init__(self, data, yname, tname, gname, idname, xnames, ml_g, ml_m):\n",
    "        \"\"\"\n",
    "        Initializes the DoubleMLDiDStaggered estimator.\n",
    "\n",
    "        Parameters:\n",
    "        - data: pandas DataFrame containing the panel data.\n",
    "        - yname: str, outcome variable name.\n",
    "        - tname: str, time variable name.\n",
    "        - gname: str, treatment cohort variable name (first treated period).\n",
    "        - idname: str, unit identifier variable name.\n",
    "        - xnames: list of str, covariate names.\n",
    "        - ml_g: fitted machine learning model for outcome regression.\n",
    "        - ml_m: fitted machine learning model for propensity score estimation.\n",
    "        \"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.yname = yname\n",
    "        self.tname = tname\n",
    "        self.gname = gname\n",
    "        self.idname = idname\n",
    "        self.xnames = xnames\n",
    "        self.ml_g = ml_g\n",
    "        self.ml_m = ml_m\n",
    "        self.results = []\n",
    "\n",
    "    def _fit_group_time(self, g, t):\n",
    "        \"\"\"\n",
    "        Estimate ATT for a specific group-time pair.\n",
    "        \"\"\"\n",
    "        df = self.data.copy()\n",
    "        df['G'] = (df[self.gname] == g).astype(int)\n",
    "        df['D'] = (df[self.tname] >= g).astype(int) * df['G']\n",
    "        df['Post'] = (df[self.tname] == t).astype(int)\n",
    "        df['Treat'] = df['D'] * df['Post']\n",
    "\n",
    "        # Select treated and control units at time t\n",
    "        df_t = df[df[self.tname] == t].copy()\n",
    "        treated = df_t['G'] == 1\n",
    "        control = (df_t[self.gname] > t) | (df_t[self.gname].isna())\n",
    "\n",
    "        # Skip if no control or treated units\n",
    "        if treated.sum() == 0 or control.sum() == 0:\n",
    "            return None\n",
    "\n",
    "        X = df_t[self.xnames]\n",
    "        Y = df_t[self.yname]\n",
    "\n",
    "        # Fit nuisance models on control units only (orthogonalization)\n",
    "        self.ml_g.fit(X[control], Y[control])\n",
    "        self.ml_m.fit(X, df_t['G'])\n",
    "\n",
    "        mu0 = self.ml_g.predict(X)\n",
    "        pscore = np.clip(self.ml_m.predict_proba(X)[:, 1], 1e-6, 1 - 1e-6)\n",
    "\n",
    "        # Compute DR scores\n",
    "        dr_scores = ((df_t['G'] - pscore) / pscore / (1 - pscore)) * (Y - mu0)\n",
    "\n",
    "        att = dr_scores[treated].mean()\n",
    "        return {'g': g, 't': t, 'att': att}\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit the model across all group-time combinations.\n",
    "        \"\"\"\n",
    "        groups = self.data[self.gname].dropna().unique()\n",
    "        times = self.data[self.tname].unique()\n",
    "\n",
    "        results = []\n",
    "        for g in groups:\n",
    "            for t in times:\n",
    "                if t >= g:\n",
    "                    res = self._fit_group_time(g, t)\n",
    "                    if res is not None:\n",
    "                        results.append(res)\n",
    "        self.results = pd.DataFrame(results)\n",
    "        return self\n",
    "\n",
    "    def aggregate_att(self):\n",
    "        \"\"\"\n",
    "        Aggregate the ATT estimates by averaging over all group-time pairs.\n",
    "        \"\"\"\n",
    "        return self.results['att'].mean()\n",
    "\n",
    "    def plot_event_study(self):\n",
    "        \"\"\"\n",
    "        Plot the event-study style results.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        if self.results.empty:\n",
    "            print(\"No results to plot.\")\n",
    "            return\n",
    "\n",
    "        avg_att_by_time = self.results.groupby('t')['att'].mean()\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(avg_att_by_time.index, avg_att_by_time.values, marker='o')\n",
    "        plt.axhline(0, color='black', linestyle='--')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Average ATT')\n",
    "        plt.title('Event Study: ATT over Time')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Pronto para usar. Voc√™ quer que eu monte um exemplo usando o arquivo `bacon_example.dta`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "g",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "att",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "150ae559-84d1-4629-b19f-65da13b8a9b9",
       "rows": [
        [
         "0",
         "1971.0",
         "1971.0",
         "-6.428094854584758"
        ],
        [
         "1",
         "1971.0",
         "1972.0",
         "-15.785884124080747"
        ],
        [
         "2",
         "1971.0",
         "1973.0",
         "-5.387280783696845"
        ],
        [
         "3",
         "1971.0",
         "1974.0",
         "16.24586781156446"
        ],
        [
         "4",
         "1971.0",
         "1975.0",
         "2.767154158965983"
        ],
        [
         "5",
         "1971.0",
         "1976.0",
         "3.8368120305944844"
        ],
        [
         "6",
         "1971.0",
         "1977.0",
         "7.409267374350074"
        ],
        [
         "7",
         "1971.0",
         "1978.0",
         "-1.1647823658699907"
        ],
        [
         "8",
         "1971.0",
         "1979.0",
         "-5.768896302126853"
        ],
        [
         "9",
         "1971.0",
         "1980.0",
         "-14.861222831246254"
        ],
        [
         "10",
         "1971.0",
         "1981.0",
         "-8.893244679244628"
        ],
        [
         "11",
         "1971.0",
         "1982.0",
         "6.4035515070576166"
        ],
        [
         "12",
         "1971.0",
         "1983.0",
         "13.961740003084907"
        ],
        [
         "13",
         "1971.0",
         "1984.0",
         "10.153450965771157"
        ],
        [
         "14",
         "1971.0",
         "1985.0",
         "15.164912049779996"
        ],
        [
         "15",
         "1971.0",
         "1986.0",
         "10.38327573939574"
        ],
        [
         "16",
         "1971.0",
         "1987.0",
         "7.052531041954624"
        ],
        [
         "17",
         "1971.0",
         "1988.0",
         "4.391399279202973"
        ],
        [
         "18",
         "1971.0",
         "1989.0",
         "-6.251316638310205"
        ],
        [
         "19",
         "1971.0",
         "1990.0",
         "-1.6369735632216376"
        ],
        [
         "20",
         "1971.0",
         "1991.0",
         "-7.627770161502198"
        ],
        [
         "21",
         "1971.0",
         "1992.0",
         "2.116382345456995"
        ],
        [
         "22",
         "1971.0",
         "1993.0",
         "8.043199226280466"
        ],
        [
         "23",
         "1971.0",
         "1994.0",
         "-0.46303868315141017"
        ],
        [
         "24",
         "1971.0",
         "1995.0",
         "-3.9213645669546264"
        ],
        [
         "25",
         "1971.0",
         "1996.0",
         "7.2486236293327675"
        ],
        [
         "26",
         "1973.0",
         "1973.0",
         "34.3522147610109"
        ],
        [
         "27",
         "1973.0",
         "1974.0",
         "28.500272073819747"
        ],
        [
         "28",
         "1973.0",
         "1975.0",
         "29.95275843475489"
        ],
        [
         "29",
         "1973.0",
         "1976.0",
         "24.109026852898403"
        ],
        [
         "30",
         "1973.0",
         "1977.0",
         "22.045289684424066"
        ],
        [
         "31",
         "1973.0",
         "1978.0",
         "20.058849520975986"
        ],
        [
         "32",
         "1973.0",
         "1979.0",
         "22.71674326040878"
        ],
        [
         "33",
         "1973.0",
         "1980.0",
         "12.037012331858651"
        ],
        [
         "34",
         "1973.0",
         "1981.0",
         "18.245645075770874"
        ],
        [
         "35",
         "1973.0",
         "1982.0",
         "25.189608009529422"
        ],
        [
         "36",
         "1973.0",
         "1983.0",
         "24.727740962630424"
        ],
        [
         "37",
         "1973.0",
         "1984.0",
         "13.712708464318833"
        ],
        [
         "38",
         "1973.0",
         "1985.0",
         "22.845226454871874"
        ],
        [
         "39",
         "1973.0",
         "1986.0",
         "17.88855823716182"
        ],
        [
         "40",
         "1973.0",
         "1987.0",
         "12.063558928818127"
        ],
        [
         "41",
         "1973.0",
         "1988.0",
         "10.246135640379894"
        ],
        [
         "42",
         "1973.0",
         "1989.0",
         "15.920592826623027"
        ],
        [
         "43",
         "1973.0",
         "1990.0",
         "12.204694488599857"
        ],
        [
         "44",
         "1973.0",
         "1991.0",
         "6.760891230186919"
        ],
        [
         "45",
         "1973.0",
         "1992.0",
         "14.049891436834088"
        ],
        [
         "46",
         "1973.0",
         "1993.0",
         "11.021861272258375"
        ],
        [
         "47",
         "1973.0",
         "1994.0",
         "18.648546001219625"
        ],
        [
         "48",
         "1973.0",
         "1995.0",
         "8.681540282025113"
        ],
        [
         "49",
         "1973.0",
         "1996.0",
         "6.458966258035275"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 258
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g</th>\n",
       "      <th>t</th>\n",
       "      <th>att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>-6.428095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>-15.785884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>-5.387281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>16.245868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>2.767154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>11.478867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>-6.032115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>-14.044631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>-23.927145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>14.873342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          g       t        att\n",
       "0    1971.0  1971.0  -6.428095\n",
       "1    1971.0  1972.0 -15.785884\n",
       "2    1971.0  1973.0  -5.387281\n",
       "3    1971.0  1974.0  16.245868\n",
       "4    1971.0  1975.0   2.767154\n",
       "..      ...     ...        ...\n",
       "253  1985.0  1992.0  11.478867\n",
       "254  1985.0  1993.0  -6.032115\n",
       "255  1985.0  1994.0 -14.044631\n",
       "256  1985.0  1995.0 -23.927145\n",
       "257  1985.0  1996.0  14.873342\n",
       "\n",
       "[258 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "# Configura√ß√£o dos modelos de ML\n",
    "ml_g = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "ml_m = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "# Configura√ß√£o do estimador com os dados carregados\n",
    "dml_did_staggered = DoubleMLDiDStaggered(\n",
    "    data=data,\n",
    "    yname=\"asmrs\",\n",
    "    tname=\"year\",\n",
    "    gname=\"_nfd\",\n",
    "    idname=\"stfips\",\n",
    "    xnames=[\"pcinc\", \"asmrh\", \"cases\"],\n",
    "    ml_g=ml_g,\n",
    "    ml_m=ml_m\n",
    ")\n",
    "\n",
    "# Rodar o estimador completo\n",
    "dml_did_staggered.fit()\n",
    "\n",
    "# Exibir resultados\n",
    "dml_did_staggered.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "g",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "att",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7071cae8-09e7-4690-b7d3-37af01f2b4d2",
       "rows": [
        [
         "0",
         "1971.0",
         "1971.0",
         "-31.346566590962222"
        ],
        [
         "1",
         "1971.0",
         "1972.0",
         "-54.91385037558236"
        ],
        [
         "2",
         "1971.0",
         "1973.0",
         "-21.940507185670224"
        ],
        [
         "3",
         "1971.0",
         "1974.0",
         "63.389740621714715"
        ],
        [
         "4",
         "1971.0",
         "1975.0",
         "11.062566721698813"
        ],
        [
         "5",
         "1971.0",
         "1976.0",
         "59.04709037232027"
        ],
        [
         "6",
         "1971.0",
         "1977.0",
         "23.720939396177556"
        ],
        [
         "7",
         "1971.0",
         "1978.0",
         "-19.149292246139794"
        ],
        [
         "8",
         "1971.0",
         "1979.0",
         "8.93696121546583"
        ],
        [
         "9",
         "1971.0",
         "1980.0",
         "-43.89958743079028"
        ],
        [
         "10",
         "1971.0",
         "1981.0",
         "-30.841452669802898"
        ],
        [
         "11",
         "1971.0",
         "1982.0",
         "59.19852195071604"
        ],
        [
         "12",
         "1971.0",
         "1983.0",
         "27.7777448245853"
        ],
        [
         "13",
         "1971.0",
         "1984.0",
         "48.53913055338056"
        ],
        [
         "14",
         "1971.0",
         "1985.0",
         "46.284443490902405"
        ],
        [
         "15",
         "1971.0",
         "1986.0",
         "54.51692135801283"
        ],
        [
         "16",
         "1971.0",
         "1987.0",
         "33.01475024819414"
        ],
        [
         "17",
         "1971.0",
         "1988.0",
         "21.4574974516232"
        ],
        [
         "18",
         "1971.0",
         "1989.0",
         "5.524146307530016"
        ],
        [
         "19",
         "1971.0",
         "1990.0",
         "4.168039116362276"
        ],
        [
         "20",
         "1971.0",
         "1991.0",
         "-3.4217838308069894"
        ],
        [
         "21",
         "1971.0",
         "1992.0",
         "22.258774033704988"
        ],
        [
         "22",
         "1971.0",
         "1993.0",
         "41.538683209551046"
        ],
        [
         "23",
         "1971.0",
         "1994.0",
         "2.3605907701361764"
        ],
        [
         "24",
         "1971.0",
         "1995.0",
         "-31.79994849789239"
        ],
        [
         "25",
         "1971.0",
         "1996.0",
         "20.61298076870475"
        ],
        [
         "26",
         "1973.0",
         "1973.0",
         "95.84896796272596"
        ],
        [
         "27",
         "1973.0",
         "1974.0",
         "83.21941176021046"
        ],
        [
         "28",
         "1973.0",
         "1975.0",
         "92.1246230944991"
        ],
        [
         "29",
         "1973.0",
         "1976.0",
         "85.5799286922841"
        ],
        [
         "30",
         "1973.0",
         "1977.0",
         "59.044172892310925"
        ],
        [
         "31",
         "1973.0",
         "1978.0",
         "49.482598572402374"
        ],
        [
         "32",
         "1973.0",
         "1979.0",
         "64.63251634876228"
        ],
        [
         "33",
         "1973.0",
         "1980.0",
         "8.361830278289299"
        ],
        [
         "34",
         "1973.0",
         "1981.0",
         "53.69199952886747"
        ],
        [
         "35",
         "1973.0",
         "1982.0",
         "82.04106236784062"
        ],
        [
         "36",
         "1973.0",
         "1983.0",
         "80.26620355532839"
        ],
        [
         "37",
         "1973.0",
         "1984.0",
         "52.03821562012844"
        ],
        [
         "38",
         "1973.0",
         "1985.0",
         "73.62638449551295"
        ],
        [
         "39",
         "1973.0",
         "1986.0",
         "60.42337412339164"
        ],
        [
         "40",
         "1973.0",
         "1987.0",
         "61.068513161564326"
        ],
        [
         "41",
         "1973.0",
         "1988.0",
         "54.8977111230419"
        ],
        [
         "42",
         "1973.0",
         "1989.0",
         "57.89288967492653"
        ],
        [
         "43",
         "1973.0",
         "1990.0",
         "52.95011614929422"
        ],
        [
         "44",
         "1973.0",
         "1991.0",
         "37.98374564380127"
        ],
        [
         "45",
         "1973.0",
         "1992.0",
         "40.54633179062571"
        ],
        [
         "46",
         "1973.0",
         "1993.0",
         "48.16527455065714"
        ],
        [
         "47",
         "1973.0",
         "1994.0",
         "63.55890052589824"
        ],
        [
         "48",
         "1973.0",
         "1995.0",
         "34.78197827844389"
        ],
        [
         "49",
         "1973.0",
         "1996.0",
         "38.801709026458575"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 258
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g</th>\n",
       "      <th>t</th>\n",
       "      <th>att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>-31.346567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>-54.913850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>-21.940507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>63.389741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>11.062567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>57.538368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>-101.236223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>-309.071009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>-139.452963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1985.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>142.449768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          g       t         att\n",
       "0    1971.0  1971.0  -31.346567\n",
       "1    1971.0  1972.0  -54.913850\n",
       "2    1971.0  1973.0  -21.940507\n",
       "3    1971.0  1974.0   63.389741\n",
       "4    1971.0  1975.0   11.062567\n",
       "..      ...     ...         ...\n",
       "253  1985.0  1992.0   57.538368\n",
       "254  1985.0  1993.0 -101.236223\n",
       "255  1985.0  1994.0 -309.071009\n",
       "256  1985.0  1995.0 -139.452963\n",
       "257  1985.0  1996.0  142.449768\n",
       "\n",
       "[258 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Configura√ß√£o dos modelos param√©tricos simples (Linear e Logit)\n",
    "ml_g_linear = LinearRegression()\n",
    "ml_m_logit = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Novo estimador usando modelos simples\n",
    "dml_did_staggered_simple = DoubleMLDiDStaggered(\n",
    "    data=data,\n",
    "    yname=\"asmrs\",\n",
    "    tname=\"year\",\n",
    "    gname=\"_nfd\",\n",
    "    idname=\"stfips\",\n",
    "    xnames=[\"pcinc\", \"asmrh\", \"cases\"],\n",
    "    ml_g=ml_g_linear,\n",
    "    ml_m=ml_m_logit\n",
    ")\n",
    "\n",
    "# Rodar o estimador completo (agora leve)\n",
    "dml_did_staggered_simple.fit()\n",
    "\n",
    "dml_did_staggered_simple.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 1000\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 6 entries, X1 to d\n",
      "dtypes: float64(6)\n",
      "memory usage: 47.0 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "from doubleml import DoubleMLData\n",
    "\n",
    "np.random.seed(42)\n",
    "n_obs = 1000\n",
    "x, y, d = make_did_SZ2020(n_obs=n_obs, dgp_type=4, cross_sectional_data=False, return_type='array')\n",
    "dml_data = DoubleMLData.from_arrays(x=x, y=y, d=d)\n",
    "print(dml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "n_estimators = 30\n",
    "ml_g = LGBMRegressor(n_estimators=n_estimators)\n",
    "ml_m = LGBMClassifier(n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 532\n",
      "[LightGBM] [Info] Number of data points in the train set: 396, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 218,891977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 530\n",
      "[LightGBM] [Info] Number of data points in the train set: 395, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 220,259985\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 530\n",
      "[LightGBM] [Info] Number of data points in the train set: 395, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 218,273798\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,002970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 529\n",
      "[LightGBM] [Info] Number of data points in the train set: 395, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 217,962222\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 530\n",
      "[LightGBM] [Info] Number of data points in the train set: 395, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 219,023319\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 541\n",
      "[LightGBM] [Info] Number of data points in the train set: 404, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 205,560182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 544\n",
      "[LightGBM] [Info] Number of data points in the train set: 405, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 204,027292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 405, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 203,468888\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 405, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 204,921630\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 405, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 203,401822\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 404, number of negative: 396\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,505000 -> initscore=0,020001\n",
      "[LightGBM] [Info] Start training from score 0,020001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,506250 -> initscore=0,025001\n",
      "[LightGBM] [Info] Start training from score 0,025001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,506250 -> initscore=0,025001\n",
      "[LightGBM] [Info] Start training from score 0,025001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,506250 -> initscore=0,025001\n",
      "[LightGBM] [Info] Start training from score 0,025001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,506250 -> initscore=0,025001\n",
      "[LightGBM] [Info] Start training from score 0,025001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "================== DoubleMLDID Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 1000\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: observational\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: LGBMRegressor(n_estimators=30)\n",
      "Learner ml_m: LGBMClassifier(n_estimators=30)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_g0 RMSE: [[11.55855122]]\n",
      "Learner ml_g1 RMSE: [[11.38983785]]\n",
      "Classification:\n",
      "Learner ml_m Log Loss: [[0.67674909]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef  std err         t     P>|t|     2.5 %    97.5 %\n",
      "d  0.305272  1.25855  0.242559  0.808347 -2.161441  2.771986\n"
     ]
    }
   ],
   "source": [
    "from doubleml import DoubleMLDID\n",
    "dml_did = DoubleMLDID(dml_data,\n",
    "                      ml_g=ml_g,\n",
    "                      ml_m=ml_m,\n",
    "                      score='observational',\n",
    "                      in_sample_normalization=True,\n",
    "                      n_folds=5)\n",
    "\n",
    "dml_did.fit()\n",
    "print(dml_did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 61.69it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('SimpleAggregation', '', 'ATT')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'analytic', 'std_error')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'lower')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'upper')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('SimpleAggregation', 'pointwise conf. band', 'zero_not_in_cband')",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "805cced6-9113-428e-8e7f-3a9fbaaf929e",
       "rows": [
        [
         "0",
         "0.0",
         null,
         null,
         null,
         ""
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">SimpleAggregation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SimpleAggregation                                                       \n",
       "                     analytic pointwise conf. band                        \n",
       "                ATT std_error                lower upper zero_not_in_cband\n",
       "0               0.0       NaN                  NaN   NaN                  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recriar o dataset simulado conforme seu exemplo anterior\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "from differences import ATTgt\n",
    "\n",
    "# Simular os dados\n",
    "np.random.seed(42)\n",
    "n_obs = 1000\n",
    "x, y, d = make_did_SZ2020(n_obs=n_obs, dgp_type=4, cross_sectional_data=False, return_type='array')\n",
    "\n",
    "# Criar estrutura de painel artificial\n",
    "df = pd.DataFrame(x, columns=[f'x{i+1}' for i in range(x.shape[1])])\n",
    "df['Y'] = y\n",
    "df['D'] = d\n",
    "\n",
    "# Adicionar per√≠odo artificial: 0 (pr√©) e 1 (p√≥s), duplicando os dados\n",
    "df_pre = df.copy()\n",
    "df_pre['time'] = 0\n",
    "df_pre['D'] = 0  # todos ainda n√£o tratados no pr√©\n",
    "\n",
    "df_post = df.copy()\n",
    "df_post['time'] = 1\n",
    "df_post['D'] = d  # tratamento no p√≥s conforme definido\n",
    "\n",
    "# Empilhar o painel\n",
    "panel_df = pd.concat([df_pre, df_post], ignore_index=True)\n",
    "\n",
    "# Adicionar ids\n",
    "panel_df['id'] = np.tile(np.arange(1, n_obs + 1), 2)\n",
    "\n",
    "# Definir cohort: todos tratados no tempo 1 se D == 1, NaN caso contr√°rio\n",
    "panel_df['G'] = panel_df.apply(lambda row: 1 if row['D'] == 1 and row['time'] == 1 else np.nan, axis=1)\n",
    "\n",
    "# Definir √≠ndice de painel\n",
    "panel_df = panel_df.set_index(['id', 'time'])\n",
    "\n",
    "# Rodar o ATTgt no pacote differences\n",
    "att_gt = ATTgt(data=panel_df, cohort_name=\"G\")\n",
    "\n",
    "# Como √© apenas um \"cohort\", usamos uma f√≥rmula simples sem covari√°veis adicionais\n",
    "att_gt.fit(\"Y ~ 1\", est_method=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<differences.attgt.attgt.ATTgt at 0x1c37a62f610>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregar o ATT m√©dio\n",
    "att_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('id', 'time')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "x1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "x4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "D",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "G",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8aaf33c2-e05a-4b1d-a3ba-79ea6f1d34e4",
       "rows": [
        [
         "(1, 0)",
         "0.248272817646453",
         "-0.11717811535335386",
         "0.30934605244086477",
         "0.9216855856063015",
         "251.86466836781307",
         "0.0",
         null
        ],
        [
         "(2, 0)",
         "-0.4352010371266951",
         "-0.2640798890889764",
         "-0.3925488683768952",
         "0.30173468396991476",
         "232.22670588146065",
         "0.0",
         null
        ],
        [
         "(3, 0)",
         "-0.6071810620063669",
         "0.6062715376825152",
         "0.19945837084197834",
         "-0.020247669201914065",
         "190.54790541594548",
         "0.0",
         null
        ],
        [
         "(4, 0)",
         "-0.018765729852440714",
         "-1.5957683234429116",
         "-0.4384891493359489",
         "-1.687259569212889",
         "159.65896573827484",
         "0.0",
         null
        ],
        [
         "(5, 0)",
         "-0.9348556841669755",
         "0.4127416587925872",
         "0.9696467785679094",
         "-0.8156960695826445",
         "155.9904539424009",
         "0.0",
         null
        ],
        [
         "(6, 0)",
         "1.6400075450177747",
         "-0.09853463653270582",
         "0.07615741672939255",
         "-1.1731646777922269",
         "229.477481738679",
         "0.0",
         null
        ],
        [
         "(7, 0)",
         "-0.6578147592644762",
         "0.11234600371037894",
         "0.6396788488393461",
         "0.268477373788349",
         "188.44871198232715",
         "0.0",
         null
        ],
        [
         "(8, 0)",
         "-0.6946129110658759",
         "-0.3721214161385029",
         "0.35161887860906493",
         "1.0528359557569358",
         "207.38561968710198",
         "0.0",
         null
        ],
        [
         "(9, 0)",
         "-0.2544793863185826",
         "-1.0167392579810088",
         "-0.036569854186116184",
         "-1.5666472941069611",
         "188.06636794342796",
         "0.0",
         null
        ],
        [
         "(10, 0)",
         "-0.05103027967933122",
         "-1.6639935283046505",
         "-0.30252028183114327",
         "-1.2445206187016422",
         "172.89823004060406",
         "0.0",
         null
        ],
        [
         "(11, 0)",
         "0.5351562570713077",
         "0.08464413139331356",
         "-0.11173077783993667",
         "-0.16357575003474353",
         "226.79168904333088",
         "0.0",
         null
        ],
        [
         "(12, 0)",
         "-1.1529003020683748",
         "-1.117503214150341",
         "0.7000908390413129",
         "0.16257979692299848",
         "167.60462343763703",
         "0.0",
         null
        ],
        [
         "(13, 0)",
         "0.08373351659362523",
         "-1.3898071704927355",
         "0.08894793516780765",
         "-1.486054366511084",
         "197.68789376858186",
         "0.0",
         null
        ],
        [
         "(14, 0)",
         "-0.742886400766362",
         "0.7407187173702539",
         "-0.7032803522608919",
         "1.0396380654280089",
         "225.48488714542844",
         "0.0",
         null
        ],
        [
         "(15, 0)",
         "-0.83966407100749",
         "-0.42373348981854564",
         "-0.3031012546778396",
         "0.3969368946584241",
         "200.76608390747043",
         "0.0",
         null
        ],
        [
         "(16, 0)",
         "-0.6138449784387092",
         "-0.2339932552460971",
         "0.5337582326663548",
         "-1.0006561977556858",
         "162.1252663225623",
         "0.0",
         null
        ],
        [
         "(17, 0)",
         "0.6302086744130226",
         "0.7618363534531941",
         "-0.08461321742154582",
         "1.6625173655955559",
         "264.8173923767888",
         "0.0",
         null
        ],
        [
         "(18, 0)",
         "0.1024505027015891",
         "-0.5154280190024068",
         "0.10894964378192747",
         "0.5604998385722467",
         "237.11247344827552",
         "0.0",
         null
        ],
        [
         "(19, 0)",
         "-0.27368706764870565",
         "1.4728600004150554",
         "0.07087995110433787",
         "1.6833261164759965",
         "208.52632846485562",
         "0.0",
         null
        ],
        [
         "(20, 0)",
         "-0.1652822405497369",
         "-0.28710427731770466",
         "-0.017138396102805695",
         "-1.571584535544923",
         "182.7873769106356",
         "0.0",
         null
        ],
        [
         "(21, 0)",
         "-0.42394195775835997",
         "0.3519725471009371",
         "-0.3487072652768507",
         "-0.18524854997137535",
         "218.15807150584908",
         "0.0",
         null
        ],
        [
         "(22, 0)",
         "-0.8219407474287932",
         "-0.669528352434247",
         "-0.7422161182902411",
         "-0.19341174277987302",
         "198.62896204502198",
         "0.0",
         null
        ],
        [
         "(23, 0)",
         "-0.6480791786869504",
         "0.5861287953942854",
         "-0.07745537401623194",
         "0.9940185893409177",
         "220.03965627878227",
         "0.0",
         null
        ],
        [
         "(24, 0)",
         "-0.7583908432479032",
         "-0.42966505144182277",
         "0.26016894050424055",
         "-1.2624791074601913",
         "157.9946613162356",
         "0.0",
         null
        ],
        [
         "(25, 0)",
         "0.03519275295132082",
         "0.18943904429985722",
         "-0.023733178932882317",
         "-0.05532869088281401",
         "219.03832754817677",
         "0.0",
         null
        ],
        [
         "(26, 0)",
         "-1.1262217780673034",
         "-0.6533147791666478",
         "0.48472521031632115",
         "-0.8974168401370207",
         "150.43901627654998",
         "0.0",
         null
        ],
        [
         "(27, 0)",
         "-0.3777117614552684",
         "0.3898056196645051",
         "-0.3287631871974817",
         "0.3341052289472506",
         "240.47154773117472",
         "0.0",
         null
        ],
        [
         "(28, 0)",
         "-0.0033845042285026235",
         "-0.07998412628235876",
         "-0.5120160608227708",
         "-0.14369830307618187",
         "188.52483590989863",
         "0.0",
         null
        ],
        [
         "(29, 0)",
         "-0.18951282034553518",
         "2.218953292905171",
         "-0.03706174497073757",
         "1.979966111846545",
         "245.31349820932417",
         "0.0",
         null
        ],
        [
         "(30, 0)",
         "-0.27273362649263927",
         "-1.1330077540239356",
         "-0.06555648047832746",
         "-0.3602602007882659",
         "218.05552279812798",
         "0.0",
         null
        ],
        [
         "(31, 0)",
         "0.6022585904412427",
         "-0.5506861923107051",
         "1.1901248915642528",
         "-1.5867498240389801",
         "219.41327800046298",
         "0.0",
         null
        ],
        [
         "(32, 0)",
         "0.3512113479580324",
         "1.4474518400558103",
         "-0.5944721895102788",
         "1.100522303097777",
         "234.83566223636683",
         "0.0",
         null
        ],
        [
         "(33, 0)",
         "-0.15378080381631734",
         "-0.46735541869460956",
         "-0.1809856050222887",
         "-0.3726140012064608",
         "187.42286020333904",
         "0.0",
         null
        ],
        [
         "(34, 0)",
         "-0.9605024777168508",
         "0.6402326642940043",
         "1.0352861135227778",
         "1.4032996387723442",
         "200.46574084922895",
         "0.0",
         null
        ],
        [
         "(35, 0)",
         "-0.8071755900183155",
         "-0.4333521973865727",
         "-0.6468434746991257",
         "-1.1107856225714745",
         "179.50752625499",
         "0.0",
         null
        ],
        [
         "(36, 0)",
         "-0.032968335877397795",
         "1.0667051729037293",
         "-0.3885379903974344",
         "1.001381540089661",
         "212.51159481254217",
         "0.0",
         null
        ],
        [
         "(37, 0)",
         "-0.001072729369020681",
         "0.6186088060582161",
         "-0.34559827283792405",
         "-0.4429234849245595",
         "190.72296131788192",
         "0.0",
         null
        ],
        [
         "(38, 0)",
         "0.2766152394585247",
         "0.18804302571348794",
         "0.10900036378085144",
         "0.38050553179209096",
         "236.87028577664165",
         "0.0",
         null
        ],
        [
         "(39, 0)",
         "-0.7448111600224696",
         "0.26965910282392513",
         "-0.2254988465719464",
         "-0.40464570097885794",
         "189.837135919462",
         "0.0",
         null
        ],
        [
         "(40, 0)",
         "2.442770727220525",
         "0.09981742461619678",
         "-1.9694890457766976",
         "0.7338348487902334",
         "261.310983205889",
         "0.0",
         null
        ],
        [
         "(41, 0)",
         "-0.9146410616751826",
         "1.0515372876950233",
         "-1.0906156045176545",
         "-0.09705385890924431",
         "198.63735866284253",
         "0.0",
         null
        ],
        [
         "(42, 0)",
         "0.8350546664061234",
         "0.19444076433154123",
         "0.824348171829762",
         "1.6235686912866432",
         "278.61848120151745",
         "0.0",
         null
        ],
        [
         "(43, 0)",
         "-0.4438798498949964",
         "-0.8114879269070254",
         "0.20020609500674558",
         "-1.1214318759485817",
         "173.52779167319085",
         "0.0",
         null
        ],
        [
         "(44, 0)",
         "-0.30863352014188744",
         "0.31273668594302567",
         "-0.04696399672268918",
         "0.7617160799760001",
         "227.3676159173352",
         "0.0",
         null
        ],
        [
         "(45, 0)",
         "-0.23140431662593222",
         "1.333665092603622",
         "-0.028777559514824722",
         "3.1286523688876215",
         "262.26416812056584",
         "0.0",
         null
        ],
        [
         "(46, 0)",
         "0.3969795335276417",
         "-0.5788526570325453",
         "-0.6774212108293853",
         "-0.3316159986750247",
         "207.04819847712042",
         "0.0",
         null
        ],
        [
         "(47, 0)",
         "-0.42689718987680003",
         "0.7241378889946398",
         "-0.13218494045471146",
         "0.3788839665534564",
         "220.14792727033029",
         "0.0",
         null
        ],
        [
         "(48, 0)",
         "-0.8439927689212194",
         "-2.0056555367218127",
         "0.3694676998980406",
         "-0.5236771635933894",
         "168.49928001212288",
         "0.0",
         null
        ],
        [
         "(49, 0)",
         "-0.045967390355536604",
         "-1.0617479978610205",
         "0.012567215382903323",
         "-0.6586756607090908",
         "207.44447072503434",
         "0.0",
         null
        ],
        [
         "(50, 0)",
         "-0.8649345861901189",
         "0.18463771337015777",
         "-0.0774759876437792",
         "-0.744041140543927",
         "171.8669354739635",
         "0.0",
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 2000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.248273</td>\n",
       "      <td>-0.117178</td>\n",
       "      <td>0.309346</td>\n",
       "      <td>0.921686</td>\n",
       "      <td>251.864668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.435201</td>\n",
       "      <td>-0.264080</td>\n",
       "      <td>-0.392549</td>\n",
       "      <td>0.301735</td>\n",
       "      <td>232.226706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.607181</td>\n",
       "      <td>0.606272</td>\n",
       "      <td>0.199458</td>\n",
       "      <td>-0.020248</td>\n",
       "      <td>190.547905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.018766</td>\n",
       "      <td>-1.595768</td>\n",
       "      <td>-0.438489</td>\n",
       "      <td>-1.687260</td>\n",
       "      <td>159.658966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.934856</td>\n",
       "      <td>0.412742</td>\n",
       "      <td>0.969647</td>\n",
       "      <td>-0.815696</td>\n",
       "      <td>155.990454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <th>1</th>\n",
       "      <td>1.457921</td>\n",
       "      <td>0.607361</td>\n",
       "      <td>5.718933</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>298.238992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.017862</td>\n",
       "      <td>-1.733995</td>\n",
       "      <td>0.112738</td>\n",
       "      <td>-1.781041</td>\n",
       "      <td>188.432492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <th>1</th>\n",
       "      <td>2.572294</td>\n",
       "      <td>-0.204188</td>\n",
       "      <td>-2.668426</td>\n",
       "      <td>-0.912382</td>\n",
       "      <td>219.081292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <th>1</th>\n",
       "      <td>-1.335875</td>\n",
       "      <td>1.216699</td>\n",
       "      <td>5.360220</td>\n",
       "      <td>0.478447</td>\n",
       "      <td>136.924503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <th>1</th>\n",
       "      <td>-1.368227</td>\n",
       "      <td>-0.552516</td>\n",
       "      <td>-2.770433</td>\n",
       "      <td>-0.045668</td>\n",
       "      <td>177.381862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1        x2        x3        x4           Y    D    G\n",
       "id   time                                                              \n",
       "1    0     0.248273 -0.117178  0.309346  0.921686  251.864668  0.0  NaN\n",
       "2    0    -0.435201 -0.264080 -0.392549  0.301735  232.226706  0.0  NaN\n",
       "3    0    -0.607181  0.606272  0.199458 -0.020248  190.547905  0.0  NaN\n",
       "4    0    -0.018766 -1.595768 -0.438489 -1.687260  159.658966  0.0  NaN\n",
       "5    0    -0.934856  0.412742  0.969647 -0.815696  155.990454  0.0  NaN\n",
       "...             ...       ...       ...       ...         ...  ...  ...\n",
       "996  1     1.457921  0.607361  5.718933  0.290200  298.238992  0.0  NaN\n",
       "997  1    -0.017862 -1.733995  0.112738 -1.781041  188.432492  0.0  NaN\n",
       "998  1     2.572294 -0.204188 -2.668426 -0.912382  219.081292  1.0  1.0\n",
       "999  1    -1.335875  1.216699  5.360220  0.478447  136.924503  1.0  1.0\n",
       "1000 1    -1.368227 -0.552516 -2.770433 -0.045668  177.381862  1.0  1.0\n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segundo exemplo de aplica√ß√£o do DDML-DiD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "# Double Debiased Machine Learning for Continuous Treatments\n",
    "\n",
    "## Introdu√ß√£o\n",
    "\n",
    "O **Double Debiased Machine Learning (DML)** √© um m√©todo estat√≠stico robusto e eficiente para estimar efeitos causais em contextos onde o tratamento √© uma vari√°vel cont√≠nua. Este m√©todo combina:\n",
    "- **Momentos Duplamente Robustos**, que garantem consist√™ncia mesmo quando uma das fun√ß√µes auxiliares √© mal especificada.\n",
    "- **Cross-fitting**, para evitar vi√©s de overfitting causado pelo uso do mesmo conjunto de dados para treinamento e infer√™ncia.\n",
    "- **M√©todos de Machine Learning (ML)**, como LASSO, Redes Neurais ou Random Forests, para modelar fun√ß√µes de expectativa condicional e densidades condicionais.\n",
    "\n",
    "O m√©todo √© especialmente adequado para cen√°rios onde o n√∫mero de covari√°veis √© grande (alta dimensionalidade), sendo robusto a especifica√ß√µes incorretas de uma das fun√ß√µes auxiliares.\n",
    "\n",
    "---\n",
    "\n",
    "## Estrutura do Problema\n",
    "\n",
    "### Dados e Objetivos\n",
    "\n",
    "Considere uma amostra $\\{Y_i, T_i, X_i\\}_{i=1}^n$, onde:\n",
    "- $Y_i$: Desfecho de interesse (vari√°vel dependente).\n",
    "- $T_i$: Tratamento cont√≠nuo.\n",
    "- $X_i$: Covari√°veis observadas (potencialmente de alta dimensionalidade).\n",
    "\n",
    "O objetivo principal √© estimar:\n",
    "1. **Fun√ß√£o de Resposta M√©dia √† Dose (Average Dose-Response Function - ADRF)**:\n",
    "   $$\n",
    "   \\beta_t = \\mathbb{E}[Y(t)],\n",
    "   $$\n",
    "   onde $Y(t)$ representa o desfecho potencial para um valor espec√≠fico $t$ do tratamento.\n",
    "\n",
    "2. **Efeito Marginal (Partial Effect)**:\n",
    "   $$\n",
    "   \\theta_t = \\frac{\\partial \\beta_t}{\\partial t}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Suposi√ß√µes para Identifica√ß√£o\n",
    "\n",
    "Para identificar os efeitos causais, assumimos:\n",
    "1. **Independ√™ncia Condicional (Unconfoundedness)**:\n",
    "   $$\n",
    "   T \\perp \\varepsilon \\mid X,\n",
    "   $$\n",
    "   onde $\\varepsilon$ √© o erro n√£o observado. Esta suposi√ß√£o implica que, condicional nas covari√°veis $X$, o tratamento √© independentemente alocado.\n",
    "\n",
    "2. **Suporte Comum (Common Support)**:\n",
    "   $$\n",
    "   f_{T|X}(t \\mid X) > 0, \\quad \\forall t \\in \\mathcal{T}.\n",
    "   $$\n",
    "   Esta condi√ß√£o assegura que h√° sobreposi√ß√£o suficiente entre grupos de tratamento.\n",
    "\n",
    "---\n",
    "\n",
    "## Estimador DML\n",
    "\n",
    "O estimador baseia-se em uma fun√ß√£o momento duplamente robusta, definida como:\n",
    "$$\n",
    "\\psi_t(Y_i, T_i, X_i) = \\gamma(t, X_i) + \\frac{K_h(T_i - t)}{f_{T|X}(t \\mid X_i)} \\left(Y_i - \\gamma(t, X_i)\\right),\n",
    "$$\n",
    "onde:\n",
    "- $\\gamma(t, X) = \\mathbb{E}[Y \\mid T = t, X]$: Expectativa condicional.\n",
    "- $f_{T|X}(t \\mid X)$: Densidade condicional do tratamento.\n",
    "- $K_h(T_i - t)$: Fun√ß√£o kernel para ponderar observa√ß√µes pr√≥ximas do valor de tratamento $t$.\n",
    "\n",
    "O estimador para $\\beta_t$ √© dado por:\n",
    "$$\n",
    "\\hat{\\beta}_t = \\frac{1}{n} \\sum_{i=1}^n \\psi_t(Y_i, T_i, X_i).\n",
    "$$\n",
    "\n",
    "### Cross-Fitting\n",
    "Para evitar vi√©s de overfitting, os dados s√£o particionados em $L$ subconjuntos (folds). Para cada fold $\\ell$, as fun√ß√µes $\\gamma$ e $f_{T|X}$ s√£o estimadas usando apenas os dados fora do fold $\\ell$. O estimador final √© obtido pela m√©dia das estimativas em cada fold:\n",
    "$$\n",
    "\\hat{\\beta}_t = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\gamma_{-\\ell}(t, X_i) + \\frac{K_h(T_i - t)}{f_{T|X,-\\ell}(t \\mid X_i)} \\left(Y_i - \\gamma_{-\\ell}(t, X_i)\\right) \\right].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Propriedades Assint√≥ticas\n",
    "\n",
    "Sob condi√ß√µes regulares, o estimador $\\hat{\\beta}_t$ √©:\n",
    "1. **Consistente**: Converge para o valor verdadeiro $\\beta_t$.\n",
    "2. **Assintoticamente Normal**:\n",
    "   $$\n",
    "   \\sqrt{n} (\\hat{\\beta}_t - \\beta_t) \\xrightarrow{d} N(0, V_t),\n",
    "   $$\n",
    "   onde $V_t$ √© a vari√¢ncia assint√≥tica, que pode ser estimada como:\n",
    "   $$\n",
    "   \\hat{V}_t = \\frac{1}{n^2} \\sum_{i=1}^n \\psi_t^2(Y_i, T_i, X_i).\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Estima√ß√£o do Efeito Marginal\n",
    "\n",
    "O efeito marginal $\\theta_t$ √© estimado numericamente:\n",
    "$$\n",
    "\\hat{\\theta}_t = \\frac{\\hat{\\beta}_{t + \\eta/2} - \\hat{\\beta}_{t - \\eta/2}}{\\eta},\n",
    "$$\n",
    "onde $\\eta$ √© uma sequ√™ncia positiva que converge para zero √† medida que $n \\to \\infty$.\n",
    "\n",
    "Para garantir consist√™ncia e efici√™ncia, $\\eta$ deve ser escolhida adequadamente, levando em conta o tamanho amostral e a variabilidade nas estimativas de $\\beta_t$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benef√≠cios e Limita√ß√µes\n",
    "\n",
    "### Benef√≠cios\n",
    "- **Flexibilidade**: Permite o uso de m√©todos de aprendizado de m√°quina para modelar $\\gamma$ e $f_{T|X}$.\n",
    "- **Efici√™ncia**: Utiliza t√©cnicas como cross-fitting para melhorar a precis√£o das estimativas.\n",
    "- **Robustez**: Resistente a erros de especifica√ß√£o em uma das fun√ß√µes auxiliares.\n",
    "\n",
    "### Limita√ß√µes\n",
    "- **Complexidade Computacional**: Requer a estimativa de fun√ß√µes auxiliares de alta dimensionalidade.\n",
    "- **Sensibilidade ao Kernel**: A escolha do kernel e da largura de banda ($h$) pode impactar os resultados.\n",
    "\n",
    "---\n",
    "\n",
    "## Exemplo Intuitivo\n",
    "\n",
    "Considere um estudo que analisa o impacto de **horas de treinamento em um programa de capacita√ß√£o** ($T$) nos **sal√°rios futuros** ($Y$):\n",
    "- Usamos $\\gamma(t, X)$ para prever sal√°rios dados $T$ e as covari√°veis $X$ (e.g., idade, escolaridade).\n",
    "- Estimamos $f_{T|X}(t \\mid X)$, que captura a distribui√ß√£o das horas de treinamento, dado o perfil do indiv√≠duo.\n",
    "- O DML ajusta as estimativas para isolar o impacto causal de $T$ em $Y$, mesmo que algumas rela√ß√µes sejam complexas ou n√£o lineares.\n",
    "\n",
    "---\n",
    "\n",
    "## Considera√ß√µes Finais\n",
    "O Double Debiased Machine Learning √© um m√©todo avan√ßado para estimar efeitos causais com tratamentos cont√≠nuos, oferecendo:\n",
    "\n",
    "* Robustez a especifica√ß√µes incorretas de modelos auxiliares.\n",
    "* Flexibilidade no uso de m√©todos de ML para modelagem de alta dimensionalidade.\n",
    "* Garantias te√≥ricas de consist√™ncia e normalidade assint√≥tica.\n",
    "\n",
    "Este m√©todo √© ideal para aplica√ß√µes emp√≠ricas que exigem alto rigor estat√≠stico, como estudos em economia, sa√∫de e pol√≠ticas p√∫blicas.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
