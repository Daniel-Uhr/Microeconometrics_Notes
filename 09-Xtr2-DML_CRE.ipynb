{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2942b8e2",
   "metadata": {},
   "source": [
    "## DML para Painel com Heterogeneidade Não Observada\n",
    "\n",
    "### Double Machine Learning - Correlated Random Effects (DML-CRE)\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "### Conteúdo\n",
    "\n",
    "* Introdução\n",
    "* Por que “demeanar e rodar DML” é perigoso?\n",
    "* O que é o DML + CRE (Mundlak) que eles recomendam?\n",
    "* O que os autores encontram nas simulações?\n",
    "* Recomendações formais\n",
    "* Um “esqueleto” de DML em painel \n",
    "* Resumo\n",
    "\n",
    "\n",
    "### Referência\n",
    "\n",
    "* Jonathan Fuhr and Dominik Papies (2024). Double Machine Learning meets Panel Data - Promises, Pitfalls, and Potential Solutions. https://arxiv.org/abs/2409.01266\n",
    "\n",
    "\n",
    "**Observações:** O material apresentado aqui é uma adaptação do material de aula do Prof. Daniel de Abreu Pereira Uhr, e não deve ser utilizado para fins comerciais. O material é disponibilizado para fins educacionais e de pesquisa, e não deve ser reproduzido sem a devida autorização do autor. Este material pode conter erros e imprecisões. O autor não se responsabiliza por quaisquer danos ou prejuízos decorrentes do uso deste material. O uso deste material é de responsabilidade exclusiva do usuário. Caso você encontre erros ou imprecisões neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer *feedback* ou sugestão de melhoria.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47894f40",
   "metadata": {},
   "source": [
    "#### Introdução\n",
    "\n",
    "O artigo parte do DML “padrão” (Chernozhukov et al., 2018), que é pensado para **amostra i.i.d. cross-sectional**, e pergunta:\n",
    "\n",
    "> “Como adaptar DML para **painel** quando há heterogeneidade não observada (U_i) que afeta tanto (Y_{it}) quanto (X_{it})?”\n",
    "\n",
    "Eles consideram um modelo do tipo:\n",
    "\n",
    "$$\n",
    "Y_{it} = \\theta_0 D_{it} + g_0(X_{it}, U_i) + \\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "* $Y_{it}$ – outcome de interesse \n",
    "* $D_{it}$ – tratamento cujo efeito causal (\\theta_0) queremos identificar.\n",
    "* $X_{it}$ – vetor de confounders observados \n",
    "* $U_i$ – heterogeneidade **não observada**, fixa no tempo (características intrínsecas do nível individual $i$)\n",
    "* E a chave: **eles admitem explicitamente o caminho (U_i \\to X_{it})**, i.e., $U_i$ influencia também os confounders observados. \n",
    "\n",
    "Esse caminho $U_i \\to X_{it}$ é o que mata a complacência: não é só FE linear clássico; com confusão não linear, “aplicar FE e depois DML” deixa de ser uma solução simples.\n",
    "\n",
    "\n",
    "#### Por que “demeanar e rodar DML” é perigoso?\n",
    "\n",
    "A nossa tentação natural é:\n",
    "\n",
    "1. Fazer **within transform** (***demeaning por unidade***) em ($Y$), ($D$), ($X$);\n",
    "2. Rodar DML nos dados transformados, análogo ao FE.\n",
    "\n",
    "O artigo mostra, via simulações, que:\n",
    "\n",
    "* DML em variáveis time-demeaned, à la FE, é **fortemente enviesado** quando a relação de confusão é não linear, justamente porque nesse caso o “efeito fixo aditivo” não separa bem $U_i$ de $X_{it}$. \n",
    "* Vários esquemas intuitivos que tentam “tirar” $U_i$ primeiro e depois aplicar DML falham quando há não linearidade e/ou $U_i \\to X_{it}$. \n",
    "\n",
    "Moral: **não** seguir aquele impulso de:\n",
    "\n",
    "> “Vou transformar tudo em desvio da média individual e pronto.”\n",
    "\n",
    "Econometricamente, o que a simulação mostra é:\n",
    "\n",
    "* O FE clássico funciona num mundo **paramétrico linear** com $U_i$ aditivo;\n",
    "* Quando você substitui essa fase de “ajustar por $X_{it}$” por um ML flexível dentro de DML, a estrutura additiva em $U_i$ pode não segurar, e o demeaning “bagunça” a identificação do efeito de interesse.\n",
    "\n",
    "\n",
    "#### O que é o DML + CRE (Mundlak) que eles recomendam?\n",
    "\n",
    "A solução que funciona bem nos experimentos deles é usar DML com uma adaptação **à la Mundlak (1978)**:\n",
    "\n",
    "***Idéia de CRE/Mundlak***\n",
    "\n",
    "Em painel linear tradicional, o método de **Correlated Random Effects (CRE)** diz:\n",
    "\n",
    "* Em vez de assumir $U_i$ independente de $X_{it}$, modelar:\n",
    "\n",
    "$$\n",
    "U_i = \\alpha + \\bar{X}_i'\\delta + a_i,\n",
    "$$\n",
    "\n",
    "onde $\\bar{X}_i$ são as **médias no tempo** das covariáveis de cada unidade (Mundlak).\n",
    "\n",
    "* Inserindo $\\bar{X}*i$ como regressoras, você “limpa” a correlação entre $X*{it}$ e $U_i$; o resto $a_i$ vira efeito aleatório “puro”.\n",
    "\n",
    "O artigo leva essa ideia para dentro do DML:\n",
    "\n",
    "> **Adicionar as médias por unidade $\\bar{X}_i$ como covariáveis extras nos modelos de previsão usados em DML**, tanto no modelo de outcome quanto no de tratamento/propensity. \n",
    "\n",
    "Ou seja, em vez de de-mean, você **enriquece $X_{it}$**:\n",
    "\n",
    "$$\n",
    "X_{it}^{\\text{aug}} = \\big(X_{it}, \\bar{X}_i\\big).\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### O que os autores encontram nas simulações?\n",
    "\n",
    "* DML em de-meaned data (tipo FE) → **grande viés** quando o confounding é não linear. \n",
    "* DML com CRE/Mundlak (isto é, incluindo médias de $X_{it}$ nos modelos ML) → funciona bem em vários cenários, desde que:\n",
    "\n",
    "  * **amostra grande** em relação ao número de covariáveis (porque você está duplicando o número de features).\n",
    "* Variações da forma de cross-fitting (aleatória, por tempo, por bloco) afetam pouco o viés/consistência, comparado com o problema da heterogeneidade não observada; o grande “ganho” vem de modelar $U_i$ via Mundlak. \n",
    "\n",
    "### Recomendações formais\n",
    "\n",
    "Eles explicitam quatro recomendações finais: \n",
    "\n",
    "1. **Sempre comparar FE tradicional com DML+CRE**\n",
    "\n",
    "   * Em aplicações onde hoje você usa FE, rode também DML com CRE (Mundlak) e compare os coeficientes. Diferenças grandes sugerem problemas de especificação funcional no modelo linear FE.\n",
    "\n",
    "2. **Confiar mais no DML quando $N$ é grande e $p$ é pequeno**\n",
    "\n",
    "   * Ganho de DML é maior se você tem muitas observações e um conjunto não tão gigantesco de confounders observados.\n",
    "\n",
    "3. **Não fazer cross-fitting “por unidade” se seu objetivo é modelar $U_i$**\n",
    "\n",
    "   * Dentro do algoritmo DML, quando você faz as predições ML dos termos de confusão, **não separe as unidades em folds distintos** (i.e., não usar GroupKFold por unidade no cross-fitting), porque isso impede o ML de ver a relação entre $\\bar{X}*i$ e $X*{it}$ ao longo do tempo para aquele mesmo $i$. \n",
    "   * Ou seja: **cross-fitting por observação, não por unidade**.\n",
    "\n",
    "4. **Não levar a sério os erros-padrão desses DML em painel**\n",
    "\n",
    "   * Ainda não há teoria clara para variâncias quando há **dependência em cluster (unidade) + tempo** + cross-fitting.\n",
    "   * Moral: usar esses DML em painel principalmente como **estimadores pontuais / checks de robustez**, não para inference “bonitinha” com IC 95% “oficial”. \n",
    "\n",
    "\n",
    "### Um “esqueleto” de DML em painel \n",
    "\n",
    "1. **Definir o objeto causal**\n",
    "\n",
    "   * Ex.: efeito médio de $D$ sobre a $Y$\n",
    "\n",
    "2. **Construir $X_{it}$ e $\\bar{X}_i$**\n",
    "\n",
    "   * features $X$ + suas médias por unidade $i$.\n",
    "\n",
    "3. **Rodar DML parcialmente linear** (tipo `LinearDML` ou `DML` customizado):\n",
    "\n",
    "   * Outcome model: $Y_{it} \\sim f(X_{it}, \\bar{X}_i)$ via ML.\n",
    "   * Treatment model: $D_{it} \\sim g(X_{it}, \\bar{X}_i)$ via ML.\n",
    "   * Cross-fitting: KFold ou blocos de tempo **sem separar por município**.\n",
    "   * Estimador final: regressão da pseudo-outcome na pseudo-treatment (score Neyman-ortogonal), como no DML padrão.\n",
    "\n",
    "4. **Comparar esse $\\hat{\\theta}_{DML+CRE}$ com o FE tradicional**\n",
    "\n",
    "   * FE linear clássico (demeaning) como benchmark.\n",
    "   * Diferenças grandes → suspeita de misspecificação funcional na FE.\n",
    "\n",
    "5. **Usar os erros-padrão com parcimônia**\n",
    "\n",
    "   * Conforme recomendação (4): não vender os IC como “gold standard”, por limitação teórica ainda aberta.\n",
    "\n",
    "\n",
    "### Resumo\n",
    "\n",
    "  * Não aplicar FE/demeaning antes de ML;\n",
    "  * Construir Mundlak (médias por município) para todas as covariáveis relevantes e incluí-las nos modelos;\n",
    "  * Quando quiser fazer DML causal, fazer cross-fitting por observações (ou blocos de tempo), não por unidade;\n",
    "  * Tratar os DML como estimadores pontuais robustos e usar FE como benchmark, sem confiar cegamente em SEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d31c6",
   "metadata": {},
   "source": [
    "### Aplicação em Python\n",
    "\n",
    "\n",
    "Vamos aplicar o DML aos dados em painel, incluindo as médias por unidade (Mundlak) como features adicionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74b833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "data = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/bacon_example.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd06347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome (Suicide Mortality)\n",
    "data['Y'] = data['asmrs']\n",
    "# Treatment D (Staggered treatment adoption)\n",
    "data['D'] = data['post']\n",
    "# Covariáveis - pcinc asmrh cases\n",
    "data['X1'] = data['pcinc']\n",
    "data['X2'] = data['asmrh']\n",
    "data['X3'] = data['cases']\n",
    "\n",
    "# Identificação do painel\n",
    "data['year'] = data['year'].astype(int)\n",
    "data['id'] = data['stfips'].astype('category').cat.codes + 1\n",
    "\n",
    "\n",
    "# Relative time (Tempo relativo até o tratamento - ocorre somente para os tratados)\n",
    "data['reltime'] = data['year'] - data['_nfd']\n",
    "# colocar valor zero caso tenha dados faltantes\n",
    "data['reltime'] = data['reltime'].fillna(0)\n",
    "# garantir que 'reltime' seja um inteiro\n",
    "data['reltime'] = data['reltime'].astype(int)\n",
    "\n",
    "# Generates a new column called 'ct' containing the numerics version of calendar time 'year'\n",
    "data['ct'] = data['year'] - 1964\n",
    "\n",
    "# Vamos criar a variável de grupo (cohoort) e G (Callaway-SantAnna)\n",
    "data['cohort'] = data['_nfd'] - 1965\n",
    "data['G']=data['_nfd']\n",
    "\n",
    "# control group\n",
    "data['treated'] = 0\n",
    "data.loc[data['_nfd'] > 0, 'treated'] = 1\n",
    "data['untreated_group'] = 1\n",
    "data.loc[data['treated'] == 1, 'untreated_group'] = 0\n",
    "\n",
    "# Criar uma coluna que identifica os indivíduos que nunca foram tratados (nevertreated)\n",
    "data['nevertreated'] = 0\n",
    "data.loc[data['treated'] == 0, 'nevertreated'] = 1\n",
    "\n",
    "# Criar uma coluna que identifica os indivíduos que sempre foram tratados (alwaystreated) Deve ser 1 para todos os anos após o tratamento D\n",
    "data['mean_treat'] = data.groupby('id')['D'].transform('mean')\n",
    "# Criar os sempre tratados\n",
    "data['alwaystreated'] = 0\n",
    "data.loc[(data['mean_treat'] == 1), 'alwaystreated'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f185f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Médias no tempo por unidade (Mundlak)\n",
    "group_means = data.groupby('id')[['D', 'X1', 'X2', 'X3']].transform('mean')\n",
    "group_means.columns = ['D_bar', 'X1_bar', 'X2_bar', 'X3_bar']\n",
    "\n",
    "data_cre = pd.concat([data, group_means], axis=1)\n",
    "\n",
    "# Matriz de features para o DML (níveis + médias)\n",
    "X_cre = data_cre[['X1', 'X2', 'X3', 'X1_bar', 'X2_bar', 'X3_bar', 'D_bar']]\n",
    "Y = data_cre['Y'].values\n",
    "T = data_cre['D'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefc8f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.26 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meconml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearDML\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Learner com hiperparâmetros fixados\u001b[39;00m\n\u001b[0;32m      5\u001b[0m base_learner_y \u001b[38;5;241m=\u001b[39m LGBMRegressor()\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\dml\\__init__.py:37\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) PyWhy contributors. All rights reserved.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the MIT License.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Double Machine Learning. The method uses machine learning methods to identify the\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mpart of the observed outcome and treatment that is not predictable by the controls X, W\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m(aka residual outcome and residual treatment).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    ACM Conference on Learning Theory. `<https://arxiv.org/abs/1901.09036>`_\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (DML, LinearDML, SparseLinearDML,\n\u001b[0;32m     38\u001b[0m                   KernelDML, NonParamDML)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausal_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CausalForestDML\n\u001b[0;32m     41\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDML\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearDML\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparseLinearDML\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernelDML\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNonParamDML\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCausalForestDML\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\dml\\dml.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ortho_learner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _OrthoLearner\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rlearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _RLearner\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cate_estimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (DebiasedLassoCateEstimatorMixin,\n\u001b[0;32m     21\u001b[0m                                ForestModelFinalCateEstimatorMixin,\n\u001b[0;32m     22\u001b[0m                                LinearModelFinalCateEstimatorMixin,\n\u001b[0;32m     23\u001b[0m                                StatsModelsCateEstimatorMixin,\n\u001b[0;32m     24\u001b[0m                                LinearCateEstimator)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\_ortho_learner.py:43\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (FunctionTransformer, LabelEncoder,\n\u001b[0;32m     40\u001b[0m                                    OneHotEncoder)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cate_estimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (BaseCateEstimator, LinearCateEstimator,\n\u001b[0;32m     44\u001b[0m                               TreatmentExpansionMixin)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BootstrapInference\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_deprecate_positional, check_input_arrays,\n\u001b[0;32m     47\u001b[0m                         cross_product, filter_none_kwargs, one_hot_encoder, strata_from_discrete_arrays,\n\u001b[0;32m     48\u001b[0m                         inverse_onehot, jacify_featurizer, ndim, reshape, shape, transpose)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\_cate_estimator.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BootstrapInference\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (tensordot, ndim, reshape, shape, parse_final_model_params, get_feature_names_or_default,\n\u001b[0;32m     14\u001b[0m                         inverse_onehot, Summary, get_input_columns, check_input_arrays, jacify_featurizer)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StatsModelsInference, StatsModelsInferenceDiscrete, LinearModelFinalInference, \\\n\u001b[0;32m     16\u001b[0m     LinearModelFinalInferenceDiscrete, NormalInferenceResults, GenericSingleTreatmentModelFinalInference, \\\n\u001b[0;32m     17\u001b[0m     GenericModelFinalInferenceDiscrete\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\inference\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) PyWhy contributors. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under the MIT License.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (BootstrapInference, GenericModelFinalInference, GenericSingleTreatmentModelFinalInference,\n\u001b[0;32m      5\u001b[0m                          LinearModelFinalInference, StatsModelsInference, GenericModelFinalInferenceDiscrete,\n\u001b[0;32m      6\u001b[0m                          LinearModelFinalInferenceDiscrete, StatsModelsInferenceDiscrete,\n\u001b[0;32m      7\u001b[0m                          NormalInferenceResults, EmpiricalInferenceResults,\n\u001b[0;32m      8\u001b[0m                          PopulationSummaryResults)\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBootstrapInference\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenericModelFinalInference\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenericSingleTreatmentModelFinalInference\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpiricalInferenceResults\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPopulationSummaryResults\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\inference\\_inference.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miolib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleTable\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bootstrap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BootstrapEstimator\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_extensions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StatsModelsLinearRegression\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Summary, _safe_norm_ppf, broadcast_unit_treatments,\n\u001b[0;32m     17\u001b[0m                          cross_product, inverse_onehot, ndim,\n\u001b[0;32m     18\u001b[0m                          parse_final_model_params, jacify_featurizer,\n\u001b[0;32m     19\u001b[0m                          reshape_treatmentwise_effects, shape, filter_none_kwargs)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"Options for performing inference in estimators.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\sklearn_extensions\\linear_model.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ndim, shape, reshape, _safe_norm_ppf, check_input_arrays\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression, LassoCV, MultiTaskLassoCV, Lasso, MultiTaskLasso\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\econml\\utilities.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sparse\\__init__.py:77\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m power \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28mpow\u001b[39m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m right_shift \u001b[38;5;28;01mas\u001b[39;00m bitwise_right_shift\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     78\u001b[0m     SparseArray,\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mabs\u001b[39m,\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mall\u001b[39m,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28many\u001b[39m,\n\u001b[0;32m     82\u001b[0m     asarray,\n\u001b[0;32m     83\u001b[0m     asnumpy,\n\u001b[0;32m     84\u001b[0m     astype,\n\u001b[0;32m     85\u001b[0m     broadcast_arrays,\n\u001b[0;32m     86\u001b[0m     broadcast_to,\n\u001b[0;32m     87\u001b[0m     concat,\n\u001b[0;32m     88\u001b[0m     concatenate,\n\u001b[0;32m     89\u001b[0m     dot,\n\u001b[0;32m     90\u001b[0m     einsum,\n\u001b[0;32m     91\u001b[0m     empty,\n\u001b[0;32m     92\u001b[0m     empty_like,\n\u001b[0;32m     93\u001b[0m     equal,\n\u001b[0;32m     94\u001b[0m     eye,\n\u001b[0;32m     95\u001b[0m     full,\n\u001b[0;32m     96\u001b[0m     full_like,\n\u001b[0;32m     97\u001b[0m     isfinite,\n\u001b[0;32m     98\u001b[0m     isinf,\n\u001b[0;32m     99\u001b[0m     isnan,\n\u001b[0;32m    100\u001b[0m     matmul,\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mmax\u001b[39m,\n\u001b[0;32m    102\u001b[0m     mean,\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mmin\u001b[39m,\n\u001b[0;32m    104\u001b[0m     moveaxis,\n\u001b[0;32m    105\u001b[0m     nonzero,\n\u001b[0;32m    106\u001b[0m     ones,\n\u001b[0;32m    107\u001b[0m     ones_like,\n\u001b[0;32m    108\u001b[0m     outer,\n\u001b[0;32m    109\u001b[0m     pad,\n\u001b[0;32m    110\u001b[0m     permute_dims,\n\u001b[0;32m    111\u001b[0m     prod,\n\u001b[0;32m    112\u001b[0m     reshape,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m    114\u001b[0m     squeeze,\n\u001b[0;32m    115\u001b[0m     stack,\n\u001b[0;32m    116\u001b[0m     std,\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28msum\u001b[39m,\n\u001b[0;32m    118\u001b[0m     tensordot,\n\u001b[0;32m    119\u001b[0m     zeros,\n\u001b[0;32m    120\u001b[0m     zeros_like,\n\u001b[0;32m    121\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCXS\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COO, as_coo\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sparse\\_common.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chain\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m index, mul\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m literal_unroll\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:56\u001b[0m\n\u001b[0;32m     51\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m---> 56\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:42\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m26\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.26 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Numba needs NumPy 1.26 or less"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from econml.dml import LinearDML\n",
    "\n",
    "# Learner com hiperparâmetros fixados\n",
    "base_learner_y = LGBMRegressor()\n",
    "base_learner_t = LGBMRegressor()\n",
    "\n",
    "dml_cre = LinearDML(\n",
    "    model_y=base_learner_y,\n",
    "    model_t=base_learner_t,\n",
    "    discrete_treatment=True,\n",
    "    cv=3,              # aqui está o cross-fitting do DML\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dml_cre.fit(\n",
    "    Y, T,\n",
    "    X=X_cre.values,    # aqui vão (X_it, X̄_i, D̄_i)\n",
    "    W=None\n",
    ")\n",
    "\n",
    "ate_cre = dml_cre.ate()  # estimativa do efeito médio do 'post'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b56063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (econml-env)",
   "language": "python",
   "name": "econml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
