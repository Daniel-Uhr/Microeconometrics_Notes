{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Causais de Double Machine Learning (DML) e CATEs\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* Causal Forest DML\n",
    "* Orthogonal Random Forest for Causal Inference\n",
    "\n",
    "\n",
    "## Referências\n",
    "\n",
    "**Principais:**\n",
    "* Microsoft EconML: https://econml.azurewebsites.net/\n",
    "* UBER CausalML: https://causalml.readthedocs.io/en/latest/\n",
    "* https://docs.doubleml.org/stable/index.html\n",
    "* https://github.com/MasaAsami/ReproducingDMLDiD/blob/main/notebook/Reproduction_of_DMLDiD_RO_for_NEW_SIMDATA.ipynb\n",
    "* Schmidheiny, K., & Siegloch, S. (2023). On event studies and distributed-lags in two-way fixed effects models: Identification, equivalence, and generalization. Journal of Applied Econometrics, 1- 19. https://doi.org/10.1002/jae.2971\n",
    "* Stevenson, Betsey, Wolfers, Justin, 2006. Bargaining in the shadow of the law: Divorce laws and family distress. Q. J. Econ. 121 (1), 267–288.\n",
    "* Goodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2021.03.014\n",
    "* Callaway, B. and Sant'Anna, P. H. C. (2021). Difference-in-Differences with multiple time periods. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2020.12.001\n",
    "\n",
    "**Complementares:**\n",
    "\n",
    "* Borusyak, K.; Jaravel, X. and Spiess, J. (2023). Revisiting Event Study Designs: Robust and Efficient Estimation. arXiv: https://arxiv.org/pdf/2108.12419.pdf\n",
    "* Clément deChaisemartin, Xavier d’Haultfoeuille. (2022) Difference-in-Differences Estimators of Intertemporal Treatment Effects. hal-03873903\n",
    "* Roth et al. (2022) What’s Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature. https://www.jonathandroth.com/assets/files/DiD_Review_Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução\n",
    "\n",
    "Vimos o processo de ortogonalização e como obter o DML. O DML é um estimador de efeito causal que utiliza machine learning para estimar o efeito causal de um tratamento em um conjunto de dados. O DML é uma extensão do método de regressão tradicional, que permite lidar com variáveis de confusão e heterogeneidade não observada.\n",
    "\n",
    "Em termos de aplicação prática você pode estar se perguntando: \n",
    "\n",
    "* ***\"Quando devo usar o DML?\"*** \n",
    "\n",
    "Então, você deve usar o DML com score ortogonal quando:\n",
    "\n",
    "* Causalidade é seu objetivo principal,\n",
    "\n",
    "* Alta dimensão / não-linearidade é um desafio,\n",
    "\n",
    "* Você quer robustez estatística sem abrir mão da flexibilidade do ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Forest DML\n",
    "\n",
    "Athey & Wager (2018) propose um método de aprendizado de máquina para estimar efeitos heterogêneos de tratamento (CATEs) usando florestas aleatórias. O método é chamado de Causal Forest e é uma extensão do Random Forest.\n",
    "\n",
    "* Athey, S., & Wager, S. (2018). Estimation and Inference of Heterogeneous Treatment Effects using Random Forests. Journal of the American Statistical Association, 113(523), 230-248. https://doi.org/10.1080/01621459.2017.1319839\n",
    "\n",
    "**Abstract:**\n",
    "\n",
    "*\"[...] desenvolvemos uma floresta causal não paramétrica para estimar efeitos heterogêneos de tratamento que estende o algoritmo de floresta aleatória amplamente utilizado de Breiman. Na estrutura de resultados potenciais com ausência de confusão, mostramos que as florestas causais são consistentes pontualmente para o efeito real do tratamento e têm uma distribuição amostral assintoticamente gaussiana e centrada. Também discutimos um método prático para construir intervalos de confiança assintóticos para o efeito real do tratamento, centrados nas estimativas da floresta causal. Nossos resultados teóricos baseiam-se em uma teoria gaussiana genérica para uma grande família de algoritmos de floresta aleatória. Até onde sabemos, este é o primeiro conjunto de resultados que permite que qualquer tipo de floresta aleatória, incluindo florestas de classificação e regressão, seja usado para inferência estatística comprovadamente válida. Em experimentos, constatamos que as florestas causais são substancialmente mais poderosas do que os métodos clássicos baseados em correspondência de vizinho mais próximo, especialmente na presença de covariáveis ​​irrelevantes. [...]\"*\n",
    "\n",
    "\n",
    "***Visão Geral***\n",
    "\n",
    "Estimar o efeito médio condicional do tratamento (**CATE**):\n",
    "\n",
    "$$\n",
    "\\theta(x) = \\mathbb{E}[Y(1) - Y(0) \\mid X = x]\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $ Y(1), Y(0) $: resultados potenciais\n",
    "- $ X $: covariáveis observadas\n",
    "- $ D \\in \\{0, 1\\} $: indicador de tratamento observado\n",
    "- $ Y = D Y(1) + (1 - D) Y(0) $: resultado observado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hipóteses de Identificação***\n",
    "\n",
    "Para identificar $ \\theta(x) $, precisamos das seguintes condições:\n",
    "\n",
    "- **Ignorabilidade condicional (unconfoundedness)**:\n",
    "  \n",
    "$$\n",
    "(Y(1), Y(0)) \\perp D \\mid X\n",
    "$$\n",
    "\n",
    "- **Suporte comum (overlap)**:\n",
    "\n",
    "$$\n",
    "0 < P(D=1 \\mid X=x) < 1 \\quad \\text{para todo } x\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***O Estimador de DML com Florestas Causais***\n",
    "\n",
    "A ideia de **Double Machine Learning (DML)** é: \n",
    "\n",
    "- Usar Machine Learning para estimar as funções \"nuisance\" de alta dimensão: regressões condicionais e propensity score.\n",
    "- Substituí-las num estimador ortogonal a essas funções, garantindo robustez e inferência válida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Etapa 1: Estimação das Funções Auxiliares***\n",
    "\n",
    "Estime:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_1(x) = \\mathbb{E}[Y \\mid X=x, D=1]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_0(x) = \\mathbb{E}[Y \\mid X=x, D=0]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{e}(x) = P(D=1 \\mid X=x)\n",
    "$$\n",
    "\n",
    "Com qualquer algoritmo de ML (ex: Random Forest, Lasso, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Etapa 2: Construção do Score Ortogonal (Neyman Orthogonal Score)***\n",
    "\n",
    "$$\n",
    "\\psi(W_i; \\theta, \\eta) = \\left( \\frac{D_i - \\hat{e}(X_i)}{\\hat{e}(X_i)(1-\\hat{e}(X_i))} \\right) \\cdot (Y_i - \\hat{\\mu}_{D_i}(X_i)) + \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) - \\theta(X_i)\n",
    "$$\n",
    "\n",
    "A condição de ortogonalidade:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbb{E}[\\psi(W; \\theta, \\eta)]}{\\partial \\eta} \\Big|_{\\eta=\\eta_0} = 0\n",
    "$$\n",
    "\n",
    "garante que pequenos erros em $ \\eta $ (nuisance functions) não impactam assintoticamente a inferência sobre $ \\theta $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicação Detalhada:**\n",
    "\n",
    "O que cada termo representa?\n",
    "\n",
    "| Símbolo | Significado |\n",
    "|:--------|:------------|\n",
    "| $ W_i $ | Todas as variáveis observadas: $ (Y_i, D_i, X_i) $ |\n",
    "| $ \\theta $ | Função alvo: o efeito condicional que queremos estimar, $ \\theta(x) = \\mathbb{E}[Y(1) - Y(0) \\mid X=x] $ |\n",
    "| $ \\eta $ | Conjunto de funções \"nuisance\": $ (\\mu_0(x), \\mu_1(x), e(x)) $ |\n",
    "| $ D_i $ | Variável de tratamento observada (0 ou 1) |\n",
    "| $ Y_i $ | Resultado observado |\n",
    "| $ \\hat{e}(X_i) $ | Propensity score estimado: $ \\mathbb{P}(D=1 \\mid X=x) $ |\n",
    "| $ \\hat{\\mu}_1(X_i) $, $ \\hat{\\mu}_0(X_i) $ | Resultados esperados estimados sob tratamento e controle |\n",
    "\n",
    "***1. Primeiro termo: resíduo ajustado pelo propensity score***\n",
    "\n",
    "$$\n",
    "\\left( \\frac{D_i - \\hat{e}(X_i)}{\\hat{e}(X_i)(1-\\hat{e}(X_i))} \\right) \\cdot (Y_i - \\hat{\\mu}_{D_i}(X_i))\n",
    "$$\n",
    "\n",
    "- $ D_i - \\hat{e}(X_i) $ → diferença entre o tratamento observado e a propensão prevista.\n",
    "- $ Y_i - \\hat{\\mu}_{D_i}(X_i) $ → resíduo do resultado observado em relação ao previsto.\n",
    "- Dividimos pela variância binomial $ \\hat{e}(X_i)(1-\\hat{e}(X_i)) $ para normalizar.\n",
    "\n",
    "Ou seja, este termo ajusta o erro entre observado e previsto, ponderado pela incerteza de receber o tratamento.\n",
    "\n",
    "\n",
    "***2. Segundo termo: diferença de médias preditas entre tratado e controle***\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)\n",
    "$$\n",
    "\n",
    "- Representa a diferença nos valores esperados do resultado sob tratamento e sob controle, para o mesmo $ X_i $. Ele captura o efeito esperado com base apenas nos modelos auxiliares.\n",
    "\n",
    "\n",
    "***3. Terceiro termo: subtração do parâmetro-alvo***\n",
    "\n",
    "$$\n",
    "-\\theta(X_i)\n",
    "$$\n",
    "\n",
    "- Remove $ \\theta(X_i) $ para formar uma equação cujo valor esperado é zero quando $ \\theta $ está corretamente estimado.\n",
    "\n",
    "**Resumo**: Força o momento a ser \"zero\" na verdade populacional.\n",
    "\n",
    "***Intuição Geral***\n",
    "\n",
    "**Essa função $ \\psi $** é um **score ortogonal**:\n",
    "\n",
    "- É construída para ser **insensível a pequenos erros na estimação de $ \\mu_0, \\mu_1, e $**.\n",
    "- Quando resolvemos $ \\mathbb{E}[\\psi(W_i; \\theta, \\eta)] = 0 $, obtemos um estimador consistente para $ \\theta(X) $.\n",
    "- O **primeiro pedaço** compensa o viés de seleção no tratamento (propensity correction).\n",
    "- O **segundo pedaço** usa predições para corrigir viés diretamente.\n",
    "- O **terceiro pedaço** ajusta para encontrar $ \\theta(X) $ de forma que o momento seja zero.\n",
    "- A função $ \\psi $ torna possível usar Machine Learning para estimar funções auxiliares sem sacrificar inferência causal válida.\n",
    "- Pequenos erros nas funções de regressão ou propensity não prejudicam a consistência de $ \\theta(x) $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propriedades da Causal Forest:**\n",
    "\n",
    "- **Consistência** sob condições regulares (ex: suavidade de $ \\theta(x) $, honestidade das árvores).\n",
    "- **Normalidade assintótica ponto a ponto**:\n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}(x) - \\theta(x)) \\overset{d}{\\to} N(0, \\sigma^2(x))\n",
    "$$\n",
    "\n",
    "\n",
    "***Teoria Asintótica***\n",
    "\n",
    "Suponha:\n",
    "\n",
    "- Estimação de $ \\hat{\\mu}_0, \\hat{\\mu}_1, \\hat{e} $ convergente a taxas $ o_p(n^{-1/4}) $,\n",
    "- Regularidade do modelo causal,\n",
    "- Cross-fitting.\n",
    "\n",
    "Então, o estimador $ \\hat{\\theta}(x) $ obtido por DML satisfaz:\n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}(x) - \\theta(x)) \\overset{d}{\\to} N(0, V(x))\n",
    "$$\n",
    "\n",
    "Este resultado permite construir **intervalos de confiança válidos**, algo que métodos de Machine Learning puros geralmente não permitem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Quando usar Causal Forest?***\n",
    "\n",
    "Ela é especialmente útil em DML por dois motivos:\n",
    "\n",
    "- Desenha partições do espaço de $ X $ de forma adaptada ao problema de inferência causal (não apenas para predição).\n",
    "- Fornece um estimador localmente adaptativo de $ \\theta(x) $ com inferência válida.\n",
    "\n",
    "\n",
    "O DML com Causal Forest:\n",
    "\n",
    "- Combina **flexibilidade não paramétrica** com **rigor estatístico**.\n",
    "- Estima **efeitos heterogêneos**, essencial para avaliações de políticas públicas, economia do trabalho, entre outros.\n",
    "- Permite usar ferramentas modernas (ML) **sem abrir mão da fundamentação clássica da inferência causal**.\n",
    "\n",
    "***Quando não usar Causal Forest?***\n",
    "\n",
    "- Se o tratamento é homogêneo e a heterogeneidade não interessa.\n",
    "- Se o número de observações é muito pequeno (árvores precisam de dados para dividir bem).\n",
    "- Se a interpretação de $ \\theta(x) $ para cada indivíduo não for relevante no seu contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Orthogonal Random Forest for Causal Inference***\n",
    "\n",
    "Oprescu, Syrgkanis e Wu (2019)\n",
    "\n",
    "Quando usar o ORF em vez do Causal Forest?\n",
    "\n",
    "Situação\tMelhor escolha\n",
    "Precisa de máxima robustez a erros de estimação auxiliar\t✅ ORF\n",
    "Quer CATEs em alta dimensão com inferência\t✅ ORF\n",
    "Precisa de interpretação mais simples, rápida\tCausal Forest\n",
    "O ORF é mais rigoroso teoricamente do que o Causal Forest \"puro\", mas é também mais pesado computacionalmente.\n",
    "\n",
    "Orthogonal Random Forest for Causal Inference\"\n",
    "📜 Oprescu, Syrgkanis, Wu (2019)\n",
    "\n",
    "Este é o artigo central que apresenta o modelo de Orthogonal Random Forest.\n",
    "\n",
    "Introduz a ideia de combinar:\n",
    "\n",
    "Score Neyman-ortogonal (como no DML)\n",
    "\n",
    "Random Forests honestas e adaptativas para aprender o CATE \n",
    "𝜃\n",
    "(\n",
    "𝑥\n",
    ")\n",
    "θ(x).\n",
    "\n",
    "Mostra teoria de:\n",
    "\n",
    "Consistência ponto a ponto\n",
    "\n",
    "Normalidade assintótica\n",
    "\n",
    "Taxas de convergência em alta dimensão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning (DRML)\n",
    "\n",
    "O estimador duplamente robusto para o Conditional Average Treatment Effect (CATE) combina modelos de *Outcome Regression* e de *escore de propensão* para fornecer estimativas consistentes, mesmo que um dos modelos seja mal especificado. A fórmula geral é:\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}(X_i) = \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) + \\frac{D_i - \\hat{p}(X_i)}{\\hat{p}(X_i)(1 - \\hat{p}(X_i))}(Y_i - \\hat{\\mu}_{D_i}(X_i)),\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $ \\hat{\\mu}_d(X_i) = \\mathbb{E}[Y_i \\mid X_i, D_i = d] $ é a estimativa do desfecho esperado para o tratamento $ d $ dado $ X_i $\n",
    "- $ \\hat{p}(X_i) = \\mathbb{P}(D_i = 1 \\mid X_i) $ é a estimativa do escore de propensão, ou seja, a probabilidade de receber o tratamento dado $ X_i $\n",
    "- $ D_i $ é a variável indicadora de tratamento (1 se tratado, 0 caso contrário),\n",
    "- $ Y_i $ é o desfecho observado.\n",
    "\n",
    "---\n",
    "\n",
    "### Processo de Estimação\n",
    "\n",
    "#### Primeiro Estágio: Estimação das Funções Incômodas\n",
    "\n",
    "1. **Modelo de Desfecho ($ \\hat{\\mu}_d(X_i) $)**:  \n",
    "   Estima-se a relação entre as covariáveis $ X_i $ e o desfecho $ Y_i $ para cada nível de tratamento $ d $.  \n",
    "   Técnicas de aprendizado de máquina, como regressão linear, árvores de decisão ou redes neurais, podem ser utilizadas.\n",
    "\n",
    "2. **Modelo de Escore de Propensão ($ \\hat{p}(X_i) $)**:  \n",
    "   Estima-se a probabilidade de um indivíduo receber o tratamento dado $ X_i $.  \n",
    "   Modelos como regressão logística ou métodos de classificação podem ser aplicados.\n",
    "\n",
    "#### Segundo Estágio: Cálculo do Estimador Duplamente Robusto\n",
    "\n",
    "Utiliza-se a fórmula acima para calcular $ \\hat{\\tau}(X_i) $ para cada indivíduo, combinando as estimativas dos modelos de desfecho e de escore de propensão.\n",
    "\n",
    "---\n",
    "\n",
    "### Propriedades do Estimador Duplamente Robusto\n",
    "\n",
    "1. **Robustez Dupla**:  \n",
    "   O estimador $ \\hat{\\tau}(X_i) $ é consistente se pelo menos um dos modelos (desfecho ou escore de propensão) for corretamente especificado.  \n",
    "   Isso significa que erros em um modelo podem ser compensados pela precisão do outro.\n",
    "\n",
    "2. **Eficiência**:  \n",
    "   Quando ambos os modelos são corretamente especificados, o estimador atinge eficiência assintótica, resultando em estimativas mais precisas.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementação Prática\n",
    "\n",
    "Na prática, é comum utilizar técnicas de *cross-fitting* para evitar viés de superajuste. O procedimento envolve dividir os dados em folds, ajustando os modelos de desfecho e escore de propensão em uma parte dos dados e validando em outra, garantindo que as estimativas sejam independentes dos dados usados para ajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o Conditional Average Treatment Effect (CATE) utiliza uma abordagem duplamente robusta para controlar o viés de seleção do tratamento. O estimador segue um processo de dois estágios: no primeiro, estimam-se as funções incômodas usando técnicas de *crossfitting*, e, no segundo, estima-se o CATE a partir das funções ajustadas.\n",
    "\n",
    "O estimador pode ser descrito pelas seguintes equações:\n",
    "\n",
    "#### Estimativa Duplamente Robusta para $ Y_{t}^{DR} $\n",
    "\n",
    "$$ \\hat{Y}_{i,t}^{DR} = \\mu_t(X_i, W_i) + \\frac{D_i}{\\hat{p}_t(X_i, W_i)} \\cdot (Y_i - \\mu_t(X_i, W_i)), $$\n",
    "\n",
    "onde:\n",
    "- $ \\mu_t(X_i, W_i) = \\mathbb{E}[Y | X_i, W_i, T_i = t] $ é a função de resultado condicional,\n",
    "- $ \\hat{p}_t(X_i, W_i) = \\mathbb{P}[T_i = t | X_i, W_i] $ é o escore de propensão condicional,\n",
    "- $ D_i = 1[T_i = t] $ é uma variável indicadora para o tratamento $ t $\n",
    "\n",
    "#### Estimativa do CATE\n",
    "\n",
    "$$ \\theta_t(X_i) = \\mathbb{E}[\\hat{Y}_{i,t}^{DR} - \\hat{Y}_{i,0}^{DR} | X_i], $$\n",
    "\n",
    "onde $ \\hat{Y}_{i,0}^{DR} $ é o contrafactual correspondente ao tratamento de referência $ t = 0 $\n",
    "\n",
    "---\n",
    "\n",
    "### Processo de Estimação\n",
    "\n",
    "1. **Primeiro estágio**:  \n",
    "   Estimam-se as funções incômodas $ \\mu_t(X, W) $ e $ \\hat{p}_t(X, W) $ usando técnicas de aprendizado de máquina em um esquema de *crossfitting* para evitar viés.\n",
    "\n",
    "2. **Segundo estágio**:  \n",
    "   Substitui-se as estimativas obtidas no primeiro estágio nas equações acima e calcula-se o CATE ajustado para cada tratamento $ t $ resolvendo a regressão de $ \\hat{Y}_{i,t}^{DR} - \\hat{Y}_{i,0}^{DR} $ sobre $ X_i $\n",
    "\n",
    "---\n",
    "\n",
    "### Observações\n",
    "\n",
    "- **Robustez**: A abordagem é robusta contra erros na especificação de $ \\mu_t(X, W) $ ou $ \\hat{p}_t(X, W) $, desde que pelo menos uma delas seja corretamente especificada.\n",
    "- **Viés residual**: A precisão da estimativa depende fortemente da qualidade das funções incômodas ajustadas no primeiro estágio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o CATE usa técnicas de correção duplamente robustas para controlar o viés de seleção do tratamento. O estimador segue um processo de dois estágios, onde um conjunto de funções incômodas (não especificado, mas que deve ser considerado no modelo) são estimadas no primeiro estágio de uma maneira de *crossfitting* e no segundo estágio estima-se o modelo CATE. \n",
    "\n",
    "Ou seja, neste estimador, o CATE é estimado usando as seguintes equações:\n",
    "\n",
    "$$ Y_{i,t}^{DR} = E[Y|X_{i}, W_{i}, T_{i}=t] + \\frac{Y_{i} - E[Y|X_{i}, W_{i}, T_{i}=t]}{Pr[T_{i}=t|X_{i}, W_{i}]}.1[T_{i}=t] $$\n",
    " \n",
    "Então,\n",
    "\n",
    "$$ E[Y_{i,t}^{DR}-Y_{i,0}^{DR}|X_{i}] = \\theta_{t}(X_{i}) $$\n",
    "\n",
    "\n",
    "Então, se estimarmos as funções $E[Y|X, W, T]$ e $Pr[T|X, W]$ no primeiro estágio, podemos estimar o segundo estágio CATE para cada tratamento $t$, rodando uma regressão $Y_{i,t}^{DR} - Y_{i,0}^{DR}$ sobre $X$.\n",
    "\n",
    "Os possíveis problemas de estimar a função do propensity score recai na definição arbitrária do modelo de \"classificação\". A segunda função é uma regressão simples em $Y$.\n",
    "\n",
    "\n",
    "https://econml.azurewebsites.net/_autosummary/econml.dr.DRLearner.html\n",
    "\n",
    "\n",
    "Outros Modelos Duplamente robustos similares podem ser aplicados:\n",
    "* econml.dr.DRLearner (visto aqui)\n",
    "  * Estimador CATE que usa técnicas de correção duplamente robustas para contabilizar o viés de seleção em variáveis observáveis no tratamento.\n",
    "* econml.dr.LinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Linear em um conjunto de recursos de baixa dimensão.\n",
    "* econml.dr.SparseLinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Lasso Desviada.\n",
    "* econml.dr.ForestDRLearner\n",
    "  * Instância do DRLearner com a RegressionForest como modelo final, para permitir inferência não paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Doble Robust Machine Learning Difference-in-Differences (DRMLDiD)\n",
    "\n",
    "**É possivel utilizar DML com dados em painel?**\n",
    "\n",
    "Antes de avançar para o DRMLDiD, vamos primeiro entender como o DML pode ser aplicado a dados em painel (DMLDiD).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Vamos considerar o efeito do homogêneo do tratamento em um painel de dados. No estilo de Sant´Anna e Zhao (2020).\n",
    "\n",
    "Os modelos de diferença em diferenças (DID) implementados no pacote focam no caso de tratamento binário com dois períodos de tratamento. Adotando a notação de Sant'Anna e Zhao (2020) , deixe ser $Y_{it}$ o resultado de interesse para a unidade $i$ no tempo $t$. Além disso, deixe $D_{it}=1$ indicar se unidade $i$ é tratada antes do tempo $t$ (de outra forma $D_{it}=0$). Como todas as unidades começam como não tratadas ($D_{it}=0$), definir $D_{i0}=0$. Com base na notação de resultado potencial, denote $Y_{it}(1)$ como resultado da unidade $i$ no tempo $t$ se a unidade não recebeu tratamento até o momento $t$ e analogamente para $Y_{it}(0)$ com tratamento. Consequentemente, o resultado observado para a unidade $i$ no tempo $t$ é $Y_{it}=Y_{it}(1)D_{it}+Y_{it}(0)(1-D_{it})$. Além disso, deixe $X_{it}$ ser um vetor de covariáveis ​​de pré-tratamento.\n",
    "\n",
    "O parâmetro de interesse é o efeito médio do tratamento no indivíduo tratado (ATTE). \n",
    "\n",
    "$$ \\theta_{ATTE} = E[Y_{i1}(1) - Y_{i1}(0)|D_{it}=1]$$\n",
    "\n",
    "As suposições de identificação correspondentes são:\n",
    "* (Cond.) Tendências paralelas: $Y_{it}(1), Y_{it}(0) \\perp D_{it}|X_{it}$ para $t=1,2$.\n",
    "* Sobreposição: $0 < P(D_{it}=1|X_{it}) < 1$ para $t=1,2$.\n",
    "\n",
    "\n",
    "Se os dados do painel estiverem disponíveis, as observações são consideradas iid. de forma ($Y_{i0},Y_{i1},D_{i},X_{i}$). Obseve que a diferença $\\Delta Y_{i} = Y_{i1} - Y_{i0}$ tem que ser definida como o resultado yno DoubleMLDataobjeto.\n",
    "\n",
    "O DoubleMLIDID implementa modelos de diferença em diferenças para dados de painel. A estimativa é conduzida por meio de seu fit() método:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLDID Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['Z1', 'Z2', 'Z3', 'Z4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 500\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: observational\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: RandomForestRegressor(max_depth=5, min_samples_leaf=5)\n",
      "Learner ml_m: RandomForestClassifier(max_depth=5, min_samples_leaf=5)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_g0 RMSE: [[16.27429763]]\n",
      "Learner ml_g1 RMSE: [[13.35731523]]\n",
      "Classification:\n",
      "Learner ml_m Log Loss: [[0.66601815]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "d -2.840718  1.760386 -1.613691  0.106595 -6.291011  0.609575\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "ml_g = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "ml_m = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "np.random.seed(42)\n",
    "data = make_did_SZ2020(n_obs=500, return_type='DataFrame')\n",
    "obj_dml_data = dml.DoubleMLData(data, 'y', 'd')\n",
    "dml_did_obj = dml.DoubleMLDID(obj_dml_data, ml_g, ml_m)\n",
    "\n",
    "print(dml_did_obj.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o CATE usa técnicas de correção duplamente robustas para controlar o viés de seleção do tratamento. O estimador segue um processo de dois estágios, onde um conjunto de funções incômodas (não especificado, mas que deve ser considerado no modelo) são estimadas no primeiro estágio de uma maneira de *crossfitting* e no segundo estágio estima-se o modelo CATE. \n",
    "\n",
    "Ou seja, neste estimador, o CATE é estimado usando as seguintes equações:\n",
    "\n",
    "$$ Y_{i,t}^{DR} = E[Y|X_{i}, W_{i}, T_{i}=t] + \\frac{Y_{i} - E[Y|X_{i}, W_{i}, T_{i}=t]}{Pr[T_{i}=t|X_{i}, W_{i}]}.1[T_{i}=t] $$\n",
    " \n",
    "Então,\n",
    "\n",
    "$$ E[Y_{i,t}^{DR}-Y_{i,0}^{DR}|X_{i}] = \\theta_{t}(X_{i}) $$\n",
    "\n",
    "\n",
    "Então, se estimarmos as funções $E[Y|X, W, T]$ e $Pr[T|X, W]$ no primeiro estágio, podemos estimar o segundo estágio CATE para cada tratamento $t$, rodando uma regressão $Y_{i,t}^{DR} - Y_{i,0}^{DR}$ sobre $X$.\n",
    "\n",
    "Os possíveis problemas de estimar a função do propensity score recai na definição arbitrária do modelo de \"classificação\". A segunda função é uma regressão simples em $Y$.\n",
    "\n",
    "\n",
    "https://econml.azurewebsites.net/_autosummary/econml.dr.DRLearner.html\n",
    "\n",
    "\n",
    "Outros Modelos Duplamente robustos similares podem ser aplicados:\n",
    "* econml.dr.DRLearner (visto aqui)\n",
    "  * Estimador CATE que usa técnicas de correção duplamente robustas para contabilizar o viés de seleção em variáveis observáveis no tratamento.\n",
    "* econml.dr.LinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Linear em um conjunto de recursos de baixa dimensão.\n",
    "* econml.dr.SparseLinearDRLearner\n",
    "  * Caso especial em DRLearner que o estágio final é uma Regressão Lasso Desviada.\n",
    "* econml.dr.ForestDRLearner\n",
    "  * Instância do DRLearner com a RegressionForest como modelo final, para permitir inferência não paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "#### Resumo Comparativo: DML vs DRML\n",
    "\n",
    "* DML: Foca na remoção de viés através de uma abordagem em dois estágios, utilizando previsões de aprendizado de máquina e resíduos. Busca a ortogonalidade entre o tratamento e o desfecho.\n",
    "* DRML: Utiliza a ponderação de probabilidade inversa e a modelagem do desfecho para obter estimativas robustas. É duplamente robusta porque requer que apenas um dos dois modelos esteja corretamente especificado.\n",
    "\n",
    "Ambas as metodologias são úteis em inferência causal e se beneficiam da flexibilidade e poder dos métodos de aprendizado de máquina, mas cada uma tem suas especificidades e contextos de aplicação onde são mais adequadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
