{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Causais de Double Machine Learning (DML) e CATEs\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conte√∫do\n",
    "\n",
    "* Causal Forest DML\n",
    "* Orthogonal Random Forest for Causal Inference\n",
    "\n",
    "\n",
    "## Refer√™ncias\n",
    "\n",
    "**Principais:**\n",
    "* Microsoft EconML: https://econml.azurewebsites.net/\n",
    "* UBER CausalML: https://causalml.readthedocs.io/en/latest/\n",
    "* https://docs.doubleml.org/stable/index.html\n",
    "* https://github.com/MasaAsami/ReproducingDMLDiD/blob/main/notebook/Reproduction_of_DMLDiD_RO_for_NEW_SIMDATA.ipynb\n",
    "* Schmidheiny, K., & Siegloch, S. (2023). On event studies and distributed-lags in two-way fixed effects models: Identification, equivalence, and generalization. Journal of Applied Econometrics, 1- 19. https://doi.org/10.1002/jae.2971\n",
    "* Stevenson, Betsey, Wolfers, Justin, 2006. Bargaining in the shadow of the law: Divorce laws and family distress. Q. J. Econ. 121 (1), 267‚Äì288.\n",
    "* Goodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2021.03.014\n",
    "* Callaway, B. and Sant'Anna, P. H. C. (2021). Difference-in-Differences with multiple time periods. Journal of Econometrics. https://doi.org/10.1016/j.jeconom.2020.12.001\n",
    "\n",
    "**Complementares:**\n",
    "\n",
    "* Borusyak, K.; Jaravel, X. and Spiess, J. (2023). Revisiting Event Study Designs: Robust and Efficient Estimation. arXiv: https://arxiv.org/pdf/2108.12419.pdf\n",
    "* Cl√©ment deChaisemartin, Xavier d‚ÄôHaultfoeuille. (2022) Difference-in-Differences Estimators of Intertemporal Treatment Effects. hal-03873903\n",
    "* Roth et al. (2022) What‚Äôs Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature. https://www.jonathandroth.com/assets/files/DiD_Review_Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdu√ß√£o\n",
    "\n",
    "Vimos o processo de ortogonaliza√ß√£o e como obter o DML. O DML √© um estimador de efeito causal que utiliza machine learning para estimar o efeito causal de um tratamento em um conjunto de dados. O DML √© uma extens√£o do m√©todo de regress√£o tradicional, que permite lidar com vari√°veis de confus√£o e heterogeneidade n√£o observada.\n",
    "\n",
    "Em termos de aplica√ß√£o pr√°tica voc√™ pode estar se perguntando: \n",
    "\n",
    "* ***\"Quando devo usar o DML?\"*** \n",
    "\n",
    "Ent√£o, voc√™ deve usar o DML com score ortogonal quando:\n",
    "\n",
    "* Causalidade √© seu objetivo principal,\n",
    "\n",
    "* Alta dimens√£o / n√£o-linearidade √© um desafio,\n",
    "\n",
    "* Voc√™ quer robustez estat√≠stica sem abrir m√£o da flexibilidade do ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Forest DML\n",
    "\n",
    "Athey & Wager (2018) propose um m√©todo de aprendizado de m√°quina para estimar efeitos heterog√™neos de tratamento (CATEs) usando florestas aleat√≥rias. O m√©todo √© chamado de Causal Forest e √© uma extens√£o do Random Forest.\n",
    "\n",
    "* Athey, S., & Wager, S. (2018). Estimation and Inference of Heterogeneous Treatment Effects using Random Forests. Journal of the American Statistical Association, 113(523), 230-248. https://doi.org/10.1080/01621459.2017.1319839\n",
    "\n",
    "**Abstract:**\n",
    "\n",
    "*\"[...] desenvolvemos uma floresta causal n√£o param√©trica para estimar efeitos heterog√™neos de tratamento que estende o algoritmo de floresta aleat√≥ria amplamente utilizado de Breiman. Na estrutura de resultados potenciais com aus√™ncia de confus√£o, mostramos que as florestas causais s√£o consistentes pontualmente para o efeito real do tratamento e t√™m uma distribui√ß√£o amostral assintoticamente gaussiana e centrada. Tamb√©m discutimos um m√©todo pr√°tico para construir intervalos de confian√ßa assint√≥ticos para o efeito real do tratamento, centrados nas estimativas da floresta causal. Nossos resultados te√≥ricos baseiam-se em uma teoria gaussiana gen√©rica para uma grande fam√≠lia de algoritmos de floresta aleat√≥ria. At√© onde sabemos, este √© o primeiro conjunto de resultados que permite que qualquer tipo de floresta aleat√≥ria, incluindo florestas de classifica√ß√£o e regress√£o, seja usado para infer√™ncia estat√≠stica comprovadamente v√°lida. Em experimentos, constatamos que as florestas causais s√£o substancialmente mais poderosas do que os m√©todos cl√°ssicos baseados em correspond√™ncia de vizinho mais pr√≥ximo, especialmente na presen√ßa de covari√°veis ‚Äã‚Äãirrelevantes. [...]\"*\n",
    "\n",
    "\n",
    "***Vis√£o Geral***\n",
    "\n",
    "Estimar o efeito m√©dio condicional do tratamento (**CATE**):\n",
    "\n",
    "$$\n",
    "\\theta(x) = \\mathbb{E}[Y(1) - Y(0) \\mid X = x]\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $ Y(1), Y(0) $: resultados potenciais\n",
    "- $ X $: covari√°veis observadas\n",
    "- $ D \\in \\{0, 1\\} $: indicador de tratamento observado\n",
    "- $ Y = D Y(1) + (1 - D) Y(0) $: resultado observado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hip√≥teses de Identifica√ß√£o***\n",
    "\n",
    "Para identificar $ \\theta(x) $, precisamos das seguintes condi√ß√µes:\n",
    "\n",
    "- **Ignorabilidade condicional (unconfoundedness)**:\n",
    "  \n",
    "$$\n",
    "(Y(1), Y(0)) \\perp D \\mid X\n",
    "$$\n",
    "\n",
    "- **Suporte comum (overlap)**:\n",
    "\n",
    "$$\n",
    "0 < P(D=1 \\mid X=x) < 1 \\quad \\text{para todo } x\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***O Estimador de DML com Florestas Causais***\n",
    "\n",
    "A ideia de **Double Machine Learning (DML)** √©: \n",
    "\n",
    "- Usar Machine Learning para estimar as fun√ß√µes \"nuisance\" de alta dimens√£o: regress√µes condicionais e propensity score.\n",
    "- Substitu√≠-las num estimador ortogonal a essas fun√ß√µes, garantindo robustez e infer√™ncia v√°lida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Etapa 1: Estima√ß√£o das Fun√ß√µes Auxiliares***\n",
    "\n",
    "Estime:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_1(x) = \\mathbb{E}[Y \\mid X=x, D=1]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_0(x) = \\mathbb{E}[Y \\mid X=x, D=0]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{e}(x) = P(D=1 \\mid X=x)\n",
    "$$\n",
    "\n",
    "Com qualquer algoritmo de ML (ex: Random Forest, Lasso, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Etapa 2: Constru√ß√£o do Score Ortogonal (Neyman Orthogonal Score)***\n",
    "\n",
    "$$\n",
    "\\psi(W_i; \\theta, \\eta) = \\left( \\frac{D_i - \\hat{e}(X_i)}{\\hat{e}(X_i)(1-\\hat{e}(X_i))} \\right) \\cdot (Y_i - \\hat{\\mu}_{D_i}(X_i)) + \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) - \\theta(X_i)\n",
    "$$\n",
    "\n",
    "A condi√ß√£o de ortogonalidade:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbb{E}[\\psi(W; \\theta, \\eta)]}{\\partial \\eta} \\Big|_{\\eta=\\eta_0} = 0\n",
    "$$\n",
    "\n",
    "garante que pequenos erros em $ \\eta $ (nuisance functions) n√£o impactam assintoticamente a infer√™ncia sobre $ \\theta $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explica√ß√£o Detalhada:**\n",
    "\n",
    "O que cada termo representa?\n",
    "\n",
    "| S√≠mbolo | Significado |\n",
    "|:--------|:------------|\n",
    "| $ W_i $ | Todas as vari√°veis observadas: $ (Y_i, D_i, X_i) $ |\n",
    "| $ \\theta $ | Fun√ß√£o alvo: o efeito condicional que queremos estimar, $ \\theta(x) = \\mathbb{E}[Y(1) - Y(0) \\mid X=x] $ |\n",
    "| $ \\eta $ | Conjunto de fun√ß√µes \"nuisance\": $ (\\mu_0(x), \\mu_1(x), e(x)) $ |\n",
    "| $ D_i $ | Vari√°vel de tratamento observada (0 ou 1) |\n",
    "| $ Y_i $ | Resultado observado |\n",
    "| $ \\hat{e}(X_i) $ | Propensity score estimado: $ \\mathbb{P}(D=1 \\mid X=x) $ |\n",
    "| $ \\hat{\\mu}_1(X_i) $, $ \\hat{\\mu}_0(X_i) $ | Resultados esperados estimados sob tratamento e controle |\n",
    "\n",
    "***1. Primeiro termo: res√≠duo ajustado pelo propensity score***\n",
    "\n",
    "$$\n",
    "\\left( \\frac{D_i - \\hat{e}(X_i)}{\\hat{e}(X_i)(1-\\hat{e}(X_i))} \\right) \\cdot (Y_i - \\hat{\\mu}_{D_i}(X_i))\n",
    "$$\n",
    "\n",
    "- $ D_i - \\hat{e}(X_i) $ ‚Üí diferen√ßa entre o tratamento observado e a propens√£o prevista.\n",
    "- $ Y_i - \\hat{\\mu}_{D_i}(X_i) $ ‚Üí res√≠duo do resultado observado em rela√ß√£o ao previsto.\n",
    "- Dividimos pela vari√¢ncia binomial $ \\hat{e}(X_i)(1-\\hat{e}(X_i)) $ para normalizar.\n",
    "\n",
    "Ou seja, este termo ajusta o erro entre observado e previsto, ponderado pela incerteza de receber o tratamento.\n",
    "\n",
    "\n",
    "***2. Segundo termo: diferen√ßa de m√©dias preditas entre tratado e controle***\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)\n",
    "$$\n",
    "\n",
    "- Representa a diferen√ßa nos valores esperados do resultado sob tratamento e sob controle, para o mesmo $ X_i $. Ele captura o efeito esperado com base apenas nos modelos auxiliares.\n",
    "\n",
    "\n",
    "***3. Terceiro termo: subtra√ß√£o do par√¢metro-alvo***\n",
    "\n",
    "$$\n",
    "-\\theta(X_i)\n",
    "$$\n",
    "\n",
    "- Remove $ \\theta(X_i) $ para formar uma equa√ß√£o cujo valor esperado √© zero quando $ \\theta $ est√° corretamente estimado.\n",
    "\n",
    "**Resumo**: For√ßa o momento a ser \"zero\" na verdade populacional.\n",
    "\n",
    "***Intui√ß√£o Geral***\n",
    "\n",
    "**Essa fun√ß√£o $ \\psi $** √© um **score ortogonal**:\n",
    "\n",
    "- √â constru√≠da para ser **insens√≠vel a pequenos erros na estima√ß√£o de $ \\mu_0, \\mu_1, e $**.\n",
    "- Quando resolvemos $ \\mathbb{E}[\\psi(W_i; \\theta, \\eta)] = 0 $, obtemos um estimador consistente para $ \\theta(X) $.\n",
    "- O **primeiro peda√ßo** compensa o vi√©s de sele√ß√£o no tratamento (propensity correction).\n",
    "- O **segundo peda√ßo** usa predi√ß√µes para corrigir vi√©s diretamente.\n",
    "- O **terceiro peda√ßo** ajusta para encontrar $ \\theta(X) $ de forma que o momento seja zero.\n",
    "- A fun√ß√£o $ \\psi $ torna poss√≠vel usar Machine Learning para estimar fun√ß√µes auxiliares sem sacrificar infer√™ncia causal v√°lida.\n",
    "- Pequenos erros nas fun√ß√µes de regress√£o ou propensity n√£o prejudicam a consist√™ncia de $ \\theta(x) $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propriedades da Causal Forest:**\n",
    "\n",
    "- **Consist√™ncia** sob condi√ß√µes regulares (ex: suavidade de $ \\theta(x) $, honestidade das √°rvores).\n",
    "- **Normalidade assint√≥tica ponto a ponto**:\n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}(x) - \\theta(x)) \\overset{d}{\\to} N(0, \\sigma^2(x))\n",
    "$$\n",
    "\n",
    "\n",
    "***Teoria Asint√≥tica***\n",
    "\n",
    "Suponha:\n",
    "\n",
    "- Estima√ß√£o de $ \\hat{\\mu}_0, \\hat{\\mu}_1, \\hat{e} $ convergente a taxas $ o_p(n^{-1/4}) $,\n",
    "- Regularidade do modelo causal,\n",
    "- Cross-fitting.\n",
    "\n",
    "Ent√£o, o estimador $ \\hat{\\theta}(x) $ obtido por DML satisfaz:\n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}(x) - \\theta(x)) \\overset{d}{\\to} N(0, V(x))\n",
    "$$\n",
    "\n",
    "Este resultado permite construir **intervalos de confian√ßa v√°lidos**, algo que m√©todos de Machine Learning puros geralmente n√£o permitem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Quando usar Causal Forest?***\n",
    "\n",
    "Ela √© especialmente √∫til em DML por dois motivos:\n",
    "\n",
    "- Desenha parti√ß√µes do espa√ßo de $ X $ de forma adaptada ao problema de infer√™ncia causal (n√£o apenas para predi√ß√£o).\n",
    "- Fornece um estimador localmente adaptativo de $ \\theta(x) $ com infer√™ncia v√°lida.\n",
    "\n",
    "\n",
    "O DML com Causal Forest:\n",
    "\n",
    "- Combina **flexibilidade n√£o param√©trica** com **rigor estat√≠stico**.\n",
    "- Estima **efeitos heterog√™neos**, essencial para avalia√ß√µes de pol√≠ticas p√∫blicas, economia do trabalho, entre outros.\n",
    "- Permite usar ferramentas modernas (ML) **sem abrir m√£o da fundamenta√ß√£o cl√°ssica da infer√™ncia causal**.\n",
    "\n",
    "***Quando n√£o usar Causal Forest?***\n",
    "\n",
    "- Se o tratamento √© homog√™neo e a heterogeneidade n√£o interessa.\n",
    "- Se o n√∫mero de observa√ß√µes √© muito pequeno (√°rvores precisam de dados para dividir bem).\n",
    "- Se a interpreta√ß√£o de $ \\theta(x) $ para cada indiv√≠duo n√£o for relevante no seu contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Orthogonal Random Forest for Causal Inference***\n",
    "\n",
    "Oprescu, Syrgkanis e Wu (2019)\n",
    "\n",
    "Quando usar o ORF em vez do Causal Forest?\n",
    "\n",
    "Situa√ß√£o\tMelhor escolha\n",
    "Precisa de m√°xima robustez a erros de estima√ß√£o auxiliar\t‚úÖ ORF\n",
    "Quer CATEs em alta dimens√£o com infer√™ncia\t‚úÖ ORF\n",
    "Precisa de interpreta√ß√£o mais simples, r√°pida\tCausal Forest\n",
    "O ORF √© mais rigoroso teoricamente do que o Causal Forest \"puro\", mas √© tamb√©m mais pesado computacionalmente.\n",
    "\n",
    "Orthogonal Random Forest for Causal Inference\"\n",
    "üìú Oprescu, Syrgkanis, Wu (2019)\n",
    "\n",
    "Este √© o artigo central que apresenta o modelo de Orthogonal Random Forest.\n",
    "\n",
    "Introduz a ideia de combinar:\n",
    "\n",
    "Score Neyman-ortogonal (como no DML)\n",
    "\n",
    "Random Forests honestas e adaptativas para aprender o CATE \n",
    "ùúÉ\n",
    "(\n",
    "ùë•\n",
    ")\n",
    "Œ∏(x).\n",
    "\n",
    "Mostra teoria de:\n",
    "\n",
    "Consist√™ncia ponto a ponto\n",
    "\n",
    "Normalidade assint√≥tica\n",
    "\n",
    "Taxas de converg√™ncia em alta dimens√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning (DRML)\n",
    "\n",
    "O estimador duplamente robusto para o Conditional Average Treatment Effect (CATE) combina modelos de *Outcome Regression* e de *escore de propens√£o* para fornecer estimativas consistentes, mesmo que um dos modelos seja mal especificado. A f√≥rmula geral √©:\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}(X_i) = \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) + \\frac{D_i - \\hat{p}(X_i)}{\\hat{p}(X_i)(1 - \\hat{p}(X_i))}(Y_i - \\hat{\\mu}_{D_i}(X_i)),\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $ \\hat{\\mu}_d(X_i) = \\mathbb{E}[Y_i \\mid X_i, D_i = d] $ √© a estimativa do desfecho esperado para o tratamento $ d $ dado $ X_i $\n",
    "- $ \\hat{p}(X_i) = \\mathbb{P}(D_i = 1 \\mid X_i) $ √© a estimativa do escore de propens√£o, ou seja, a probabilidade de receber o tratamento dado $ X_i $\n",
    "- $ D_i $ √© a vari√°vel indicadora de tratamento (1 se tratado, 0 caso contr√°rio),\n",
    "- $ Y_i $ √© o desfecho observado.\n",
    "\n",
    "---\n",
    "\n",
    "### Processo de Estima√ß√£o\n",
    "\n",
    "#### Primeiro Est√°gio: Estima√ß√£o das Fun√ß√µes Inc√¥modas\n",
    "\n",
    "1. **Modelo de Desfecho ($ \\hat{\\mu}_d(X_i) $)**:  \n",
    "   Estima-se a rela√ß√£o entre as covari√°veis $ X_i $ e o desfecho $ Y_i $ para cada n√≠vel de tratamento $ d $.  \n",
    "   T√©cnicas de aprendizado de m√°quina, como regress√£o linear, √°rvores de decis√£o ou redes neurais, podem ser utilizadas.\n",
    "\n",
    "2. **Modelo de Escore de Propens√£o ($ \\hat{p}(X_i) $)**:  \n",
    "   Estima-se a probabilidade de um indiv√≠duo receber o tratamento dado $ X_i $.  \n",
    "   Modelos como regress√£o log√≠stica ou m√©todos de classifica√ß√£o podem ser aplicados.\n",
    "\n",
    "#### Segundo Est√°gio: C√°lculo do Estimador Duplamente Robusto\n",
    "\n",
    "Utiliza-se a f√≥rmula acima para calcular $ \\hat{\\tau}(X_i) $ para cada indiv√≠duo, combinando as estimativas dos modelos de desfecho e de escore de propens√£o.\n",
    "\n",
    "---\n",
    "\n",
    "### Propriedades do Estimador Duplamente Robusto\n",
    "\n",
    "1. **Robustez Dupla**:  \n",
    "   O estimador $ \\hat{\\tau}(X_i) $ √© consistente se pelo menos um dos modelos (desfecho ou escore de propens√£o) for corretamente especificado.  \n",
    "   Isso significa que erros em um modelo podem ser compensados pela precis√£o do outro.\n",
    "\n",
    "2. **Efici√™ncia**:  \n",
    "   Quando ambos os modelos s√£o corretamente especificados, o estimador atinge efici√™ncia assint√≥tica, resultando em estimativas mais precisas.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementa√ß√£o Pr√°tica\n",
    "\n",
    "Na pr√°tica, √© comum utilizar t√©cnicas de *cross-fitting* para evitar vi√©s de superajuste. O procedimento envolve dividir os dados em folds, ajustando os modelos de desfecho e escore de propens√£o em uma parte dos dados e validando em outra, garantindo que as estimativas sejam independentes dos dados usados para ajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o Conditional Average Treatment Effect (CATE) utiliza uma abordagem duplamente robusta para controlar o vi√©s de sele√ß√£o do tratamento. O estimador segue um processo de dois est√°gios: no primeiro, estimam-se as fun√ß√µes inc√¥modas usando t√©cnicas de *crossfitting*, e, no segundo, estima-se o CATE a partir das fun√ß√µes ajustadas.\n",
    "\n",
    "O estimador pode ser descrito pelas seguintes equa√ß√µes:\n",
    "\n",
    "#### Estimativa Duplamente Robusta para $ Y_{t}^{DR} $\n",
    "\n",
    "$$ \\hat{Y}_{i,t}^{DR} = \\mu_t(X_i, W_i) + \\frac{D_i}{\\hat{p}_t(X_i, W_i)} \\cdot (Y_i - \\mu_t(X_i, W_i)), $$\n",
    "\n",
    "onde:\n",
    "- $ \\mu_t(X_i, W_i) = \\mathbb{E}[Y | X_i, W_i, T_i = t] $ √© a fun√ß√£o de resultado condicional,\n",
    "- $ \\hat{p}_t(X_i, W_i) = \\mathbb{P}[T_i = t | X_i, W_i] $ √© o escore de propens√£o condicional,\n",
    "- $ D_i = 1[T_i = t] $ √© uma vari√°vel indicadora para o tratamento $ t $\n",
    "\n",
    "#### Estimativa do CATE\n",
    "\n",
    "$$ \\theta_t(X_i) = \\mathbb{E}[\\hat{Y}_{i,t}^{DR} - \\hat{Y}_{i,0}^{DR} | X_i], $$\n",
    "\n",
    "onde $ \\hat{Y}_{i,0}^{DR} $ √© o contrafactual correspondente ao tratamento de refer√™ncia $ t = 0 $\n",
    "\n",
    "---\n",
    "\n",
    "### Processo de Estima√ß√£o\n",
    "\n",
    "1. **Primeiro est√°gio**:  \n",
    "   Estimam-se as fun√ß√µes inc√¥modas $ \\mu_t(X, W) $ e $ \\hat{p}_t(X, W) $ usando t√©cnicas de aprendizado de m√°quina em um esquema de *crossfitting* para evitar vi√©s.\n",
    "\n",
    "2. **Segundo est√°gio**:  \n",
    "   Substitui-se as estimativas obtidas no primeiro est√°gio nas equa√ß√µes acima e calcula-se o CATE ajustado para cada tratamento $ t $ resolvendo a regress√£o de $ \\hat{Y}_{i,t}^{DR} - \\hat{Y}_{i,0}^{DR} $ sobre $ X_i $\n",
    "\n",
    "---\n",
    "\n",
    "### Observa√ß√µes\n",
    "\n",
    "- **Robustez**: A abordagem √© robusta contra erros na especifica√ß√£o de $ \\mu_t(X, W) $ ou $ \\hat{p}_t(X, W) $, desde que pelo menos uma delas seja corretamente especificada.\n",
    "- **Vi√©s residual**: A precis√£o da estimativa depende fortemente da qualidade das fun√ß√µes inc√¥modas ajustadas no primeiro est√°gio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o CATE usa t√©cnicas de corre√ß√£o duplamente robustas para controlar o vi√©s de sele√ß√£o do tratamento. O estimador segue um processo de dois est√°gios, onde um conjunto de fun√ß√µes inc√¥modas (n√£o especificado, mas que deve ser considerado no modelo) s√£o estimadas no primeiro est√°gio de uma maneira de *crossfitting* e no segundo est√°gio estima-se o modelo CATE. \n",
    "\n",
    "Ou seja, neste estimador, o CATE √© estimado usando as seguintes equa√ß√µes:\n",
    "\n",
    "$$ Y_{i,t}^{DR} = E[Y|X_{i}, W_{i}, T_{i}=t] + \\frac{Y_{i} - E[Y|X_{i}, W_{i}, T_{i}=t]}{Pr[T_{i}=t|X_{i}, W_{i}]}.1[T_{i}=t] $$\n",
    " \n",
    "Ent√£o,\n",
    "\n",
    "$$ E[Y_{i,t}^{DR}-Y_{i,0}^{DR}|X_{i}] = \\theta_{t}(X_{i}) $$\n",
    "\n",
    "\n",
    "Ent√£o, se estimarmos as fun√ß√µes $E[Y|X, W, T]$ e $Pr[T|X, W]$ no primeiro est√°gio, podemos estimar o segundo est√°gio CATE para cada tratamento $t$, rodando uma regress√£o $Y_{i,t}^{DR} - Y_{i,0}^{DR}$ sobre $X$.\n",
    "\n",
    "Os poss√≠veis problemas de estimar a fun√ß√£o do propensity score recai na defini√ß√£o arbitr√°ria do modelo de \"classifica√ß√£o\". A segunda fun√ß√£o √© uma regress√£o simples em $Y$.\n",
    "\n",
    "\n",
    "https://econml.azurewebsites.net/_autosummary/econml.dr.DRLearner.html\n",
    "\n",
    "\n",
    "Outros Modelos Duplamente robustos similares podem ser aplicados:\n",
    "* econml.dr.DRLearner (visto aqui)\n",
    "  * Estimador CATE que usa t√©cnicas de corre√ß√£o duplamente robustas para contabilizar o vi√©s de sele√ß√£o em vari√°veis observ√°veis no tratamento.\n",
    "* econml.dr.LinearDRLearner\n",
    "  * Caso especial em DRLearner que o est√°gio final √© uma Regress√£o Linear em um conjunto de recursos de baixa dimens√£o.\n",
    "* econml.dr.SparseLinearDRLearner\n",
    "  * Caso especial em DRLearner que o est√°gio final √© uma Regress√£o Lasso Desviada.\n",
    "* econml.dr.ForestDRLearner\n",
    "  * Inst√¢ncia do DRLearner com a RegressionForest como modelo final, para permitir infer√™ncia n√£o param√©trica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Doble Robust Machine Learning Difference-in-Differences (DRMLDiD)\n",
    "\n",
    "**√â possivel utilizar DML com dados em painel?**\n",
    "\n",
    "Antes de avan√ßar para o DRMLDiD, vamos primeiro entender como o DML pode ser aplicado a dados em painel (DMLDiD).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Vamos considerar o efeito do homog√™neo do tratamento em um painel de dados. No estilo de Sant¬¥Anna e Zhao (2020).\n",
    "\n",
    "Os modelos de diferen√ßa em diferen√ßas (DID) implementados no pacote focam no caso de tratamento bin√°rio com dois per√≠odos de tratamento. Adotando a nota√ß√£o de Sant'Anna e Zhao (2020) , deixe ser $Y_{it}$ o resultado de interesse para a unidade $i$ no tempo $t$. Al√©m disso, deixe $D_{it}=1$ indicar se unidade $i$ √© tratada antes do tempo $t$ (de outra forma $D_{it}=0$). Como todas as unidades come√ßam como n√£o tratadas ($D_{it}=0$), definir $D_{i0}=0$. Com base na nota√ß√£o de resultado potencial, denote $Y_{it}(1)$ como resultado da unidade $i$ no tempo $t$ se a unidade n√£o recebeu tratamento at√© o momento $t$ e analogamente para $Y_{it}(0)$ com tratamento. Consequentemente, o resultado observado para a unidade $i$ no tempo $t$ √© $Y_{it}=Y_{it}(1)D_{it}+Y_{it}(0)(1-D_{it})$. Al√©m disso, deixe $X_{it}$ ser um vetor de covari√°veis ‚Äã‚Äãde pr√©-tratamento.\n",
    "\n",
    "O par√¢metro de interesse √© o efeito m√©dio do tratamento no indiv√≠duo tratado (ATTE). \n",
    "\n",
    "$$ \\theta_{ATTE} = E[Y_{i1}(1) - Y_{i1}(0)|D_{it}=1]$$\n",
    "\n",
    "As suposi√ß√µes de identifica√ß√£o correspondentes s√£o:\n",
    "* (Cond.) Tend√™ncias paralelas: $Y_{it}(1), Y_{it}(0) \\perp D_{it}|X_{it}$ para $t=1,2$.\n",
    "* Sobreposi√ß√£o: $0 < P(D_{it}=1|X_{it}) < 1$ para $t=1,2$.\n",
    "\n",
    "\n",
    "Se os dados do painel estiverem dispon√≠veis, as observa√ß√µes s√£o consideradas iid. de forma ($Y_{i0},Y_{i1},D_{i},X_{i}$). Obseve que a diferen√ßa $\\Delta Y_{i} = Y_{i1} - Y_{i0}$ tem que ser definida como o resultado yno DoubleMLDataobjeto.\n",
    "\n",
    "O DoubleMLIDID implementa modelos de diferen√ßa em diferen√ßas para dados de painel. A estimativa √© conduzida por meio de seu fit() m√©todo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLDID Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['Z1', 'Z2', 'Z3', 'Z4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 500\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: observational\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: RandomForestRegressor(max_depth=5, min_samples_leaf=5)\n",
      "Learner ml_m: RandomForestClassifier(max_depth=5, min_samples_leaf=5)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_g0 RMSE: [[16.27429763]]\n",
      "Learner ml_g1 RMSE: [[13.35731523]]\n",
      "Classification:\n",
      "Learner ml_m Log Loss: [[0.66601815]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "d -2.840718  1.760386 -1.613691  0.106595 -6.291011  0.609575\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "ml_g = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "ml_m = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "np.random.seed(42)\n",
    "data = make_did_SZ2020(n_obs=500, return_type='DataFrame')\n",
    "obj_dml_data = dml.DoubleMLData(data, 'y', 'd')\n",
    "dml_did_obj = dml.DoubleMLDID(obj_dml_data, ml_g, ml_m)\n",
    "\n",
    "print(dml_did_obj.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Robust Machine Learning - DRML\n",
    "\n",
    "O Estimador de DRML para o CATE usa t√©cnicas de corre√ß√£o duplamente robustas para controlar o vi√©s de sele√ß√£o do tratamento. O estimador segue um processo de dois est√°gios, onde um conjunto de fun√ß√µes inc√¥modas (n√£o especificado, mas que deve ser considerado no modelo) s√£o estimadas no primeiro est√°gio de uma maneira de *crossfitting* e no segundo est√°gio estima-se o modelo CATE. \n",
    "\n",
    "Ou seja, neste estimador, o CATE √© estimado usando as seguintes equa√ß√µes:\n",
    "\n",
    "$$ Y_{i,t}^{DR} = E[Y|X_{i}, W_{i}, T_{i}=t] + \\frac{Y_{i} - E[Y|X_{i}, W_{i}, T_{i}=t]}{Pr[T_{i}=t|X_{i}, W_{i}]}.1[T_{i}=t] $$\n",
    " \n",
    "Ent√£o,\n",
    "\n",
    "$$ E[Y_{i,t}^{DR}-Y_{i,0}^{DR}|X_{i}] = \\theta_{t}(X_{i}) $$\n",
    "\n",
    "\n",
    "Ent√£o, se estimarmos as fun√ß√µes $E[Y|X, W, T]$ e $Pr[T|X, W]$ no primeiro est√°gio, podemos estimar o segundo est√°gio CATE para cada tratamento $t$, rodando uma regress√£o $Y_{i,t}^{DR} - Y_{i,0}^{DR}$ sobre $X$.\n",
    "\n",
    "Os poss√≠veis problemas de estimar a fun√ß√£o do propensity score recai na defini√ß√£o arbitr√°ria do modelo de \"classifica√ß√£o\". A segunda fun√ß√£o √© uma regress√£o simples em $Y$.\n",
    "\n",
    "\n",
    "https://econml.azurewebsites.net/_autosummary/econml.dr.DRLearner.html\n",
    "\n",
    "\n",
    "Outros Modelos Duplamente robustos similares podem ser aplicados:\n",
    "* econml.dr.DRLearner (visto aqui)\n",
    "  * Estimador CATE que usa t√©cnicas de corre√ß√£o duplamente robustas para contabilizar o vi√©s de sele√ß√£o em vari√°veis observ√°veis no tratamento.\n",
    "* econml.dr.LinearDRLearner\n",
    "  * Caso especial em DRLearner que o est√°gio final √© uma Regress√£o Linear em um conjunto de recursos de baixa dimens√£o.\n",
    "* econml.dr.SparseLinearDRLearner\n",
    "  * Caso especial em DRLearner que o est√°gio final √© uma Regress√£o Lasso Desviada.\n",
    "* econml.dr.ForestDRLearner\n",
    "  * Inst√¢ncia do DRLearner com a RegressionForest como modelo final, para permitir infer√™ncia n√£o param√©trica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "#### Resumo Comparativo: DML vs DRML\n",
    "\n",
    "* DML: Foca na remo√ß√£o de vi√©s atrav√©s de uma abordagem em dois est√°gios, utilizando previs√µes de aprendizado de m√°quina e res√≠duos. Busca a ortogonalidade entre o tratamento e o desfecho.\n",
    "* DRML: Utiliza a pondera√ß√£o de probabilidade inversa e a modelagem do desfecho para obter estimativas robustas. √â duplamente robusta porque requer que apenas um dos dois modelos esteja corretamente especificado.\n",
    "\n",
    "Ambas as metodologias s√£o √∫teis em infer√™ncia causal e se beneficiam da flexibilidade e poder dos m√©todos de aprendizado de m√°quina, mas cada uma tem suas especificidades e contextos de aplica√ß√£o onde s√£o mais adequadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
