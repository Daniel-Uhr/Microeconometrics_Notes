{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b5b84c",
   "metadata": {},
   "source": [
    "### Efficient Influence Function (EIF)\n",
    "\n",
    "Daniel de Abreu Pereira Uhr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda8ecc4",
   "metadata": {},
   "source": [
    "A **Efficient Influence Function (EIF)** (ou **Função de Influência Eficiente**) é o **objeto matemático fundamental** que define:\n",
    "\n",
    "1. o **estimador mais eficiente possível** de um parâmetro causal (como o ATE),\n",
    "2. e as condições sob as quais esse estimador é **sem viés em primeira ordem** mesmo quando usamos ML flexível nas etapas auxiliares.\n",
    "\n",
    "Quando queremos estimar um parâmetro causal, por exemplo o efeito médio do tratamento (ATE):\n",
    "\n",
    "$$\n",
    "\\psi_0 = E[m_1(X) - m_0(X)]\n",
    "$$\n",
    "\n",
    "onde ($m_d(X) = E[Y|D=d, X]$),\n",
    "\n",
    "temos duas fontes de incerteza:\n",
    "\n",
    "* o erro de amostragem (ruído estatístico);\n",
    "* e o erro de estimação dos “nuisance functions” (os modelos de ($E[Y|D,X]$) e ($P(D|X)$)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ec932",
   "metadata": {},
   "source": [
    "**Definição**\n",
    "\n",
    "A **Efficient Influence Function (EIF)** é uma função ($\\phi(W; \\psi_0)$) que mede **como o erro em cada observação influencia o erro total do estimador** de forma linearizada.\n",
    "\n",
    "Considere o espaço de todas as distribuições ($P$) para os dados ($W=(Y,D,X)$). O parâmetro de interesse é uma função ($\\psi(P)$) (por exemplo, o ATE).\n",
    "\n",
    "A **influence function** (IF) é definida como:\n",
    "\n",
    "$$\n",
    "\\phi(W; P) = \\left. \\frac{d}{d\\epsilon} \\psi(P_\\epsilon) \\right|_{\\epsilon=0}\n",
    "$$\n",
    "\n",
    "onde ($P_\\epsilon = (1 - \\epsilon) P + \\epsilon \\delta_W$).\n",
    "\n",
    "***Interpretação:***\n",
    "\n",
    "É a **sensibilidade infinitesimal** do estimando ($\\psi(P)$) a pequenas perturbações na distribuição amostral em torno de ($P$).\n",
    "\n",
    "A **Efficient Influence Function (EIF)** é a **influence function com menor variância** entre todas as IFs válidas (isto é, todas que têm esperança zero e derivam corretamente ($\\psi(P)$)).\n",
    "Essa variância mínima define o **semiparametric efficiency bound**.\n",
    "\n",
    "**Exemplo**\n",
    "\n",
    "Para ($D \\in {0,1}$), o EIF do ATE é:\n",
    "\n",
    "$$\n",
    "\\phi(W; \\eta) =\n",
    "\\left[\n",
    "\\frac{D}{p(X)} - \\frac{1-D}{1-p(X)}\n",
    "\\right](Y - m(D,X)) + [m(1,X) - m(0,X)] - \\psi\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "* ($p(X) = P(D=1|X)$) é o propensity score,\n",
    "* ($m(d,X) = E[Y|D=d, X]$) é o outcome regression,\n",
    "* ($\\eta = (m, p)$) é o vetor dos “nuisance parameters”.\n",
    "\n",
    "Esse objeto é importante porque:\n",
    "\n",
    "* ($E[\\phi(W; \\eta_0)] = 0$) no ponto verdadeiro;\n",
    "* Ele é **ortogonal**: pequenas variações em ($m$) ou ($p$) não alteram ($\\psi$) em primeira ordem;\n",
    "* E ele **gera todos os estimadores eficientes** possíveis (TMLE, AIPW, DR-DML, etc).\n",
    "\n",
    "A EIF serve como a **base de construção** de todos os estimadores modernos de efeito causal:\n",
    "\n",
    "| Estimador                | Como usa a EIF                                                            |\n",
    "| ------------------------ | ------------------------------------------------------------------------- |\n",
    "| **AIPW (Augmented IPW)** | Substitui ($m, p$) por ML e usa a média de ($\\phi(W; \\hat\\eta)$)              |\n",
    "| **TMLE**                 | Ajusta ($m$) até que a média de ($\\phi(W; \\hat\\eta^*) = 0$)                   |\n",
    "| **DR-DML**               | Usa cross-fitting e estima ($\\psi$) resolvendo ($E_n[\\phi(W; \\hat\\eta)] = 0$) |\n",
    "| **Causal Forests**       | Aproximam o EIF localmente em cada folha                                  |\n",
    "| **G-formula**            | Implícita, sem ajuste pela EIF (por isso é menos robusta)                 |\n",
    "\n",
    "\n",
    "***Propriedades***\n",
    "\n",
    "1. **Esperança zero:**\n",
    "   $$\n",
    "   E[\\phi(W; \\eta_0)] = 0\n",
    "   $$\n",
    "\n",
    "2. **Ortogonalidade:**\n",
    "   $$\n",
    "   \\frac{\\partial E[\\phi(W; \\eta)]}{\\partial \\eta}\\Big|_{\\eta_0} = 0\n",
    "   $$\n",
    "   → pequenos erros em ML não afetam ($\\hat\\psi$).\n",
    "\n",
    "3. **Variância mínima:**\n",
    "   $$\n",
    "   Var(\\phi(W; \\eta_0)) = \\text{Semiparametric Efficiency Bound}\n",
    "   $$\n",
    "\n",
    "4. **Inferência assintótica:**\n",
    "   $$\n",
    "   \\sqrt{n}(\\hat\\psi - \\psi_0) \\to N(0, Var(\\phi(W; \\eta_0)))\n",
    "   $$\n",
    "   → Intervalos de confiança vêm diretamente da EIF.\n",
    "\n",
    "***Relação entre TMLE, DR e DML***\n",
    "\n",
    "* **TMLE**: constrói um modelo para ($m(D,X)$) e ajusta via *targeting* até satisfazer ($E_n[\\phi(W;\\hat\\eta)] = 0$).\n",
    "* **DR-DML**: usa cross-fitting e resolve a mesma equação, mas sem targeting iterativo.\n",
    "* **Ambos estimam o mesmo parâmetro** — o ATE — definido exatamente pela EIF acima.\n",
    "\n",
    "\n",
    "***Interpretação intuitiva***\n",
    "\n",
    "Pense na EIF como o **\"peso ótimo\"** que cada observação deve ter para corrigir viés de confusão.\n",
    "\n",
    "* O termo ($\\frac{D}{p(X)} - \\frac{1-D}{1-p(X)}$) ajusta o desequilíbrio de propensão;\n",
    "* O termo ($Y - m(D,X)$) corrige a predição;\n",
    "* E ($m(1,X) - m(0,X)$) dá o componente contrafactual esperado.\n",
    "\n",
    "A média ponderada desses componentes é o **efeito causal eficiente**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
