{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputação, Outcome Regression, and Doubly Robust Estimation\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* Estimadores Baseados em Imputação\n",
    "  * Aplicação no Python\n",
    "* Outcome Regression\n",
    "  * Aplicação no Python\n",
    "* Doubly Robust Estimation\n",
    "  * Aplicação no Python\n",
    "* Boas Práticas\n",
    "\n",
    "\n",
    "## Referências\n",
    "\n",
    "* Heckman, James, Hidehiko Ichimura, Jefrey Smith, and Petra Todd. (1998). Characterizing selection bias using experimental data\". Econometrica 66.5, pp. 1017-1098.\n",
    "* Cunningham, S. W. (2013). Causal inference: The mixtape. https://www.scunning.com/mixtape.html\n",
    "* Courthoud, Matteo. Understanding AIPW. https://matteocourthoud.github.io/post/aipw/ \n",
    "* Matheus Facure. Doubly Robust Estimation. https://matheusfacure.github.io/python-causality-handbook/12-Doubly-Robust-Estimation.html\n",
    "* Pearl, J. (2000). Causality: Models, reasoning, and inference. Cambridge University Press.\n",
    "* Joshua D. Angrist and Jörn-Steffen Pischke (2009). Mostly Harmless Econometrics: An Empiricist's Companion. Princeton University Press.\n",
    "* Morgan, S. L., & Winship, C. (2014). Counterfactuals and causal inference: Methods and principles for social research. Cambridge University Press. Capítulo 3.\n",
    "\n",
    "**Pacotes Python**\n",
    "* pyDRReg - Regressão Duplamente Robusta, Outcome Regression e Inverse Probability Weighting, com erro padrão bootstrap.\n",
    "* Instalação: `pip install git+https://github.com/Daniel-Uhr/pyDRReg.git`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Lembre que nossa busca é a identificação do parâmetro causal. Devido ao **problema fundamental da inferência causal**: \n",
    "\n",
    "$$ Y_{i} = D Y^{1}_{i} + (1-D)Y^{0}_{i} $$\n",
    "\n",
    "rearrajando a equação, temos:\n",
    "\n",
    "$$ Y_{i} = Y^{0}_{i} + (Y^{1}_{i} - Y^{0}_{i})D $$\n",
    "\n",
    "Essa segunda equação nos oference \"insights\" importantes, repare que $(Y^{1}_{i} - Y^{0}_{i})$ é o efeito do tratamento no nível do indivíduo, chamaos isso de ***Individual Treatment Effect***. Vamos definir o ITE como $\\tau_{i}$.\n",
    "\n",
    "$$ Y_{i} = Y^{0}_{i} + \\tau_{i} D $$\n",
    "\n",
    "A interpretação direta é que o resultado do individuo *i* será o estado da natureza de não tratado ($Y^{0}$) mais (ou menos) o efeito do tratamento individual ($\\tau_{i}$), caso o indivíduo seja tratado ($D=1$). Essa estrutura é fundamentada na consideração explicita do contrafactual (temos os dois estados do mundo considerados para cada indivíduo).\n",
    "\n",
    "***Estrutura dos Dados Reais***\n",
    "\n",
    "A prática do problema fundamental da inferencia causal é que não podemos observar o resultado de um indivíduo sendo tratado e não-tratado simultaneamente. Logo, nossa estrutura de dados implica em **dados faltante**. Um dos estados da natureza está \"faltante no nosso banco de dados.\n",
    "\n",
    "Vamos considerar um exemplo simples para ilustrar o problema. Suponha que temos um conjunto de dados com as seguintes variáveis:\n",
    "\n",
    "\n",
    "| Unidade |   $Y^{1}$     |  $Y^{0}$     | $D$      |  $X $    |\n",
    "|---------|--------|-------|--------|-------|\n",
    "| 1       | 5      |       | 1      | 11    |\n",
    "| 2       | 2      |       | 1      | 7     |\n",
    "| 3       | 10     |       | 1      | 5     |\n",
    "| 4       | 6      |       | 1      | 3     |\n",
    "| 5       |        | 4     | 0      | 10    |\n",
    "| 6       |        | 0     | 0      | 8     |\n",
    "| 7       |        | 5     | 0      | 4     |\n",
    "| 8       |        | 1     | 0      |  1    |\n",
    "\n",
    "\n",
    "Repare que quando os indivíduos são tratados ($D=1$), não temos os resultados para o indivíduo no estado da natureza de não tratado ($Y^{0}$). O mesmo ocorre quando os indivíduos são nâo tratados ($D=0$), então não observamos o seus respectivos resultados caso \"tivessem sido tratados\" ($Y^{1}$).\n",
    "\n",
    "Processo de completar esses dados faltantes é chamado de imputação.\n",
    "\n",
    "\n",
    "### Regressão Linear\n",
    "\n",
    "Mas se desconsiderarmos o ***problema fundamental da inferência causal***, e calculássemos uma regressão linear? \n",
    "\n",
    "Repare na estrutura de uma estimação linear:\n",
    "\n",
    "$$ Y = \\alpha + \\beta D + \\epsilon $$\n",
    "\n",
    "(ela não é parecida com alguma coisa que vimos recentemente?)\n",
    "\n",
    "A interpretação geral da regressão linear é o seguinte, o valor de $Y$ é composto por um valor constante ($\\alpha$) mais um valor $\\beta$ que é adicionado quando D é um, mais um choque.\n",
    "\n",
    "De outra forma, vamos desagregar Y entre os dois grupos definidos por D.\n",
    "\n",
    "$$ E[Y | D=0 ] = \\alpha $$\n",
    "\n",
    "$$ E[Y | D=1 ] = \\alpha + \\beta $$\n",
    "\n",
    "Voce reparou que há uma semelhança com a estrutura de identificação do efeito ITE? Entretanto não é igual..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf \n",
    "# DataFrame\n",
    "df = pd.read_stata(\"https://github.com/scunning1975/mixtape/raw/master/training_bias_reduction.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que na coluna dos resultados ($Y$), temos tanto ($Y^{1}$ quanto $Y^{0}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unit",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "Y",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "D",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "X",
         "rawType": "int8",
         "type": "integer"
        }
       ],
       "ref": "6ab9bdfc-4c83-495c-abd5-cd1201089148",
       "rows": [
        [
         "0",
         "1",
         "5",
         "1",
         "11"
        ],
        [
         "1",
         "2",
         "2",
         "1",
         "7"
        ],
        [
         "2",
         "3",
         "10",
         "1",
         "5"
        ],
        [
         "3",
         "4",
         "6",
         "1",
         "3"
        ],
        [
         "4",
         "5",
         "4",
         "0",
         "10"
        ],
        [
         "5",
         "6",
         "0",
         "0",
         "8"
        ],
        [
         "6",
         "7",
         "5",
         "0",
         "4"
        ],
        [
         "7",
         "8",
         "1",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unit   Y  D   X\n",
       "0     1   5  1  11\n",
       "1     2   2  1   7\n",
       "2     3  10  1   5\n",
       "3     4   6  1   3\n",
       "4     5   4  0  10\n",
       "5     6   0  0   8\n",
       "6     7   5  0   4\n",
       "7     8   1  0   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez de rodar a regressão, vamos encontrar os parâmetros através das médias. Que tal fazermos na mão?\n",
    "\n",
    "* $E[Y | D = 0 ] = (4 + 0 + 5 + 1)/4 = 10/4 = 2,5 $\n",
    "* $E[Y | D = 1 ] = (5 + 2 + 10 + 6) / 4 = 23/4 = 5,75 $\n",
    "\n",
    "E a difereça entre as médias (SDO) é dada por:\n",
    "\n",
    "$$ \\beta_{OLS} = E[Y | D = 1 ] - E[Y | D = 0 ] $$\n",
    "\n",
    "* $\\beta_{OLS} = 5,75 - 2,5 = 3,25 $\n",
    "\n",
    "\n",
    "Logo, \n",
    "\n",
    "$$ Y = 2,5 + 3,25 D + \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar na regressão?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.298\n",
      "Model:                            OLS   Adj. R-squared:                  0.181\n",
      "Method:                 Least Squares   F-statistic:                     2.548\n",
      "Date:                sex, 08 ago 2025   Prob (F-statistic):              0.162\n",
      "Time:                        16:52:55   Log-Likelihood:                -18.662\n",
      "No. Observations:                   8   AIC:                             41.32\n",
      "Df Residuals:                       6   BIC:                             41.48\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.5000      1.440      1.736      0.133      -1.023       6.023\n",
      "D              3.2500      2.036      1.596      0.162      -1.732       8.232\n",
      "==============================================================================\n",
      "Omnibus:                        0.266   Durbin-Watson:                   2.966\n",
      "Prob(Omnibus):                  0.875   Jarque-Bera (JB):                0.395\n",
      "Skew:                           0.190   Prob(JB):                        0.821\n",
      "Kurtosis:                       1.980   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg0 = smf.ols('Y ~ D', data=df).fit()\n",
    "print(reg0.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa conclusão é que a regressão linear realmente pode ser interpretada como uma diferença de médias. \n",
    "\n",
    "Do ponto de vista da identificação do efeito causal, a regressão não garante o real efeito porque estamos aplicando uma diferença entre as médias dos tratados contra o grupo não tratado.\n",
    "\n",
    "Para encontrarmos o efeito causal, temos que ter em mente a questão de considerar o \"contrafactual\". Uma solução seria estimadores baseados em imputação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimadores baseados em Imputação\n",
    "\n",
    "Estimadores baseados em imputação são métodos estatísticos que lidam com a ausência de dados ou informações não observadas, preenchendo esses valores faltantes com estimativas calculadas a partir dos dados disponíveis. \n",
    "\n",
    "Considerando o exemplo anterior:\n",
    "\n",
    "| Unidade |   $Y^{1}$     |  $Y^{0}$     | $D$      |  $X $    |\n",
    "|---------|--------|-------|--------|-------|\n",
    "| 1       | 5      |   ?    | 1      | 11    |\n",
    "| 2       | 2      |   ?    | 1      | 7     |\n",
    "| 3       | 10     |   ?    | 1      | 5     |\n",
    "| 4       | 6      |   ?    | 1      | 3     |\n",
    "| 5       |   ?     | 4     | 0      | 10    |\n",
    "| 6       |   ?     | 0     | 0      | 8     |\n",
    "| 7       |   ?     | 5     | 0      | 4     |\n",
    "| 8       |   ?     | 1     | 0      |  1    |\n",
    "\n",
    "\n",
    "\n",
    "* ITE\n",
    "Para estimar o ITE para cada i.\n",
    "\n",
    "* ATE\n",
    "\n",
    "* Generalizando a regressão quando há covariáveis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Para a inferência causal, nos deparamos com **dados faltantes**, principalmente, devido ao **problema fundamental da inferência causal**: não podemos observar o resultado de um indivíduo sob tratamento e controle simultaneamente. Portanto, **não podemos observar o efeito causal de um tratamento em um indivíduo**. O que podemos observar são os resultados de um indivíduo tratado ou não-tratado, mas não em ambos.\n",
    "\n",
    "$$ Y_{i} = D Y^{1}_{i} + (1-D)Y^{0}_{i} $$\n",
    "\n",
    "rearrajando a equação, temos:\n",
    "\n",
    "$$ Y_{i} = Y^{0}_{i} + (Y^{1}_{i} - Y^{0}_{i})D $$\n",
    "\n",
    "Vamos chamar o efeito causal individual (Individual Treatment Effect - ITE) é a diferença nos dois estados da natureza, que vamos denotar aqui como $\\tau_{i}$, então:\n",
    "\n",
    "$$ Y_{i} = Y^{0}_{i} + \\tau_{i} D $$\n",
    "\n",
    "\n",
    "Quando possuímos uma amostra, podemos avaliar na média. Se calcularmos a média de $Y_{i}$, temos:\n",
    "\n",
    "$$ E[Y_{i}] = E[Y^{0}_{i}] + E[\\tau_{i}]E[D] $$\n",
    "\n",
    "E as médias condicionais:\n",
    "\n",
    "$$ E[Y_{i}|D=1] = E[Y^{1}_{i}] = E[Y^{0}_{i}] + E[\\tau_{i}] $$\n",
    "\n",
    "$$ E[Y_{i}|D=0] = E[Y^{0}_{i}] $$\n",
    "\n",
    "Considere  $\\mu_{0}$ a média dos resultados potenciais de controle, e $\\mu_{1}$ a média dos resultados potenciais de tratamento. Então:\n",
    "\n",
    "$$ E[Y_{i}] = \\mu_{0} + \\tau E[D] $$\n",
    "\n",
    "$$ E[Y_{i}|D=1] = \\mu_{0} + \\tau = \\mu_{1}$$\n",
    "\n",
    "$$ E[Y_{i}|D=0] = \\mu_{0} $$\n",
    "\n",
    "\n",
    "Considerando $\\mu_{0}$ é a média dos resultados potenciais sob controle e $\\epsilon$ o erro:\n",
    "\n",
    "Mas lembre-se que o modelo de regressão linear podemos controlar por covariáveis. Então podemos considerar o modelo linear dado por:\n",
    "\n",
    "$$ Y = \\alpha + \\tau D + \\gamma X + \\epsilon $$\n",
    "\n",
    "Continuamos considerando $ Y $ como a variável dependente, $ D $ é a variável indicadora de tratamento (1 se o tratamento foi aplicado, 0 caso contrário), $ X $ são as covariáveis observáveis, e $ \\epsilon $ é o termo de erro do modelo.\n",
    "\n",
    "Agora, repare que se aplicamos a expectativa condicional de $Y$ em $D$, temos:\n",
    "   \n",
    "$$ E[Y|X, D=1] = \\mu_{1}(X) +  u_1  $$\n",
    "\n",
    "$$ E[Y|X, D=0] = \\mu_{0}(X) + u_0  $$\n",
    "\n",
    "É importante notar que agora tanto $\\mu_{0}$ quanto $\\mu_{1}$ são função de $X$, suas características observáveis. E $\\mu_{1}(X) $ e $ \\mu_{0}(X) $ representam as **médias dos resultados potenciais** para os tratados e não tratados, respectivamente, dados $ X $. Os termos $ u_1 $ e $u_0 $ são termos de erro associados aos grupos de tratamento e controle, respectivamente.\n",
    "\n",
    "\n",
    "Voltando ao nosso objetivo inicial. Queremos é estimar o efeito causal, como o efeito médio do tratamento (Average Treatment Effect, ATE), definido como:\n",
    "\n",
    "$$ATE = E[Y_{i}^{1} - Y_{i}^{0}]$$\n",
    "\n",
    "**Como calcular o ATE?**\n",
    "\n",
    "Devido à falta de observação simultânea de $Y^{1}$ e $Y^{0}$ para a mesma unidade, os pesquisadores propuseram utilizar **estimadores baseados em imputação** para estimar o potencial resultado não observado.\n",
    "\n",
    "A ideia é que podemos estimar o ATE a partir de valores previstos dos resultados potenciais sob tratamento ($\\hat{Y^{1}}$) e não-tratado ($\\hat{Y^{0}}$).\n",
    "\n",
    "\n",
    "**Exemplo aplicado**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.136\n",
      "Model:                            OLS   Adj. R-squared:                 -0.296\n",
      "Method:                 Least Squares   F-statistic:                    0.3157\n",
      "Date:                Wed, 06 Nov 2024   Prob (F-statistic):              0.631\n",
      "Time:                        17:10:49   Log-Likelihood:                -9.5879\n",
      "No. Observations:                   4   AIC:                             23.18\n",
      "Df Residuals:                       2   BIC:                             21.95\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      8.0714      4.540      1.778      0.217     -11.461      27.604\n",
      "X             -0.3571      0.636     -0.562      0.631      -3.092       2.378\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   3.356\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.254\n",
      "Skew:                           0.071   Prob(JB):                        0.881\n",
      "Kurtosis:                       1.773   Cond. No.                         17.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf \n",
    "# DataFrame\n",
    "df = pd.read_stata(\"https://github.com/scunning1975/mixtape/raw/master/training_bias_reduction.dta\")\n",
    "reg1 = smf.ols('Y ~ X', data=df[df['D'] == 1]).fit()\n",
    "print(reg1.summary())\n",
    "df['Yhat_1']= reg1.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.015\n",
      "Model:                            OLS   Adj. R-squared:                 -0.478\n",
      "Method:                 Least Squares   F-statistic:                   0.03001\n",
      "Date:                Wed, 06 Nov 2024   Prob (F-statistic):              0.878\n",
      "Time:                        17:10:53   Log-Likelihood:                -8.5398\n",
      "No. Observations:                   4   AIC:                             21.08\n",
      "Df Residuals:                       2   BIC:                             19.85\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.0872      2.788      0.749      0.532      -9.909      14.083\n",
      "X              0.0718      0.414      0.173      0.878      -1.712       1.855\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   3.412\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.402\n",
      "Skew:                          -0.018   Prob(JB):                        0.818\n",
      "Kurtosis:                       1.448   Cond. No.                         13.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "      <th>Yhat_1</th>\n",
       "      <th>Yhat_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>2.876923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>2.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>2.446154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.302564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.805128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.214286</td>\n",
       "      <td>2.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>2.374359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>2.158974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unit   Y  D   X    Yhat_1    Yhat_0\n",
       "0     1   5  1  11  4.142857  2.876923\n",
       "1     2   2  1   7  5.571429  2.589744\n",
       "2     3  10  1   5  6.285714  2.446154\n",
       "3     4   6  1   3  7.000000  2.302564\n",
       "4     5   4  0  10  4.500000  2.805128\n",
       "5     6   0  0   8  5.214286  2.661538\n",
       "6     7   5  0   4  6.642857  2.374359\n",
       "7     8   1  0   1  7.714286  2.158974"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg0 = smf.ols('Y ~ X', data=df[df['D'] == 0]).fit()\n",
    "print(reg0.summary())\n",
    "\n",
    "df['Yhat_0']= reg0.predict(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos calcular o efeito médio do tratamento (ATE) nos valores previstos de $Y^{1}$ e $Y^{0}$, e então estimar o efeito médio do tratamento.\n",
    "\n",
    "$$ \\hat{ATE} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\hat{Y}_{i}^{1} - \\hat{Y}_{i}^{0} \\right) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "      <th>Yhat_1</th>\n",
       "      <th>Yhat_0</th>\n",
       "      <th>tau_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>2.876923</td>\n",
       "      <td>1.265934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>2.589744</td>\n",
       "      <td>2.981685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>2.446154</td>\n",
       "      <td>3.839560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.302564</td>\n",
       "      <td>4.697436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.805128</td>\n",
       "      <td>1.694872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.214286</td>\n",
       "      <td>2.661538</td>\n",
       "      <td>2.552747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>2.374359</td>\n",
       "      <td>4.268498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>2.158974</td>\n",
       "      <td>5.555311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unit   Y  D   X    Yhat_1    Yhat_0   tau_hat\n",
       "0     1   5  1  11  4.142857  2.876923  1.265934\n",
       "1     2   2  1   7  5.571429  2.589744  2.981685\n",
       "2     3  10  1   5  6.285714  2.446154  3.839560\n",
       "3     4   6  1   3  7.000000  2.302564  4.697436\n",
       "4     5   4  0  10  4.500000  2.805128  1.694872\n",
       "5     6   0  0   8  5.214286  2.661538  2.552747\n",
       "6     7   5  0   4  6.642857  2.374359  4.268498\n",
       "7     8   1  0   1  7.714286  2.158974  5.555311"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tau_hat'] = df['Yhat_1'] - df['Yhat_0']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efeito Médio do Tratamento (ATE) estimado: 3.3570054945054957\n"
     ]
    }
   ],
   "source": [
    "ATE = df['tau_hat'].mean()\n",
    "print(f\"\\nEfeito Médio do Tratamento (ATE) estimado: {ATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E o ATT e o ATC?**\n",
    "\n",
    "Podemos também estimar o efeito médio do tratamento para os tratados (ATT) e o efeito médio do tratamento para os não tratados (ATU), que são definidos como:\n",
    "\n",
    "$$ATT = E[Y_{i}^{1} - Y_{i}^{0} | D = 1]$$\n",
    "\n",
    "$$ATU = E[Y_{i}^{1} - Y_{i}^{0} | D = 0]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o ATT (média dos tau_hat para D=1)\n",
    "ATT = df[df['D'] == 1]['tau_hat'].mean()\n",
    "\n",
    "# Calculando o ATU (média dos tau_hat para D=0)\n",
    "ATU = df[df['D'] == 0]['tau_hat'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efeito Médio do Tratamento (ATE): 3.3570054945054957\n",
      "Efeito Médio do Tratamento sobre os Tratados (ATT): 3.1961538461538472\n",
      "Efeito Médio do Tratamento sobre os Controles (ATU): 3.517857142857144\n"
     ]
    }
   ],
   "source": [
    "# Exibindo os resultados\n",
    "print(f\"Efeito Médio do Tratamento (ATE): {ATE}\")\n",
    "print(f\"Efeito Médio do Tratamento sobre os Tratados (ATT): {ATT}\")\n",
    "print(f\"Efeito Médio do Tratamento sobre os Controles (ATU): {ATU}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação dos Resultados**\n",
    "\n",
    "* **ATE (Efeito Médio do Tratamento):** Estimado em aproximadamente 3.36, indica o efeito médio esperado do tratamento na população geral.\n",
    "\n",
    "* **ATT (Efeito Médio sobre os Tratados):** Estimado em aproximadamente 3.20, sugere que, para as unidades que receberam o tratamento, o efeito médio do tratamento é um aumento de 3.20 unidades em Y.\n",
    "\n",
    "* **ATU (Efeito Médio sobre os Não-Tratados)**: Estimado em aproximadamente 3.52, indica que, se as unidades de controle tivessem recebido o tratamento, o efeito médio esperado seria um aumento de 3.52 unidades em Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome Regression\n",
    "\n",
    "O estimador de \"Outcome Regression\" também é conhecido como Regression Adjustment ou Augmented Regression. É um desdobramento do estimador de imputação visto no exemplo anterior. Vejamos mais a fundo.\n",
    "\n",
    "**Outcome Regression - ATE**\n",
    "\n",
    "Logo, no contexto de resultados potenciais, poderíamos recuperar o efeito causal $\\tau$ ao tirarmos e expectativa da diferença de médias. Ou seja:\n",
    "\n",
    "$$ \\hat{ATE} = E[\\hat{Y}^{1} - \\hat{Y}^{0}] $$\n",
    "\n",
    "\n",
    "$$ \\hat{ATE} = E[ (\\mu_{1}(X) +  u_1) - (\\mu_{0}(X) - u_0) ] $$\n",
    "\n",
    "$$ \\hat{ATE} = E[\\mu_{1}(X) - \\mu_{0}(X)] - E[u_1 - u_0] $$\n",
    "\n",
    "\n",
    "Em um experimento controlado, esperaríamos que:\n",
    "* $E[Y_{1} - \\mu_{1}(X)] = E[u_{1}] = 0$ \n",
    "* $E[Y_{0} - \\mu_{0}(X)] = E[u_{0}] = 0$\n",
    "\n",
    "o que simplificaria a expressão para o efeito causal médio ajustado pelas covariáveis: \n",
    "\n",
    "$$ \\hat{ATE} = E[\\mu_{1}(X)- \\mu_{0}(X)] - E[u_1 - u_0] = E[\\beta] $$\n",
    "\n",
    "em outras palavras, em caso de um experimento, a expressão para o ATE, ajustado pelas covariáveis, deve simplificar para\n",
    "\n",
    "$$ \\hat{\\beta}^{OR}_{ATE} = E[\\mu_{1}(X)- \\mu_{0}(X)] $$\n",
    "\n",
    "Uma proposta natural para estimar as funções $\\mu_{1}(X)$ e $\\mu_{0}(X)$ é ajustar um modelo de regressão linear para $Y$ em função de $D$ e $X$. Se o modelo for **corretamente especificado**, o coeficiente de $D$ estimado será uma estimativa consistente do efeito causal médio ajustado pelas covariáveis.\n",
    "\n",
    "Logo, os *pressupostos principais* para identificação do efeito causal:\n",
    "\n",
    "* **Linearidade**\n",
    "* **Viés de seleção por observáveis** (ignorabilidade condicional)\n",
    "  * Assumimos que, ao incluir $X$ no modelo, estamos controlando adequadamente por todas as fontes de viés de seleção.\n",
    "\n",
    "**Limitações:**\n",
    "* Se existirem variáveis não observadas que afetam $D$ e $Y$, o estimador de Outcome Regression será enviesado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome Regression - ATT**\n",
    "\n",
    "Para obter o efeito médio do tratamento para os tratados, utilizamos a ideia contrafactual, para o subgrupo amostral dos tratados. A ideia é utilizar a projeção do grupo Não-tratado com as características X do grupo de tratamento ($X^{1}$) para construir o contrafactual. \n",
    "\n",
    "Queremos construir um grupo de controle, sua função ($\\mu_{0}(.)$ representa como os não-tratados se comportam, entretanto projetamos seu resultado contrafactual ao considerar \"se eles tivessem as características observáveis dos tratados\").\n",
    "\n",
    "Dessa forma a estimativa do efeito médio do tratamento para os tratados (ATT) é dada por:\n",
    "\n",
    "$$ \\hat{\\beta}^{OR}_{ATT} = E[\\mu_{1}(X^{1}) - \\mu_{0}(X^{1})] + E[(Y_{1} - \\mu_{1}(X^{1})) - (Y_{0} - \\mu_{0}(X^{1}))] $$\n",
    "\n",
    "\n",
    "Em outras palavras, consideramos os resultados do grupo de controle caso eles tivessem as mesmas características observáveis do grupo de tratamento.\n",
    "\n",
    "Como no exemplo anterior, isso ocorre na subamostra dos tratados, ou seja, quando restringimos a análise em $D=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação no Python\t\n",
    "\n",
    "Vamos fazer um exemplo prático no Python, com os dados das mães fumantes e não fumantes durante a gestação, e o peso dos bebês ao nascer. \n",
    "\n",
    "Primeiramente farei os códigos na \"mão\", e depois utilizarei o pacote pyDRReg.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/cattaneo2.dta\")\n",
    "\n",
    "# Criar a variável de resultado\n",
    "df['Y'] = df['bweight']\n",
    "\n",
    "# Crie a variável 'Treated' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'Treated' para 1 se 'mbsmoke' for igual a 'smoker'\n",
    "df.loc[df['mbsmoke'] == 'smoker', 'Treated'] = 1\n",
    "\n",
    "# Criar variáveis de controle\n",
    "df['Mmarried'] = 0\n",
    "df.loc[df['mmarried'] == 'married', 'Mmarried'] = 1\n",
    "df['casada'] = 0\n",
    "df.loc[df['mmarried']=='married', 'casada'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após carregar os dados vamos tentar aplicar o Outcome Regression para estimar o ATE.\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome Regression - ATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Regression Estimate - ATE (OR - ATE): -236.52788533678506\n"
     ]
    }
   ],
   "source": [
    "def OR_ate(df, X_cols, T_col, Y_col):\n",
    "    X_np = df[X_cols].values  # Converter X para numpy array\n",
    "    T_np = df[T_col].values  # Converter T para numpy array\n",
    "    Y_np = df[Y_col].values  # Converter Y para numpy array\n",
    "    # Essas linhas convertem as colunas de interesse do DataFrame (df) em arrays numpy, o que facilita a manipulação e os cálculos subsequentes.\n",
    "        \n",
    "    # Ajustar regressão linear para não tratados (D=0)\n",
    "    model_0 = LinearRegression().fit(X_np[T_np==0], Y_np[T_np==0])\n",
    "    mu0 = model_0.predict(X_np)\n",
    "    # Aqui, ajusta-se um modelo de regressão linear para as observações que não receberam o tratamento (T_np == 0). Em seguida, são feitas previsões (mu0) para todas as observações com base neste modelo.\n",
    "    \n",
    "    # Ajustar regressão linear para tratados (D=1)\n",
    "    model_1 = LinearRegression().fit(X_np[T_np==1], Y_np[T_np==1])\n",
    "    mu1 = model_1.predict(X_np)\n",
    "    # Da mesma forma, ajusta-se um modelo de regressão linear para as observações que receberam o tratamento (T_np == 1) e são feitas previsões (mu1) para todas as observações com base neste modelo.\n",
    "    \n",
    "    # Calcular o efeito causal médio\n",
    "    effect = np.mean(mu1 - mu0)\n",
    "    # Calcula-se a diferença média entre as previsões dos modelos para tratados e não tratados, resultando em uma estimativa preliminar do efeito causal médio\n",
    "    \n",
    "    # Calcular os desvios para todas as observações\n",
    "    deviations = (Y_np - (T_np * mu1 + (1 - T_np) * mu0))\n",
    "    # Os desvios são calculados como a diferença entre os valores observados de Y e as previsões ponderadas dos modelos de tratados e não tratados.\n",
    "    \n",
    "    # Calcular a média dos desvios\n",
    "    deviations_mean = np.mean(deviations)\n",
    "    # Calcula-se a média dos desvios, que é usada para ajustar a estimativa do efeito causal médio.\n",
    "    \n",
    "    # Calcular o OR\n",
    "    OR_ate_estimate = effect + deviations_mean\n",
    "    \n",
    "    return OR_ate_estimate\n",
    "\n",
    "# Definir as colunas de interesse\n",
    "T_col = 'Treated'\n",
    "Y_col = 'Y'\n",
    "X_cols = ['casada', 'mage', 'medu']\n",
    "\n",
    "# Calcular o OR\n",
    "result_OR_ate = OR_ate(df, X_cols, T_col, Y_col)\n",
    "print(\"Outcome Regression Estimate - ATE (OR - ATE):\", result_OR_ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado da estimativa de ATE (Average Treatment Effect) usando a técnica de Outcome Regression é de aproximadamente -236.53. Isso significa que, em média, o efeito do fumo durante a gestação sobre o resultado $Y$ (peso dos bebês ao nascer) é uma redução de aproximadamente 236.53 gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Regression (ATT): -215.24538690027902\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def OR_att(df, X_cols, T_col, Y_col):\n",
    "    # Separar dados tratados (D=1) e não tratados (D=0)\n",
    "    X_treated = df[df[T_col] == 1][X_cols]\n",
    "    Y_treated = df[df[T_col] == 1][Y_col]\n",
    "    X_control = df[df[T_col] == 0][X_cols]\n",
    "    Y_control = df[df[T_col] == 0][Y_col]\n",
    "\n",
    "    # Ajustar modelos de regressão linear\n",
    "    model_treated = LinearRegression().fit(X_treated, Y_treated)\n",
    "    model_control = LinearRegression().fit(X_control, Y_control)\n",
    "\n",
    "    # Calcular previsões para tratados e não tratados\n",
    "    mu1_X = model_treated.predict(X_treated)\n",
    "    mu0_X = model_control.predict(X_treated)  # Usando X_treated para manter o contrafactual consistente\n",
    "\n",
    "    # Calcular desvios para todas as observações\n",
    "    deviations_treated = Y_treated - mu1_X\n",
    "    deviations_control = Y_control - model_control.predict(X_control)\n",
    "\n",
    "    # Calcular a média dos desvios tratados e não tratados\n",
    "    deviations_mean_treated = deviations_treated.mean()\n",
    "    deviations_mean_control = deviations_control.mean()\n",
    "\n",
    "    # Calcular a média geral dos desvios\n",
    "    deviations_mean = deviations_treated.mean()  # Considerando apenas os tratados para o ATT\n",
    "\n",
    "    # Calcular ATT\n",
    "    OR_att_estimate = (mu1_X.mean() - mu0_X.mean()) + deviations_mean\n",
    "\n",
    "    return OR_att_estimate\n",
    "\n",
    "T_col = 'Treated'\n",
    "Y_col = 'Y'\n",
    "X_cols = ['casada', 'mage', 'medu']\n",
    "\n",
    "result_OR_att = OR_att(df, X_cols, T_col, Y_col)\n",
    "print(\"Outcome Regression (ATT):\", result_OR_att)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo a análise de forma mais fácil, pelo pacote pyDRReg, encontramos os mesmos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome Regression - ATT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric       Value\n",
      "0     Estimator          OR\n",
      "1        Method         ATT\n",
      "2      Estimate -215.245387\n",
      "3  bootstrap_SE   22.410568\n",
      "4        t-stat   -9.604638\n",
      "5       p-value         0.0\n",
      "6      CI Lower   -259.1701\n",
      "7      CI Upper -171.320674\n"
     ]
    }
   ],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "OR_att = pyDRReg(df, X_vars, T_var, Y_var, method='att', estimator='OR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(OR_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome Regression - ATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric       Value\n",
      "0     Estimator          OR\n",
      "1        Method         ATE\n",
      "2      Estimate -236.527885\n",
      "3  bootstrap_SE   24.192087\n",
      "4        t-stat   -9.777077\n",
      "5       p-value         0.0\n",
      "6      CI Lower -283.944375\n",
      "7      CI Upper -189.111396\n"
     ]
    }
   ],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "OR_ate = pyDRReg(df, X_vars, T_var, Y_var, method='ate', estimator='OR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(OR_ate.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado da estimativa de ATT (Average Treatment Effect on the Treated) usando a técnica de Outcome Regression é de aproximadamente -215.25; Isso significa que, em média, o efeito do fumo durante a gestação sobre o resultado $Y$ (peso dos bebês ao nascer) é uma redução de aproximadamente 215.25 gramas para os tratados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doubly Robust Estimation (DR)\n",
    "\n",
    "A estimativa duplamente robusta combina uma forma de \"Outcome Regression\" com um modelo de ponderação (ou seja, utilizando o escore de propensão) para estimar o efeito causal sobre um resultado. Quando usados individualmente para estimar um efeito causal, os métodos de regressão de resultados e escore de propensão são não enviesados apenas se o modelo estatístico for especificado corretamente. O **estimador duplamente robusto** combina estas 2 abordagens de modo que apenas 1 dos 2 modelos precisa ser especificado corretamente para obter um estimador de efeito não-viesado.\n",
    "\n",
    "A especificação correta do modelo de regressão é um pressuposto fundamental na análise econométrica. Quando o objetivo é ajustar o fator de confusão, o estimador é consistente (e, portanto, assintoticamente não-enviesado) se o modelo refletir as verdadeiras relações entre a exposição e os fatores de confusão com o resultado. Na prática, nunca poderemos saber se algum modelo específico representa com precisão essas relações. **A estimativa duplamente robusta combina regressão de resultados com ponderação pelo escore de propensão (PS), de modo que o estimador seja robusto à especificação incorreta de um (mas não de ambos) desses modelos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome Regression Approach**\n",
    "\n",
    "Vimos que:\n",
    "\n",
    "$$ \\hat{\\beta}_{ATE}^{OR} = E[\\mu_{1}(X) - \\mu_{0}(X)] + E[(Y_{1} - \\mu_{1}(X)) - (Y_{0} - \\mu_{0}(X))] $$\n",
    "\n",
    "e\n",
    "\n",
    "$$ \\hat{\\beta}^{OR}_{ATT} = E[\\mu_{1}(X^{1}) - \\mu_{0}(X^{1})] + E[(Y_{1} - \\mu_{1}(X^{1})) - (Y_{0} - \\mu_{0}(X^{1}))] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "\n",
    "**Approach de Inverse Probability Weighting (IPW)**\n",
    "\n",
    "Nesta abordagem, o viés de confusão é ajustado por meio de técnicas de matching (pareamento) e ponderação pelo escore de propensão (Peso = $W$). As ponderações são calculadas da seguinte forma:\n",
    "\n",
    "$$ W_{ATE} = \\frac{D}{\\hat{p}(X)} + \\frac{1-D}{1-\\hat{p}(X)} $$\n",
    "\n",
    "e,\n",
    "\n",
    "$$ W_{ATT} = D + (1-D)\\frac{\\hat{p}(X)}{1-\\hat{p}(X)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach do Doubly Robust Estimation (DR)**\n",
    "\n",
    "A abordagem Doubly Robust Estimation (DR) combina as vantagens das abordagens de Outcome Regression e de Ponderação pela Probabilidade Inversa. Isso proporciona uma maior robustez aos resultados. Os estimadores duplamente robustos para o Average Treatment Effect (ATE) e o Average Treatment Effect on the Treated (ATT) são dados pelas seguintes fórmulas:\n",
    "\n",
    "* **Doubly Robust Estimation for Average Treatment Effect (ATE)**\n",
    "\n",
    "$$ \\hat{\\beta_{ATE}^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) \\right] + \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "* **Doubly Robust Estimation for Average Treatment Effect on the Treated (ATT)**\n",
    "\n",
    "$$ \\hat{\\beta_{ATT}^{DR}} = \\mathbb{E} \\left[ (\\mu_1 (X) - \\mu_0 (X)) \\right] + \\mathbb{E} \\left[ D(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)\\hat{p}(X)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que realizamos um \"ajuste\" nos resíduos da regressão de resultados, ponderando-os pelo escore de propensão. Isso garante que o estimador seja robusto à especificação incorreta de um dos modelos. O \"ajuste\" é essencialmente um estimador IPW realizado sobre os resíduos.\n",
    "\n",
    "Por isso que o Doubly Robust Estimation também é conhecido como Augmented Inverse Probability Weighting (AIPW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Por que a o estimador Duplamente Robusto (*Augmented Inverse Probability Weighting* - AIPW) é tão atraente?**\n",
    "\n",
    "A razão é que só precisamos de uma das duas previsões, *$\\hat{\\mu}$* ou *$\\hat{p}$*, para que a estimativa seja correta (não enviesada/imparcial). \n",
    "* Se ambos os modelos estiverem corretos, o estimador será mais eficiente do que qualquer um dos modelos sozinho. \n",
    "* Se um dos modelos estiver errado, o estimador ainda será consistente, desde que o outro modelo esteja correto. \n",
    "\n",
    "Isso é uma grande vantagem em relação a outras abordagens, como a regressão de resultados ou a ponderação pelo escore de propensão, que exigem que ambos os modelos estejam corretos para que o estimador seja consistente.\n",
    "\n",
    "Suponha que $\\hat{\\mu}$ esteja especificado corretamente. Então $E[\\hat{\\mu}^{d}(x)=E[Y|X=x, D=d]$ , então o estimador DR é consistente, mesmo que o modelo de propensão $\\hat{p}$ esteja mal especificado.\n",
    "\n",
    "$$ \\hat{\\beta^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) +  \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$  =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$  =  \\mathbb{E} \\left[ Y^{1} - Y^{0} \\right] = $$\n",
    "\n",
    "$$ = \\beta $$\n",
    "\n",
    "A intuição é que, se $\\hat{\\mu}$ está **especificado corretamente é imparcial e o fator de ajuste desaparece**, uma vez que os resíduos convergem para zero.\n",
    "\n",
    "\n",
    "Por outro lado, suponha $\\hat{p}$ está especificado corretamente, ou seja, $E[\\hat{p}(X)]=P(D=1|X)$, então o estimador DR é consistente, mesmo que o modelo de resultados $\\hat{\\mu}$ esteja mal especificado.\n",
    "\n",
    "$$ \\hat{\\beta^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) +  \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\mu_1(X) - \\mu_0 (X) + \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{D}{\\hat{p}(X)}.\\mu_1 (X) - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\frac{(1-D)}{1-\\hat{p}(X)}.\\mu_0 (X) \\right] = $$\n",
    "\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) - \\frac{D}{\\hat{p}(X)}.\\mu_1 (X) + \\frac{(1-D)}{1-\\hat{p}(X)}.\\mu_0 (X) - \\mu_0 (X) \\right] = $$\n",
    "\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) (1 - \\frac{D}{\\hat{p}(X)}) + \\mu_0 (X)(\\frac{(1-D)}{1-\\hat{p}(X)} - 1) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) (\\frac{\\hat{p}(X) - D}{\\hat{p}(X)}) + \\mu_0 (X)(\\frac{(1-D)- (1-\\hat{p}(X))}{1-\\hat{p}(X)}) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ Y^{1} - Y^{0} \\right] = $$\n",
    "\n",
    "$$ = \\beta $$\n",
    "\n",
    "A intuição é que, se $\\hat{p}$ está especificado corretamente, o $\\hat{\\beta}^{DR}$ é imparcial e o fator de ajuste desaparece, uma vez que os resíduos ($D_{i}-\\hat{p}(X)$) convergem para zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação em Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, a ideia é mostrar todos os componentes da Estimação Duplamente Robusta, e realizar as estimações na \"mão\" e, posteriormente, com o pacote pyDRReg.\n",
    "\n",
    "Primeiro precisamos estimar os componentes da Estimação Duplamente Robusta, \"escore de propensão\" ($p(X)$) e as funções de resposta ($\\mu_{0}(X)$ e $\\mu_{1}(X)$). Num primeiro momento vamos estimar o Propensity Score e estimar regressões ATE e ATE para o método de Propensity Score Weighting (PSW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando o escore de propensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.446546\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Treated   No. Observations:                 4642\n",
      "Model:                          Logit   Df Residuals:                     4638\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 05 Sep 2024   Pseudo R-squ.:                 0.07078\n",
      "Time:                        16:28:30   Log-Likelihood:                -2072.9\n",
      "converged:                       True   LL-Null:                       -2230.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.853e-68\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5894      0.230      2.564      0.010       0.139       1.040\n",
      "casada        -1.0310      0.090    -11.497      0.000      -1.207      -0.855\n",
      "mage           0.0122      0.008      1.570      0.116      -0.003       0.027\n",
      "medu          -0.1415      0.017     -8.540      0.000      -0.174      -0.109\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Regressão Logística para estimar o escore de propensão\n",
    "logit_model = smf.logit(\"Treated ~ 1 + casada + mage + medu\", data=df).fit()\n",
    "# Imprimindo o modelo\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o escore de propensão no DataFrame\n",
    "df['ps'] = logit_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verificar graficamente a área de sobreposição\n",
    "sns.histplot(data=df, x='ps', hue='Treated', bins=100, stat='density', common_norm=False).\\\n",
    "    set(ylabel=\"\", title=\"Distribution of Propensity Scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos calcular os pesos IPW para o ATE e ATT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Probability of Treatment Weight (IPTW)\n",
    "\n",
    "# Peso para o efeito médio do tratamento (ATE)\n",
    "df['W1'] = 1 / df['ps']\n",
    "df.loc[df['Treated'] == 0, 'W1'] = 0\n",
    "df['W2'] = 1 / (1 - df['ps'])\n",
    "df.loc[df['Treated'] == 1, 'W2'] = 0\n",
    "\n",
    "# Peso para o efeito médio do tratamento nos tratados (ATT)\n",
    "df['W_ATE'] = df['W1'] + df['W2']\n",
    "df['W_ATT'] = df['ps'] / (1 - df['ps'])\n",
    "df.loc[df['Treated'] == 1, 'W_ATT'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A título de curiosidade, podemos estimar o efeito médio do tratamento para os tratados (ATT) e o efeito médio do tratamento (ATE) utilizando o método de Ponderação pelo Escore de Propensão (IPW). Para isso, basta rodar a regressão linear considerando como peso amostral os valores de $W_{ATE}$ e $W_{ATT}$, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.040\n",
      "Model:                            WLS   Adj. R-squared:                  0.040\n",
      "Method:                 Least Squares   F-statistic:                     194.9\n",
      "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           2.03e-43\n",
      "Time:                        21:04:19   Log-Likelihood:                -36594.\n",
      "No. Observations:                4642   AIC:                         7.319e+04\n",
      "Df Residuals:                    4640   BIC:                         7.321e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3401.1645     11.754    289.358      0.000    3378.121    3424.208\n",
      "Treated     -234.4371     16.793    -13.960      0.000    -267.360    -201.515\n",
      "==============================================================================\n",
      "Omnibus:                     1345.722   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13048.433\n",
      "Skew:                          -1.100   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.914   Cond. No.                         2.60\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Propensity Score Weighting - ATE\n",
    "psw_ate = smf.wls(\"Y ~ Treated\", weights=df['W_ATE'], data=df).fit()\n",
    "print(psw_ate.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.032\n",
      "Model:                            WLS   Adj. R-squared:                  0.032\n",
      "Method:                 Least Squares   F-statistic:                     155.8\n",
      "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           3.41e-35\n",
      "Time:                        16:28:39   Log-Likelihood:                -37060.\n",
      "No. Observations:                4642   AIC:                         7.412e+04\n",
      "Df Residuals:                    4640   BIC:                         7.414e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3350.9689     12.014    278.924      0.000    3327.416    3374.522\n",
      "Treated     -213.3092     17.089    -12.482      0.000    -246.812    -179.807\n",
      "==============================================================================\n",
      "Omnibus:                     1802.084   Durbin-Watson:                   2.029\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22353.766\n",
      "Skew:                          -1.499   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.324   Cond. No.                         2.60\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Propensity Score Weighting - ATT\n",
    "psw_att = smf.wls(\"Y ~ Treated\", weights=df['W_ATT'], data=df).fit()\n",
    "print(psw_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que podemos obter os mesmos resultados utilizando o pacote pyDRReg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric       Value\n",
      "0     Estimator         IPW\n",
      "1        Method         ATT\n",
      "2      Estimate -213.309168\n",
      "3  bootstrap_SE   22.839909\n",
      "4        t-stat   -9.339318\n",
      "5       p-value         0.0\n",
      "6      CI Lower -258.075389\n",
      "7      CI Upper -168.542946\n"
     ]
    }
   ],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "IPW_att = pyDRReg(df, X_vars, T_var, Y_var, method='att', estimator='IPW', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(IPW_att.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric       Value\n",
      "0     Estimator         IPW\n",
      "1        Method         ATE\n",
      "2      Estimate -234.437125\n",
      "3  bootstrap_SE   23.479172\n",
      "4        t-stat   -9.984897\n",
      "5       p-value         0.0\n",
      "6      CI Lower -280.456303\n",
      "7      CI Upper -188.417947\n"
     ]
    }
   ],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "IPW_ate = pyDRReg(df, X_vars, T_var, Y_var, method='ate', estimator='IPW', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(IPW_ate.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimativa Duplamente Robusta**\n",
    "\n",
    "Agora temos todos os componentes para estimar o DR para ATE e o ATT, vamos fazer \"na mão\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-229.19546059542853\n"
     ]
    }
   ],
   "source": [
    "# DR-ATE\n",
    "DR_ATE = mu1 - mu0 + df[\"Treated\"] / df[\"ps\"] * (df[\"Y\"] - mu1) - (1-df[\"Treated\"]) / (1-df[\"ps\"]) * (df[\"Y\"] - mu0)\n",
    "print(np.mean(DR_ATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-218.94795582708\n"
     ]
    }
   ],
   "source": [
    "# DR-ATT\n",
    "DR_ATT = mu1 - mu0 + df[\"Treated\"] * (df[\"Y\"] - mu1) - (1-df[\"Treated\"])*df[\"ps\"] / (1-df[\"ps\"]) * (df[\"Y\"] - mu0)\n",
    "print(np.mean(DR_ATT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar o pacote pyDRReg para obter os mesmos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric       Value\n",
      "0     Estimator          DR\n",
      "1        Method         ATE\n",
      "2      Estimate -229.195464\n",
      "3  bootstrap_SE   23.584023\n",
      "4        t-stat   -9.718251\n",
      "5       p-value         0.0\n",
      "6      CI Lower  -275.42015\n",
      "7      CI Upper -182.970779\n"
     ]
    }
   ],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "DR_ate = pyDRReg(df, X_vars, T_var, Y_var, method='ate', estimator='DR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(DR_ate.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric       Value\n",
      "0     Estimator          DR\n",
      "1        Method         ATT\n",
      "2      Estimate -218.947956\n",
      "3  bootstrap_SE   22.000454\n",
      "4        t-stat   -9.951974\n",
      "5       p-value         0.0\n",
      "6      CI Lower -262.068846\n",
      "7      CI Upper -175.827066\n"
     ]
    }
   ],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "DR_att = pyDRReg(df, X_vars, T_var, Y_var, method='att', estimator='DR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(DR_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse tipo de estimador é bastante importante na literatura. E já possui alguns estimadores que realizam as estimações de forma direta. Por exemplo, poderíamos computar diretamente com 'LinearDRLearner' da biblioteca 'EconML' da Microsoft (EconML - Estimate causal effects with ML).\n",
    "\n",
    "obs: https://www.microsoft.com/en-us/research/project/econml/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from econml.dr import LinearDRLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['casada', 'mage', 'medu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDRLearner(model_propensity=LogisticRegression(), \n",
    "                        model_regression=LinearRegression(),\n",
    "                        random_state=1)\n",
    "model.fit(Y=df[\"Y\"], T=df[\"Treated\"], X=X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Uncertainty of Mean Point Estimate</caption>\n",
       "<tr>\n",
       "  <th>mean_point</th> <th>stderr_mean</th>  <th>zstat</th> <th>pvalue</th> <th>ci_mean_lower</th> <th>ci_mean_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>-228.118</td>    <td>23.167</td>    <td>-9.847</td>   <td>0.0</td>    <td>-273.524</td>      <td>-182.712</td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ate_inference(X=X.values, T0=0, T1=1).summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo nos dá diretamente o efeito médio do tratamento. A estimativa é estatisticamente diferente de zero e o intervalo de confiança inclui o valor verdadeiro de -229,17. Observe que obtivemos uma estimativa diferente porque a função **LinearDRLearner** também realizou o cross-fitting em segundo plano, o que não fizemos antes. Ele não calcula o ATT.\n",
    "\n",
    "Outro pacote importante é o \"causalml\" (https://causalml.readthedocs.io/en/latest/about.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boas práticas\n",
    "\n",
    "* Verifique o balanço das covariáveis.\n",
    "  * Tanto o IPW quanto o DR (AIPW) foram desenvolvidos para ambientes nos quais o tratamento não é atribuído aleatoriamente incondicionalmente, mas pode depender de algumas variáveis observáveis. Essas informações podem ser verificadas de duas maneiras: \n",
    "    * (1) Produza uma tabela de médias/equilíbrio das covariáveis. Se a randomização incondicional não for válida, esperamos ver diferenças significativas entre alguns observáveis; \n",
    "    * (2) Trace os escores de propensão estimados. Se a randomização incondicional for válida, esperamos que os escores de propensão sejam constantes.\n",
    "* Verifique a suposição de sobreposição.\n",
    "  * Podemos simplesmente verificar os limites dos escores de propensão previstos. Se a suposição de sobreposição for violada, acabamos dividindo algum termo do estimador por zero.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
