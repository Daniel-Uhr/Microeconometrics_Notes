{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664f1dd9",
   "metadata": {},
   "source": [
    "# Inverse Probability Weighting and Doubly Robust Estimation\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* Estimadores Baseados em Imputação\n",
    "  * Aplicação no Python\n",
    "* Outcome Regression\n",
    "  * Aplicação no Python\n",
    "* Doubly Robust Estimation\n",
    "  * Aplicação no Python\n",
    "* Boas Práticas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Observações:** O material apresentado aqui é uma adaptação do material de aula do Prof. Daniel de Abreu Pereira Uhr, e não deve ser utilizado para fins comerciais. O material é disponibilizado para fins educacionais e de pesquisa, e não deve ser reproduzido sem a devida autorização do autor. Este material pode conter erros e imprecisões. O autor não se responsabiliza por quaisquer danos ou prejuízos decorrentes do uso deste material. O uso deste material é de responsabilidade exclusiva do usuário. Caso você encontre erros ou imprecisões neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer *feedback* ou sugestão de melhoria.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093e748",
   "metadata": {},
   "source": [
    "## Propensity Score Weighting\n",
    "\n",
    "### Definição formal do Propensity Score\n",
    "\n",
    "O **Propensity Score** é definido como a probabilidade condicional de uma unidade receber o tratamento dado o vetor de covariáveis observadas:\n",
    "\n",
    "$$\n",
    "p(X_i) = \\Pr(D_i = 1 \\mid X_i)\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $D_i \\in \\{0, 1\\}$ é o indicador de tratamento;\n",
    "- $X_i$ é o vetor de covariáveis observadas.\n",
    "\n",
    "A ideia central de **Propensity Score Weighting** é reponderar a amostra de forma a criar uma população *pseudo‐randomizada*, em que a distribuição das covariáveis seja balanceada entre tratados e não tratados.\n",
    "\n",
    "## Inverse Probability of Treatment Weight (IPTW)\n",
    "\n",
    "### 1. Pesos para o **ATE** (Average Treatment Effect)\n",
    "\n",
    "O peso **IPTW** para o ATE é definido como:\n",
    "\n",
    "$$\n",
    "w_i^{ATE} = \\frac{D_i}{p(X_i)} + \\frac{1 - D_i}{1 - p(X_i)}\n",
    "$$\n",
    "\n",
    "**Na prática**:\n",
    "- Tratados ($D_i = 1$) recebem peso $1 / p(X_i)$  \n",
    "- Controles ($D_i = 0$) recebem peso $1 / (1 - p(X_i))$\n",
    "\n",
    "\n",
    "### 2. Pesos para o **ATT** (Average Treatment Effect on the Treated)\n",
    "\n",
    "O peso **IPTW** para o ATT é definido como:\n",
    "\n",
    "$$\n",
    "w_i^{ATT} = D_i + (1 - D_i) \\cdot \\frac{p(X_i)}{1 - p(X_i)}\n",
    "$$\n",
    "\n",
    "**Na prática**:\n",
    "- Tratados ($D_i = 1$) recebem peso = 1  \n",
    "- Controles ($D_i = 0$) recebem peso $p(X_i) / (1 - p(X_i))$\n",
    "\n",
    "\n",
    "### Interpretação dos pesos\n",
    "\n",
    "- **No ATE**:  \n",
    "  - Unidades tratadas com baixa probabilidade de tratamento recebem peso alto.  \n",
    "  - Unidades de controle com baixa probabilidade de não tratamento recebem peso alto.  \n",
    "\n",
    "- **No ATT**:  \n",
    "  - Tratados sempre têm peso 1.  \n",
    "  - Controles são reponderados para se assemelhar à distribuição de covariáveis dos tratados.\n",
    "\n",
    "### Hipóteses de identificação\n",
    "\n",
    "1. **Ignorabilidade (ou não confusão)**:  \n",
    "   $$\n",
    "   (Y_i(1), Y_i(0)) \\perp D_i \\mid X_i\n",
    "   $$  \n",
    "   Isto é, não existem confundidores não observados dados $X_i$.\n",
    "\n",
    "2. **Sobreposição (ou suporte comum)**:  \n",
    "   $$\n",
    "   0 < p(X_i) < 1 \\quad \\forall i\n",
    "   $$  \n",
    "   Cada unidade tem probabilidade positiva de receber ambos os estados de tratamento.\n",
    "\n",
    "### Estimação do efeito causal ponderado\n",
    "\n",
    "O **ATE ponderado** pode ser visto como:\n",
    "\n",
    "> Média ponderada dos resultados observados entre os tratados  \n",
    "> **menos**  \n",
    "> Média ponderada dos resultados observados entre os controles.\n",
    "\n",
    "Matematicamente:\n",
    "\n",
    "$$\n",
    "\\widehat{\\tau}_{ATE} =\n",
    "\\underbrace{\\frac{\\sum_{i=1}^n w_i^{ATE} D_i Y_i}{\\sum_{i=1}^n w_i^{ATE} D_i}}_{\\text{Média ponderada nos tratados}}\n",
    "-\n",
    "\\underbrace{\\frac{\\sum_{i=1}^n w_i^{ATE} (1-D_i) Y_i}{\\sum_{i=1}^n w_i^{ATE} (1-D_i)}}_{\\text{Média ponderada nos controles}}\n",
    "$$\n",
    "\n",
    "O **ATT** pode ser obtido substituindo $w_i^{ATE}$ por $w_i^{ATT}$ na fórmula acima, interpretando o resultado como efeito médio nos tratados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bd5e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a55087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/cattaneo2.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0310073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a variável de resultado\n",
    "df['Y'] = df['bweight']\n",
    "\n",
    "# Crie a variável 'Treated' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'Treated' para 1 se 'mbsmoke' for igual a 'smoker'\n",
    "df.loc[df['mbsmoke'] == 'smoker', 'Treated'] = 1\n",
    "\n",
    "df['casada'] = 0\n",
    "df.loc[df['mmarried']=='married', 'casada'] = 1\n",
    "\n",
    "# gerar uma variável de contagem de linhas iniciando em 1\n",
    "df['id'] = np.arange(len(df)) + 1\n",
    "\n",
    "# Conjunto de Covariáveis X\n",
    "X = ['casada', 'mage', 'medu']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565100c",
   "metadata": {},
   "source": [
    "Rodar o escore de propensão e salvar no dataframe \"pscore\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "484b0706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.446546\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Estimar o escore de propensão com regressão logística\n",
    "df['pscore'] = smf.logit(\"Treated ~ casada + mage + medu\", data=df).fit().predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75f59a",
   "metadata": {},
   "source": [
    "Criar os pesos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b221994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATE weights\n",
    "df['W_ATE'] = df['Treated'] / df['pscore'] + (1 - df['Treated']) / (1 - df['pscore'])\n",
    "\n",
    "# ATT weights\n",
    "df['W_ATT'] = df['Treated'] * 1 + (1 - df['Treated']) * (df['pscore'] / (1 - df['pscore']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49be178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.040\n",
      "Model:                            WLS   Adj. R-squared:                  0.040\n",
      "Method:                 Least Squares   F-statistic:                     194.9\n",
      "Date:                Wed, 20 Aug 2025   Prob (F-statistic):           2.03e-43\n",
      "Time:                        17:19:19   Log-Likelihood:                -36594.\n",
      "No. Observations:                4642   AIC:                         7.319e+04\n",
      "Df Residuals:                    4640   BIC:                         7.321e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3401.1645     11.754    289.358      0.000    3378.121    3424.208\n",
      "Treated     -234.4371     16.793    -13.960      0.000    -267.360    -201.515\n",
      "==============================================================================\n",
      "Omnibus:                     1345.722   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13048.433\n",
      "Skew:                          -1.100   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.914   Cond. No.                         2.60\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Aplicando regressão ponderada (IPTW) para ATE\n",
    "model_ate = smf.wls(\"Y ~ Treated\", data=df, weights=df['W_ATE']).fit()\n",
    "print(model_ate.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c14487",
   "metadata": {},
   "source": [
    "ATE com peso IPTW apresentou efeito de -234.4371 gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69fce080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.032\n",
      "Model:                            WLS   Adj. R-squared:                  0.032\n",
      "Method:                 Least Squares   F-statistic:                     155.8\n",
      "Date:                Wed, 20 Aug 2025   Prob (F-statistic):           3.41e-35\n",
      "Time:                        17:19:46   Log-Likelihood:                -37060.\n",
      "No. Observations:                4642   AIC:                         7.412e+04\n",
      "Df Residuals:                    4640   BIC:                         7.414e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3350.9689     12.014    278.924      0.000    3327.416    3374.522\n",
      "Treated     -213.3092     17.089    -12.482      0.000    -246.812    -179.807\n",
      "==============================================================================\n",
      "Omnibus:                     1802.084   Durbin-Watson:                   2.029\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22353.766\n",
      "Skew:                          -1.499   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.324   Cond. No.                         2.60\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Aplicando regressão ponderada (IPTW) para ATT\n",
    "model_att = smf.wls(\"Y ~ Treated\", data=df, weights=df['W_ATT']).fit()\n",
    "print(model_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988fe81",
   "metadata": {},
   "source": [
    "ATT com peso IPTW é -213.3092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7003554a",
   "metadata": {},
   "source": [
    "### Doubly Robust Estimation (DR - AIPW)\n",
    "\n",
    "***Doubly Robust Estimation (DR)***\n",
    "\n",
    "* É a ideia geral de combinar Outcome Regression e Inverse Probability Weighting. Um estimador é “duplamente robusto” quando é consistente se pelo menos um dos modelos (de resultado ou de propensão) estiver corretamente especificado. Exemplo clássico: AIPW.\n",
    "\n",
    "***AIPW (Augmented Inverse Probability Weighting)***\n",
    "\n",
    "* É um caso específico de estimador duplamente robusto. A forma canônica do AIPW para o ATE é exatamente aquela fórmula que vou apresentar.\n",
    "\n",
    "\n",
    "***Motivação***\n",
    "\n",
    "Na avaliação de efeitos causais, dois métodos são comuns:  \n",
    "\n",
    "- **Outcome Regression (OR):** modelar diretamente o resultado condicional a $X$ e $D$.  \n",
    "- **Inverse Probability Weighting (IPW):** reponderar as observações pelo escore de propensão $\\hat{p}(X)$.  \n",
    "\n",
    "Cada um é **consistente apenas se o modelo estiver corretamente especificado**.  \n",
    "O **estimador duplamente robusto (Doubly Robust, ou Augmented IPW - AIPW)** combina as duas abordagens, garantindo consistência se **pelo menos um dos modelos estiver correto**.\n",
    "\n",
    "**Modelos básicos**\n",
    "\n",
    "- Tratamento: $D_i \\in \\{0,1\\}$\n",
    "- Covariáveis: $X_i$\n",
    "- Resultado: $Y_i = D_i Y_i(1) + (1-D_i) Y_i(0)$\n",
    "- Propensity score: $p(X) = P(D=1|X)$\n",
    "- Funções de regressão: $\\mu_d(X) = E[Y|D=d,X]$\n",
    "\n",
    "Queremos o efeito médio do tratamento (ATE):\n",
    "\n",
    "$$\n",
    "\\beta_{ATE} = E[Y(1) - Y(0)] \n",
    "$$\n",
    "\n",
    "\n",
    "#### Outcome Regression (OR)\n",
    "\n",
    "O estimador para o ATE é:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{OR} = \\frac{1}{n}\\sum_{i=1}^n \\left[ \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i) \\right]\n",
    "$$\n",
    "\n",
    "onde $\\hat{\\mu}_d(X)$ é obtido por regressão.\n",
    "\n",
    "\n",
    "#### Inverse Probability Weighting (IPW)\n",
    "\n",
    "O estimador ATE via IPW é:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{IPW} = \\frac{1}{n}\\sum_{i=1}^n \\left( \\frac{D_i Y_i}{\\hat{p}(X_i)} - \\frac{(1-D_i)Y_i}{1-\\hat{p}(X_i)} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "#### Estimador Doubly Robust (AIPW)\n",
    "\n",
    "O estimador duplamente robusto para o ATE é dado por:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{DR} = \\frac{1}{n}\\sum_{i=1}^n \\Bigg\\{ \\Big(\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)\\Big) \\;+\\; \\frac{D_i}{\\hat{p}(X_i)}\\big(Y_i - \\hat{\\mu}_1(X_i)\\big) \\;-\\; \\frac{1-D_i}{1-\\hat{p}(X_i)}\\big(Y_i - \\hat{\\mu}_0(X_i)\\big) \\Bigg\\}\n",
    "$$\n",
    "\n",
    "**Interpretação:**  \n",
    "\n",
    "- O **primeiro termo** ($\\hat{\\mu}_1 - \\hat{\\mu}_0$) é a predição média da regressão de resultados.  \n",
    "- Os **termos adicionais** são “correções” baseadas em resíduos ponderados por IPW.  \n",
    "\n",
    "\n",
    "***Propriedade de Dupla Robustez***\n",
    "\n",
    "- Se $\\hat{\\mu}_d(X)$ estiver corretamente especificado → os resíduos têm média zero, e o estimador DR converge para o ATE mesmo que $\\hat{p}(X)$ esteja errado.  \n",
    "- Se $\\hat{p}(X)$ estiver corretamente especificado → a ponderação corrige vieses da regressão mal especificada, garantindo consistência.  \n",
    "- Se **ambos** estiverem corretos → o estimador é **eficiente** (atinge menor variância assintótica).\n",
    "\n",
    "\n",
    "***Em termos intuitivos:***\n",
    "\n",
    "- O DR é chamado também de **Augmented IPW** porque começa com IPW e **adiciona regressão dos resultados** como “ajuste extra”.  \n",
    "- Outra visão: é uma **regressão de resultados com resíduos reponderados**, de modo que o viés de especificação de um modelo é compensado pelo outro.  \n",
    "\n",
    "\n",
    "**Extensões**\n",
    "\n",
    "- **ATT (Average Treatment Effect on the Treated):** versão análoga existe, com pesos ajustados para focar nos tratados.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875c3fd",
   "metadata": {},
   "source": [
    "### Aplicação em Python\n",
    "\n",
    "Para facilitar a aplicação vamos utilizar uma abordagem moderna chamada ***DR-Learner***.\n",
    "\n",
    "***DR-Learner***\n",
    "* É um meta-algoritmo de Machine Learning (Chernozhukov et al., 2018; Nie & Wager, 2021), que usa a ideia de dupla robustez junto com algoritmos de ML para estimar Conditional Average Treatment Effects (CATE). O DR-Learner aproveita a estrutura AIPW (score de influência duplamente robusto) e depois ajusta modelos de ML em cima disso para obter heterogeneidade do efeito. Portanto, DR-Learner é um desdobramento moderno do AIPW aplicado à estimação de efeitos condicionais (CATE), não sinônimo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b396ef9",
   "metadata": {},
   "source": [
    "## Doubly Robust Estimation (DR)\n",
    "\n",
    "A estimativa duplamente robusta combina uma forma de \"Outcome Regression\" com um modelo de ponderação (ou seja, utilizando o escore de propensão) para estimar o efeito causal sobre um resultado. Quando usados individualmente para estimar um efeito causal, os métodos de regressão de resultados e escore de propensão são não enviesados apenas se o modelo estatístico for especificado corretamente. O **estimador duplamente robusto** combina estas 2 abordagens de modo que apenas 1 dos 2 modelos precisa ser especificado corretamente para obter um estimador de efeito não-viesado.\n",
    "\n",
    "A especificação correta do modelo de regressão é um pressuposto fundamental na análise econométrica. Quando o objetivo é ajustar o fator de confusão, o estimador é consistente (e, portanto, assintoticamente não-enviesado) se o modelo refletir as verdadeiras relações entre a exposição e os fatores de confusão com o resultado. Na prática, nunca poderemos saber se algum modelo específico representa com precisão essas relações. **A estimativa duplamente robusta combina regressão de resultados com ponderação pelo escore de propensão (PS), de modo que o estimador seja robusto à especificação incorreta de um (mas não de ambos) desses modelos**.\n",
    "\n",
    "\n",
    "**Outcome Regression Approach**\n",
    "\n",
    "Vimos que:\n",
    "\n",
    "$$ \\hat{\\beta}_{ATE}^{OR} = E[\\mu_{1}(X) - \\mu_{0}(X)] + E[(Y_{1} - \\mu_{1}(X)) - (Y_{0} - \\mu_{0}(X))] $$\n",
    "\n",
    "e\n",
    "\n",
    "$$ \\hat{\\beta}^{OR}_{ATT} = E[\\mu_{1}(X^{1}) - \\mu_{0}(X^{1})] + E[(Y_{1} - \\mu_{1}(X^{1})) - (Y_{0} - \\mu_{0}(X^{1}))] $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Approach de Inverse Probability Weighting (IPW)**\n",
    "\n",
    "Nesta abordagem, o viés de confusão é ajustado por meio de técnicas de matching (pareamento) e ponderação pelo escore de propensão (Peso = $W$). As ponderações são calculadas da seguinte forma:\n",
    "\n",
    "$$ W_{ATE} = \\frac{D}{\\hat{p}(X)} + \\frac{1-D}{1-\\hat{p}(X)} $$\n",
    "\n",
    "e,\n",
    "\n",
    "$$ W_{ATT} = D + (1-D)\\frac{\\hat{p}(X)}{1-\\hat{p}(X)} $$\n",
    "\n",
    "\n",
    "**Approach do Doubly Robust Estimation (DR)**\n",
    "\n",
    "A abordagem Doubly Robust Estimation (DR) combina as vantagens das abordagens de Outcome Regression e de Ponderação pela Probabilidade Inversa. Isso proporciona uma maior robustez aos resultados. Os estimadores duplamente robustos para o Average Treatment Effect (ATE) e o Average Treatment Effect on the Treated (ATT) são dados pelas seguintes fórmulas:\n",
    "\n",
    "* **Doubly Robust Estimation for Average Treatment Effect (ATE)**\n",
    "\n",
    "$$ \\hat{\\beta_{ATE}^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) \\right] + \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] $$\n",
    "\n",
    "* **Doubly Robust Estimation for Average Treatment Effect on the Treated (ATT)**\n",
    "\n",
    "$$ \\hat{\\beta_{ATT}^{DR}} = \\mathbb{E} \\left[ (\\mu_1 (X) - \\mu_0 (X)) \\right] + \\mathbb{E} \\left[ D(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)\\hat{p}(X)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] $$\n",
    "\n",
    "\n",
    "Repare que realizamos um \"ajuste\" nos resíduos da regressão de resultados, ponderando-os pelo escore de propensão. Isso garante que o estimador seja robusto à especificação incorreta de um dos modelos. O \"ajuste\" é essencialmente um estimador IPW realizado sobre os resíduos.\n",
    "\n",
    "Por isso que o Doubly Robust Estimation também é conhecido como Augmented Inverse Probability Weighting (AIPW).\n",
    "\n",
    "**Por que a o estimador Duplamente Robusto (*Augmented Inverse Probability Weighting* - AIPW) é tão atraente?**\n",
    "\n",
    "A razão é que só precisamos de uma das duas previsões, *$\\hat{\\mu}$* ou *$\\hat{p}$*, para que a estimativa seja correta (não enviesada/imparcial). \n",
    "* Se ambos os modelos estiverem corretos, o estimador será mais eficiente do que qualquer um dos modelos sozinho. \n",
    "* Se um dos modelos estiver errado, o estimador ainda será consistente, desde que o outro modelo esteja correto. \n",
    "\n",
    "Isso é uma grande vantagem em relação a outras abordagens, como a regressão de resultados ou a ponderação pelo escore de propensão, que exigem que ambos os modelos estejam corretos para que o estimador seja consistente.\n",
    "\n",
    "Suponha que $\\hat{\\mu}$ esteja especificado corretamente. Então $E[\\hat{\\mu}^{d}(x)=E[Y|X=x, D=d]$ , então o estimador DR é consistente, mesmo que o modelo de propensão $\\hat{p}$ esteja mal especificado.\n",
    "\n",
    "$$ \\hat{\\beta^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) +  \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$  =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$  =  \\mathbb{E} \\left[ Y^{1} - Y^{0} \\right] = $$\n",
    "\n",
    "$$ = \\beta $$\n",
    "\n",
    "A intuição é que, se $\\hat{\\mu}$ está **especificado corretamente é imparcial e o fator de ajuste desaparece**, uma vez que os resíduos convergem para zero.\n",
    "\n",
    "\n",
    "Por outro lado, suponha $\\hat{p}$ está especificado corretamente, ou seja, $E[\\hat{p}(X)]=P(D=1|X)$, então o estimador DR é consistente, mesmo que o modelo de resultados $\\hat{\\mu}$ esteja mal especificado.\n",
    "\n",
    "$$ \\hat{\\beta^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) +  \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\mu_1(X) - \\mu_0 (X) + \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{D}{\\hat{p}(X)}.\\mu_1 (X) - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\frac{(1-D)}{1-\\hat{p}(X)}.\\mu_0 (X) \\right] = $$\n",
    "\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) - \\frac{D}{\\hat{p}(X)}.\\mu_1 (X) + \\frac{(1-D)}{1-\\hat{p}(X)}.\\mu_0 (X) - \\mu_0 (X) \\right] = $$\n",
    "\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) (1 - \\frac{D}{\\hat{p}(X)}) + \\mu_0 (X)(\\frac{(1-D)}{1-\\hat{p}(X)} - 1) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) (\\frac{\\hat{p}(X) - D}{\\hat{p}(X)}) + \\mu_0 (X)(\\frac{(1-D)- (1-\\hat{p}(X))}{1-\\hat{p}(X)}) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ Y^{1} - Y^{0} \\right] = $$\n",
    "\n",
    "$$ = \\beta $$\n",
    "\n",
    "A intuição é que, se $\\hat{p}$ está especificado corretamente, o $\\hat{\\beta}^{DR}$ é imparcial e o fator de ajuste desaparece, uma vez que os resíduos ($D_{i}-\\hat{p}(X)$) convergem para zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d1973",
   "metadata": {},
   "source": [
    "### Aplicação em Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53e315",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d783f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33729140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logística para estimar o escore de propensão\n",
    "logit_model = smf.logit(\"Treated ~ 1 + casada + mage + medu\", data=df).fit()\n",
    "# Imprimindo o modelo\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o escore de propensão no DataFrame\n",
    "df['ps'] = logit_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fccb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar graficamente a área de sobreposição\n",
    "sns.histplot(data=df, x='ps', hue='Treated', bins=100, stat='density', common_norm=False).\\\n",
    "    set(ylabel=\"\", title=\"Distribution of Propensity Scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6e16f",
   "metadata": {},
   "source": [
    "Agora vamos calcular os pesos IPW para o ATE e ATT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Probability of Treatment Weight (IPTW)\n",
    "\n",
    "# Peso para o efeito médio do tratamento (ATE)\n",
    "df['W1'] = 1 / df['ps']\n",
    "df.loc[df['Treated'] == 0, 'W1'] = 0\n",
    "df['W2'] = 1 / (1 - df['ps'])\n",
    "df.loc[df['Treated'] == 1, 'W2'] = 0\n",
    "\n",
    "# Peso para o efeito médio do tratamento nos tratados (ATT)\n",
    "df['W_ATE'] = df['W1'] + df['W2']\n",
    "df['W_ATT'] = df['ps'] / (1 - df['ps'])\n",
    "df.loc[df['Treated'] == 1, 'W_ATT'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d2c5f",
   "metadata": {},
   "source": [
    "A título de curiosidade, podemos estimar o efeito médio do tratamento para os tratados (ATT) e o efeito médio do tratamento (ATE) utilizando o método de Ponderação pelo Escore de Propensão (IPW). Para isso, basta rodar a regressão linear considerando como peso amostral os valores de $W_{ATE}$ e $W_{ATT}$, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0109f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propensity Score Weighting - ATE\n",
    "psw_ate = smf.wls(\"Y ~ Treated\", weights=df['W_ATE'], data=df).fit()\n",
    "print(psw_ate.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0746e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propensity Score Weighting - ATT\n",
    "psw_att = smf.wls(\"Y ~ Treated\", weights=df['W_ATT'], data=df).fit()\n",
    "print(psw_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4a910",
   "metadata": {},
   "source": [
    "Repare que podemos obter os mesmos resultados utilizando o pacote pyDRReg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "IPW_att = pyDRReg(df, X_vars, T_var, Y_var, method='att', estimator='IPW', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(IPW_att.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "IPW_ate = pyDRReg(df, X_vars, T_var, Y_var, method='ate', estimator='IPW', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(IPW_ate.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02f063",
   "metadata": {},
   "source": [
    "**Estimativa Duplamente Robusta**\n",
    "\n",
    "Agora temos todos os componentes para estimar o DR para ATE e o ATT, vamos fazer \"na mão\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DR-ATE\n",
    "DR_ATE = mu1 - mu0 + df[\"Treated\"] / df[\"ps\"] * (df[\"Y\"] - mu1) - (1-df[\"Treated\"]) / (1-df[\"ps\"]) * (df[\"Y\"] - mu0)\n",
    "print(np.mean(DR_ATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7192631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DR-ATT\n",
    "DR_ATT = mu1 - mu0 + df[\"Treated\"] * (df[\"Y\"] - mu1) - (1-df[\"Treated\"])*df[\"ps\"] / (1-df[\"ps\"]) * (df[\"Y\"] - mu0)\n",
    "print(np.mean(DR_ATT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb287c1",
   "metadata": {},
   "source": [
    "Podemos utilizar o pacote pyDRReg para obter os mesmos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "DR_ate = pyDRReg(df, X_vars, T_var, Y_var, method='ate', estimator='DR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(DR_ate.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "DR_att = pyDRReg(df, X_vars, T_var, Y_var, method='att', estimator='DR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(DR_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721ad1b8",
   "metadata": {},
   "source": [
    "Esse tipo de estimador é bastante importante na literatura. E já possui alguns estimadores que realizam as estimações de forma direta. Por exemplo, poderíamos computar diretamente com 'LinearDRLearner' da biblioteca 'EconML' da Microsoft (EconML - Estimate causal effects with ML).\n",
    "\n",
    "obs: https://www.microsoft.com/en-us/research/project/econml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c76e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from econml.dr import LinearDRLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['casada', 'mage', 'medu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDRLearner(model_propensity=LogisticRegression(), \n",
    "                        model_regression=LinearRegression(),\n",
    "                        random_state=1)\n",
    "model.fit(Y=df[\"Y\"], T=df[\"Treated\"], X=X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e975a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ate_inference(X=X.values, T0=0, T1=1).summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bff262",
   "metadata": {},
   "source": [
    "O modelo nos dá diretamente o efeito médio do tratamento. A estimativa é estatisticamente diferente de zero e o intervalo de confiança inclui o valor verdadeiro de -229,17. Observe que obtivemos uma estimativa diferente porque a função **LinearDRLearner** também realizou o cross-fitting em segundo plano, o que não fizemos antes. Ele não calcula o ATT.\n",
    "\n",
    "Outro pacote importante é o \"causalml\" (https://causalml.readthedocs.io/en/latest/about.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf35ef",
   "metadata": {},
   "source": [
    "## Boas práticas\n",
    "\n",
    "* Verifique o balanço das covariáveis.\n",
    "  * Tanto o IPW quanto o DR (AIPW) foram desenvolvidos para ambientes nos quais o tratamento não é atribuído aleatoriamente incondicionalmente, mas pode depender de algumas variáveis observáveis. Essas informações podem ser verificadas de duas maneiras: \n",
    "    * (1) Produza uma tabela de médias/equilíbrio das covariáveis. Se a randomização incondicional não for válida, esperamos ver diferenças significativas entre alguns observáveis; \n",
    "    * (2) Trace os escores de propensão estimados. Se a randomização incondicional for válida, esperamos que os escores de propensão sejam constantes.\n",
    "* Verifique a suposição de sobreposição.\n",
    "  * Podemos simplesmente verificar os limites dos escores de propensão previstos. Se a suposição de sobreposição for violada, acabamos dividindo algum termo do estimador por zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
