{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664f1dd9",
   "metadata": {},
   "source": [
    "# Inverse Probability Weighting and Doubly Robust Estimation\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "## Conteúdo\n",
    "\n",
    "* Estimadores Baseados em Imputação\n",
    "  * Aplicação no Python\n",
    "* Outcome Regression\n",
    "  * Aplicação no Python\n",
    "* Doubly Robust Estimation\n",
    "  * Aplicação no Python\n",
    "* Boas Práticas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Observações:** O material apresentado aqui é uma adaptação do material de aula do Prof. Daniel de Abreu Pereira Uhr, e não deve ser utilizado para fins comerciais. O material é disponibilizado para fins educacionais e de pesquisa, e não deve ser reproduzido sem a devida autorização do autor. Este material pode conter erros e imprecisões. O autor não se responsabiliza por quaisquer danos ou prejuízos decorrentes do uso deste material. O uso deste material é de responsabilidade exclusiva do usuário. Caso você encontre erros ou imprecisões neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer *feedback* ou sugestão de melhoria.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093e748",
   "metadata": {},
   "source": [
    "## Propensity Score Weighting\n",
    "\n",
    "### Definição formal do Propensity Score\n",
    "\n",
    "O **Propensity Score** é definido como a probabilidade condicional de uma unidade receber o tratamento dado o vetor de covariáveis observadas:\n",
    "\n",
    "$$\n",
    "p(X_i) = \\Pr(D_i = 1 \\mid X_i)\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $D_i \\in \\{0, 1\\}$ é o indicador de tratamento;\n",
    "- $X_i$ é o vetor de covariáveis observadas.\n",
    "\n",
    "A ideia central de **Propensity Score Weighting** é reponderar a amostra de forma a criar uma população *pseudo‐randomizada*, em que a distribuição das covariáveis seja balanceada entre tratados e não tratados.\n",
    "\n",
    "## Inverse Probability of Treatment Weight (IPTW)\n",
    "\n",
    "### 1. Pesos para o **ATE** (Average Treatment Effect)\n",
    "\n",
    "O peso **IPTW** para o ATE é definido como:\n",
    "\n",
    "$$\n",
    "w_i^{ATE} = \\frac{D_i}{p(X_i)} + \\frac{1 - D_i}{1 - p(X_i)}\n",
    "$$\n",
    "\n",
    "**Na prática**:\n",
    "- Tratados ($D_i = 1$) recebem peso $1 / p(X_i)$  \n",
    "- Controles ($D_i = 0$) recebem peso $1 / (1 - p(X_i))$\n",
    "\n",
    "\n",
    "### 2. Pesos para o **ATT** (Average Treatment Effect on the Treated)\n",
    "\n",
    "O peso **IPTW** para o ATT é definido como:\n",
    "\n",
    "$$\n",
    "w_i^{ATT} = D_i + (1 - D_i) \\cdot \\frac{p(X_i)}{1 - p(X_i)}\n",
    "$$\n",
    "\n",
    "**Na prática**:\n",
    "- Tratados ($D_i = 1$) recebem peso = 1  \n",
    "- Controles ($D_i = 0$) recebem peso $p(X_i) / (1 - p(X_i))$\n",
    "\n",
    "\n",
    "### Interpretação dos pesos\n",
    "\n",
    "- **No ATE**:  \n",
    "  - Unidades tratadas com baixa probabilidade de tratamento recebem peso alto.  \n",
    "  - Unidades de controle com baixa probabilidade de não tratamento recebem peso alto.  \n",
    "\n",
    "- **No ATT**:  \n",
    "  - Tratados sempre têm peso 1.  \n",
    "  - Controles são reponderados para se assemelhar à distribuição de covariáveis dos tratados.\n",
    "\n",
    "### Hipóteses de identificação\n",
    "\n",
    "1. **Ignorabilidade (ou não confusão)**:  \n",
    "   $$\n",
    "   (Y_i(1), Y_i(0)) \\perp D_i \\mid X_i\n",
    "   $$  \n",
    "   Isto é, não existem confundidores não observados dados $X_i$.\n",
    "\n",
    "2. **Sobreposição (ou suporte comum)**:  \n",
    "   $$\n",
    "   0 < p(X_i) < 1 \\quad \\forall i\n",
    "   $$  \n",
    "   Cada unidade tem probabilidade positiva de receber ambos os estados de tratamento.\n",
    "\n",
    "### Estimação do efeito causal ponderado\n",
    "\n",
    "O **ATE ponderado** pode ser visto como:\n",
    "\n",
    "> Média ponderada dos resultados observados entre os tratados  \n",
    "> **menos**  \n",
    "> Média ponderada dos resultados observados entre os controles.\n",
    "\n",
    "Matematicamente:\n",
    "\n",
    "$$\n",
    "\\widehat{\\tau}_{ATE} =\n",
    "\\underbrace{\\frac{\\sum_{i=1}^n w_i^{ATE} D_i Y_i}{\\sum_{i=1}^n w_i^{ATE} D_i}}_{\\text{Média ponderada nos tratados}}\n",
    "-\n",
    "\\underbrace{\\frac{\\sum_{i=1}^n w_i^{ATE} (1-D_i) Y_i}{\\sum_{i=1}^n w_i^{ATE} (1-D_i)}}_{\\text{Média ponderada nos controles}}\n",
    "$$\n",
    "\n",
    "O **ATT** pode ser obtido substituindo $w_i^{ATE}$ por $w_i^{ATT}$ na fórmula acima, interpretando o resultado como efeito médio nos tratados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATE\n",
    "df['W_ATE'] = df['Treated'] / df['pscore'] + (1 - df['Treated']) / (1 - df['pscore'])\n",
    "\n",
    "# ATT\n",
    "df['W_ATT'] = df['Treated'] * 1 + (1 - df['Treated']) * (df['pscore'] / (1 - df['pscore']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b396ef9",
   "metadata": {},
   "source": [
    "## Doubly Robust Estimation (DR)\n",
    "\n",
    "A estimativa duplamente robusta combina uma forma de \"Outcome Regression\" com um modelo de ponderação (ou seja, utilizando o escore de propensão) para estimar o efeito causal sobre um resultado. Quando usados individualmente para estimar um efeito causal, os métodos de regressão de resultados e escore de propensão são não enviesados apenas se o modelo estatístico for especificado corretamente. O **estimador duplamente robusto** combina estas 2 abordagens de modo que apenas 1 dos 2 modelos precisa ser especificado corretamente para obter um estimador de efeito não-viesado.\n",
    "\n",
    "A especificação correta do modelo de regressão é um pressuposto fundamental na análise econométrica. Quando o objetivo é ajustar o fator de confusão, o estimador é consistente (e, portanto, assintoticamente não-enviesado) se o modelo refletir as verdadeiras relações entre a exposição e os fatores de confusão com o resultado. Na prática, nunca poderemos saber se algum modelo específico representa com precisão essas relações. **A estimativa duplamente robusta combina regressão de resultados com ponderação pelo escore de propensão (PS), de modo que o estimador seja robusto à especificação incorreta de um (mas não de ambos) desses modelos**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cdf6b2",
   "metadata": {},
   "source": [
    "**Outcome Regression Approach**\n",
    "\n",
    "Vimos que:\n",
    "\n",
    "$$ \\hat{\\beta}_{ATE}^{OR} = E[\\mu_{1}(X) - \\mu_{0}(X)] + E[(Y_{1} - \\mu_{1}(X)) - (Y_{0} - \\mu_{0}(X))] $$\n",
    "\n",
    "e\n",
    "\n",
    "$$ \\hat{\\beta}^{OR}_{ATT} = E[\\mu_{1}(X^{1}) - \\mu_{0}(X^{1})] + E[(Y_{1} - \\mu_{1}(X^{1})) - (Y_{0} - \\mu_{0}(X^{1}))] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fdfbc5",
   "metadata": {},
   "source": [
    "\n",
    "**Approach de Inverse Probability Weighting (IPW)**\n",
    "\n",
    "Nesta abordagem, o viés de confusão é ajustado por meio de técnicas de matching (pareamento) e ponderação pelo escore de propensão (Peso = $W$). As ponderações são calculadas da seguinte forma:\n",
    "\n",
    "$$ W_{ATE} = \\frac{D}{\\hat{p}(X)} + \\frac{1-D}{1-\\hat{p}(X)} $$\n",
    "\n",
    "e,\n",
    "\n",
    "$$ W_{ATT} = D + (1-D)\\frac{\\hat{p}(X)}{1-\\hat{p}(X)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b6470",
   "metadata": {},
   "source": [
    "**Approach do Doubly Robust Estimation (DR)**\n",
    "\n",
    "A abordagem Doubly Robust Estimation (DR) combina as vantagens das abordagens de Outcome Regression e de Ponderação pela Probabilidade Inversa. Isso proporciona uma maior robustez aos resultados. Os estimadores duplamente robustos para o Average Treatment Effect (ATE) e o Average Treatment Effect on the Treated (ATT) são dados pelas seguintes fórmulas:\n",
    "\n",
    "* **Doubly Robust Estimation for Average Treatment Effect (ATE)**\n",
    "\n",
    "$$ \\hat{\\beta_{ATE}^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) \\right] + \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6d4a3",
   "metadata": {},
   "source": [
    "* **Doubly Robust Estimation for Average Treatment Effect on the Treated (ATT)**\n",
    "\n",
    "$$ \\hat{\\beta_{ATT}^{DR}} = \\mathbb{E} \\left[ (\\mu_1 (X) - \\mu_0 (X)) \\right] + \\mathbb{E} \\left[ D(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)\\hat{p}(X)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c113ea",
   "metadata": {},
   "source": [
    "Repare que realizamos um \"ajuste\" nos resíduos da regressão de resultados, ponderando-os pelo escore de propensão. Isso garante que o estimador seja robusto à especificação incorreta de um dos modelos. O \"ajuste\" é essencialmente um estimador IPW realizado sobre os resíduos.\n",
    "\n",
    "Por isso que o Doubly Robust Estimation também é conhecido como Augmented Inverse Probability Weighting (AIPW)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b45f81",
   "metadata": {},
   "source": [
    "**Por que a o estimador Duplamente Robusto (*Augmented Inverse Probability Weighting* - AIPW) é tão atraente?**\n",
    "\n",
    "A razão é que só precisamos de uma das duas previsões, *$\\hat{\\mu}$* ou *$\\hat{p}$*, para que a estimativa seja correta (não enviesada/imparcial). \n",
    "* Se ambos os modelos estiverem corretos, o estimador será mais eficiente do que qualquer um dos modelos sozinho. \n",
    "* Se um dos modelos estiver errado, o estimador ainda será consistente, desde que o outro modelo esteja correto. \n",
    "\n",
    "Isso é uma grande vantagem em relação a outras abordagens, como a regressão de resultados ou a ponderação pelo escore de propensão, que exigem que ambos os modelos estejam corretos para que o estimador seja consistente.\n",
    "\n",
    "Suponha que $\\hat{\\mu}$ esteja especificado corretamente. Então $E[\\hat{\\mu}^{d}(x)=E[Y|X=x, D=d]$ , então o estimador DR é consistente, mesmo que o modelo de propensão $\\hat{p}$ esteja mal especificado.\n",
    "\n",
    "$$ \\hat{\\beta^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) +  \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$  =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$  =  \\mathbb{E} \\left[ Y^{1} - Y^{0} \\right] = $$\n",
    "\n",
    "$$ = \\beta $$\n",
    "\n",
    "A intuição é que, se $\\hat{\\mu}$ está **especificado corretamente é imparcial e o fator de ajuste desaparece**, uma vez que os resíduos convergem para zero.\n",
    "\n",
    "\n",
    "Por outro lado, suponha $\\hat{p}$ está especificado corretamente, ou seja, $E[\\hat{p}(X)]=P(D=1|X)$, então o estimador DR é consistente, mesmo que o modelo de resultados $\\hat{\\mu}$ esteja mal especificado.\n",
    "\n",
    "$$ \\hat{\\beta^{DR}} =  \\mathbb{E} \\left[ (\\mu_1(X) - \\mu_0 (X)) +  \\frac{D}{\\hat{p}(X)}.(Y_{1} - \\mu_1 (X)) - \\frac{(1-D)}{1-\\hat{p}(X)}.(Y_{0} - \\mu_0 (X)) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\mu_1(X) - \\mu_0 (X) + \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{D}{\\hat{p}(X)}.\\mu_1 (X) - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\frac{(1-D)}{1-\\hat{p}(X)}.\\mu_0 (X) \\right] = $$\n",
    "\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) - \\frac{D}{\\hat{p}(X)}.\\mu_1 (X) + \\frac{(1-D)}{1-\\hat{p}(X)}.\\mu_0 (X) - \\mu_0 (X) \\right] = $$\n",
    "\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) (1 - \\frac{D}{\\hat{p}(X)}) + \\mu_0 (X)(\\frac{(1-D)}{1-\\hat{p}(X)} - 1) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} + \\mu_1(X) (\\frac{\\hat{p}(X) - D}{\\hat{p}(X)}) + \\mu_0 (X)(\\frac{(1-D)- (1-\\hat{p}(X))}{1-\\hat{p}(X)}) \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ \\frac{D}{\\hat{p}(X)}.Y_{1} - \\frac{(1-D)}{1-\\hat{p}(X)}Y_{0} \\right] = $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ Y^{1} - Y^{0} \\right] = $$\n",
    "\n",
    "$$ = \\beta $$\n",
    "\n",
    "A intuição é que, se $\\hat{p}$ está especificado corretamente, o $\\hat{\\beta}^{DR}$ é imparcial e o fator de ajuste desaparece, uma vez que os resíduos ($D_{i}-\\hat{p}(X)$) convergem para zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d1973",
   "metadata": {},
   "source": [
    "### Aplicação em Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53e315",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d783f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33729140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logística para estimar o escore de propensão\n",
    "logit_model = smf.logit(\"Treated ~ 1 + casada + mage + medu\", data=df).fit()\n",
    "# Imprimindo o modelo\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o escore de propensão no DataFrame\n",
    "df['ps'] = logit_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fccb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar graficamente a área de sobreposição\n",
    "sns.histplot(data=df, x='ps', hue='Treated', bins=100, stat='density', common_norm=False).\\\n",
    "    set(ylabel=\"\", title=\"Distribution of Propensity Scores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6e16f",
   "metadata": {},
   "source": [
    "Agora vamos calcular os pesos IPW para o ATE e ATT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Probability of Treatment Weight (IPTW)\n",
    "\n",
    "# Peso para o efeito médio do tratamento (ATE)\n",
    "df['W1'] = 1 / df['ps']\n",
    "df.loc[df['Treated'] == 0, 'W1'] = 0\n",
    "df['W2'] = 1 / (1 - df['ps'])\n",
    "df.loc[df['Treated'] == 1, 'W2'] = 0\n",
    "\n",
    "# Peso para o efeito médio do tratamento nos tratados (ATT)\n",
    "df['W_ATE'] = df['W1'] + df['W2']\n",
    "df['W_ATT'] = df['ps'] / (1 - df['ps'])\n",
    "df.loc[df['Treated'] == 1, 'W_ATT'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d2c5f",
   "metadata": {},
   "source": [
    "A título de curiosidade, podemos estimar o efeito médio do tratamento para os tratados (ATT) e o efeito médio do tratamento (ATE) utilizando o método de Ponderação pelo Escore de Propensão (IPW). Para isso, basta rodar a regressão linear considerando como peso amostral os valores de $W_{ATE}$ e $W_{ATT}$, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0109f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propensity Score Weighting - ATE\n",
    "psw_ate = smf.wls(\"Y ~ Treated\", weights=df['W_ATE'], data=df).fit()\n",
    "print(psw_ate.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0746e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propensity Score Weighting - ATT\n",
    "psw_att = smf.wls(\"Y ~ Treated\", weights=df['W_ATT'], data=df).fit()\n",
    "print(psw_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4a910",
   "metadata": {},
   "source": [
    "Repare que podemos obter os mesmos resultados utilizando o pacote pyDRReg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "IPW_att = pyDRReg(df, X_vars, T_var, Y_var, method='att', estimator='IPW', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(IPW_att.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "IPW_ate = pyDRReg(df, X_vars, T_var, Y_var, method='ate', estimator='IPW', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(IPW_ate.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02f063",
   "metadata": {},
   "source": [
    "**Estimativa Duplamente Robusta**\n",
    "\n",
    "Agora temos todos os componentes para estimar o DR para ATE e o ATT, vamos fazer \"na mão\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DR-ATE\n",
    "DR_ATE = mu1 - mu0 + df[\"Treated\"] / df[\"ps\"] * (df[\"Y\"] - mu1) - (1-df[\"Treated\"]) / (1-df[\"ps\"]) * (df[\"Y\"] - mu0)\n",
    "print(np.mean(DR_ATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7192631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DR-ATT\n",
    "DR_ATT = mu1 - mu0 + df[\"Treated\"] * (df[\"Y\"] - mu1) - (1-df[\"Treated\"])*df[\"ps\"] / (1-df[\"ps\"]) * (df[\"Y\"] - mu0)\n",
    "print(np.mean(DR_ATT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb287c1",
   "metadata": {},
   "source": [
    "Podemos utilizar o pacote pyDRReg para obter os mesmos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "DR_ate = pyDRReg(df, X_vars, T_var, Y_var, method='ate', estimator='DR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(DR_ate.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDRReg.pyDRReg import pyDRReg\n",
    "\n",
    "T_var = 'Treated'\n",
    "Y_var = 'Y'\n",
    "X_vars = ['casada', 'mage', 'medu']\n",
    "\n",
    "DR_att = pyDRReg(df, X_vars, T_var, Y_var, method='att', estimator='DR', n_bootstrap=50, seed=44)\n",
    "\n",
    "print(DR_att.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721ad1b8",
   "metadata": {},
   "source": [
    "Esse tipo de estimador é bastante importante na literatura. E já possui alguns estimadores que realizam as estimações de forma direta. Por exemplo, poderíamos computar diretamente com 'LinearDRLearner' da biblioteca 'EconML' da Microsoft (EconML - Estimate causal effects with ML).\n",
    "\n",
    "obs: https://www.microsoft.com/en-us/research/project/econml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c76e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from econml.dr import LinearDRLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['casada', 'mage', 'medu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDRLearner(model_propensity=LogisticRegression(), \n",
    "                        model_regression=LinearRegression(),\n",
    "                        random_state=1)\n",
    "model.fit(Y=df[\"Y\"], T=df[\"Treated\"], X=X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e975a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ate_inference(X=X.values, T0=0, T1=1).summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bff262",
   "metadata": {},
   "source": [
    "O modelo nos dá diretamente o efeito médio do tratamento. A estimativa é estatisticamente diferente de zero e o intervalo de confiança inclui o valor verdadeiro de -229,17. Observe que obtivemos uma estimativa diferente porque a função **LinearDRLearner** também realizou o cross-fitting em segundo plano, o que não fizemos antes. Ele não calcula o ATT.\n",
    "\n",
    "Outro pacote importante é o \"causalml\" (https://causalml.readthedocs.io/en/latest/about.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf35ef",
   "metadata": {},
   "source": [
    "## Boas práticas\n",
    "\n",
    "* Verifique o balanço das covariáveis.\n",
    "  * Tanto o IPW quanto o DR (AIPW) foram desenvolvidos para ambientes nos quais o tratamento não é atribuído aleatoriamente incondicionalmente, mas pode depender de algumas variáveis observáveis. Essas informações podem ser verificadas de duas maneiras: \n",
    "    * (1) Produza uma tabela de médias/equilíbrio das covariáveis. Se a randomização incondicional não for válida, esperamos ver diferenças significativas entre alguns observáveis; \n",
    "    * (2) Trace os escores de propensão estimados. Se a randomização incondicional for válida, esperamos que os escores de propensão sejam constantes.\n",
    "* Verifique a suposição de sobreposição.\n",
    "  * Podemos simplesmente verificar os limites dos escores de propensão previstos. Se a suposição de sobreposição for violada, acabamos dividindo algum termo do estimador por zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
