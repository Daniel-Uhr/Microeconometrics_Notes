{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching, Mahalanobis Distance Matching (MDM), e Propensity Score Matching (PSM)\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "### Conteúdo\n",
    "\n",
    "* Causalidade\n",
    "  * Revisão Breve dos \"Directed Acyclic Graphs\" (DAGs)\n",
    "  * Selection Bias em Variáveis Observáveis\n",
    "  \n",
    "* Matching (Correspondência)\n",
    "  * Correspondência Exata\n",
    "  * Correspondência Aproximada\n",
    "  * Hipóteses de Identificação para o Matching\n",
    "  * Aumentando a Dimensão do Espaço de Características\n",
    "    * Mahalanobis Distance Matching (MDM)\n",
    "    * Propensity Score Matching (PSM)\n",
    "    * MDM ou PSM?\n",
    "* Aplicação na Literatura\n",
    "* Aplicação em Python\n",
    "  * PSM\n",
    "  * MDM\n",
    "\n",
    "\n",
    "### Referências\n",
    "\n",
    "* Morgan, S. L., & Winship, C. (2014). Counterfactuals and causal inference: Methods and principles for social research. Cambridge University Press. Capítulo 3.\n",
    "* Cunningham, S. W. (2013). Causal inference: The mixtape. https://www.scunning.com/mixtape.html\n",
    "* Pearl, J. (2000). Causality: Models, reasoning, and inference. Cambridge University Press.\n",
    "* Joshua D. Angrist and Jörn-Steffen Pischke (2009). Mostly Harmless Econometrics: An Empiricist's Companion. Princeton University Press.\n",
    "* Hirano, K and Imbens, G. (2004). The Propensity Score with Continuous Treatments. In Applied Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives, Andrew Gelman and Xiao-Li Meng (eds.), Wiley, New York.\n",
    "* Kennedy EH, Ma Z, McHugh MD, Small DS. Nonparametric methods for doubly robust estimation of continuous treatment effects. Journal of the Royal Statistical Society, Series B. 79(4), 2017, pp.1229-1245.\n",
    "* Moodie E and Stephens DA. Estimation of dose–response functions for longitudinal data using the generalised propensity score. In: Statistical Methods in Medical Research 21(2), 2010, pp.149–166.\n",
    "* van der Laan MJ and Gruber S. Collaborative double robust penalized targeted maximum likelihood estimation. In: The International Journal of Biostatistics 6(1), 2010.\n",
    "* van der Laan MJ and Rubin D. Targeted maximum likelihood learning. In: ​U.C. Berkeley Division of Biostatistics Working Paper Series, 2006.\n",
    "* Marques, M. L. V.; Uhr, D. A. P.; Benevit, B.; Uhr, J. G. Z. An analysis of the relationship between rental housing and adoption of self-generating energy sources in Brazil using matching methodology. Journal of International Development, v. 36, p. 1570-1592, 2024.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Observações:** O material apresentado aqui é uma adaptação do material de aula do Prof. Daniel de Abreu Pereira Uhr, e não deve ser utilizado para fins comerciais. O material é disponibilizado para fins educacionais e de pesquisa, e não deve ser reproduzido sem a devida autorização do autor. Este material pode conter erros e imprecisões. O autor não se responsabiliza por quaisquer danos ou prejuízos decorrentes do uso deste material. O uso deste material é de responsabilidade exclusiva do usuário. Caso você encontre erros ou imprecisões neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer *feedback* ou sugestão de melhoria.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causalidade\n",
    "\n",
    "#### Revisão Breve dos \"Directed Acyclic Graphs\" (DAGs)\n",
    "\n",
    "O DAG é uma ferramenta gráfica que permite representar as relações causais entre variáveis. O DAG é uma representação gráfica de um conjunto de equações estruturais. O DAG é acíclico, ou seja, não possui ciclos. O DAG é uma ferramenta poderosa para identificar relações causais.\n",
    "\n",
    "Vamos supor que queremos avaliar o efeito de uma variável $D$ sobre uma variável $Y$. Entretanto, outra variável $X$ afeta a decisão de $D$ e também afeta $Y$. Neste caso, $X$ é uma variável de confusão (*Confounding Variable*). O DAG é uma ferramenta que permite visualizar as relações causais entre as variáveis. Vejamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o pacote para fazer a visualização do grafo\n",
    "import graphviz as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- D -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>D&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.54,-72.05C36.52,-64.32 40.13,-54.96 43.48,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"46.65,-47.79 46.98,-37.2 40.12,-45.27 46.65,-47.79\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-156.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;D -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>X&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.46,-144.05C44.48,-136.32 40.87,-126.96 37.52,-118.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.88,-117.27 34.02,-109.2 34.35,-119.79 40.88,-117.27\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.32,-63.97 61.08,-55.33 59.73,-47.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.17,-46.79 57.93,-37.58 56.29,-48.05 63.17,-46.79\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x23df1aca6d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grafo indicando a variável de tratamento D, e um confounding X, e a variável de resultado Y\n",
    "g = gr.Digraph()\n",
    "g.edge(\"D\", \"Y\")\n",
    "g.edge(\"X\", \"D\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos supor que queremos avaliar o efeito de uma variável $D$ sobre uma variável $Y$. Entretanto, outra variável $U$ não observável pelo pesquisador afeta a decisão de $D$ e também afeta $Y$. Neste caso, $U$ também uma variável de confusão (*Confounding Variable*) não observável. Novamente, o DAG é uma ferramenta que permite visualizar as relações causais entre as variáveis. Vejamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- D -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>D&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.54,-72.05C36.52,-64.32 40.13,-54.96 43.48,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"46.65,-47.79 46.98,-37.2 40.12,-45.27 46.65,-47.79\"/>\n",
       "</g>\n",
       "<!-- U -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>U</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-156.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">U</text>\n",
       "</g>\n",
       "<!-- U&#45;&gt;D -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>U&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M47.46,-144.05C44.48,-136.32 40.87,-126.96 37.52,-118.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.88,-117.27 34.02,-109.2 34.35,-119.79 40.88,-117.27\"/>\n",
       "</g>\n",
       "<!-- U&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>U&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.32,-63.97 61.08,-55.33 59.73,-47.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.17,-46.79 57.93,-37.58 56.29,-48.05 63.17,-46.79\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x23df1af7dd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grafo indicando a variável de tratamento D, e um confounding U, e a variável de resultado Y\n",
    "g = gr.Digraph()\n",
    "g.edge(\"D\", \"Y\")\n",
    "g.edge(\"U\", \"D\", style=\"dashed\")\n",
    "g.edge(\"U\", \"Y\", style=\"dashed\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **viés de seleção** (*Selection Bias*) ocorre quando a amostra utilizada para análise não é representativa da população-alvo devido a um processo de seleção que está relacionado tanto à variável de tratamento quanto ao resultado. Isso pode levar a estimativas enviesadas dos efeitos causais, uma vez que as diferenças observadas entre os grupos podem ser atribuídas ao processo de seleção, e não ao efeito do tratamento em si. Por exemplo:\n",
    "\n",
    "* **Autoseleção no Tratamento**: Os indivíduos podem optar por participar ou aderir a um determinado tratamento com base em suas características ou preferências pessoais. Ou seja, os participantes que optam por aderir ao tratamento podem ter características diferentes daqueles que optam por não aderir. Isso pode levar a uma amostra de tratamento que não é representativa da população em geral.\n",
    "  \n",
    "* **Viés de desistência** (Atrito): Quando os participantes desistem ou abandonam um tratamento antes da conclusão do estudo, isso pode introduzir um viés, especialmente se a desistência estiver relacionada à eficácia ou tolerabilidade do tratamento.\n",
    "\n",
    "\n",
    "**Definições adicionais importantes**\n",
    "\n",
    "* **Tratamento \"Não Ignorável\" (Non-Ignorable Treatment)**: Um tratamento é considerado \"não ignorável\" quando a **associação entre o tratamento e o resultado não pode ser controlada ou ajustada apenas pelas variáveis observadas**. Nesses casos, há a **presença de confundimento não observado** ou variáveis latentes que afetam tanto a seleção do tratamento quanto o resultado, e não podem ser ignorados ao estimar o efeito causal. \n",
    "\n",
    "* **Tratamento \"Ignorável\" (Ignorable Treatment)**: Um tratamento é considerado \"ignorável\" se a associação entre o tratamento (a variável de exposição) e o resultado (a variável de interesse) pode ser adequadamente controlada ou ajustada por meio de outras variáveis observadas. Em outras palavras, se as condições de ignorabilidade são satisfeitas, podemos confiar nas estimativas dos efeitos causais mesmo sem observar todas as variáveis relevantes. Isso é fundamental para a inferência causal em estudos observacionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection Bias em Variáveis Observáveis\n",
    "\n",
    "Pelos exemplos de DAGs vistos anteriormente, podemos perceber que a seleção de tratamento pode ser influenciada por variáveis observáveis e não observáveis. Nestes casos, a seleção pela realização do tratamento é endógena e decore de duas situações:\n",
    "\n",
    "* **Seleção em Observáveis (Selection on Observables):** A seleção em observáveis refere-se à situação em que a seleção das unidades para um tratamento ($D$) é influenciada por variáveis observáveis ($X$). Em outras palavras, as características ou atributos conhecidos das unidades afetam a probabilidade de serem selecionadas para receber o tratamento. Nesse cenário, é possível controlar o viés resultante ao levar em consideração e ajustar as diferenças nas características observáveis entre os grupos de tratamento e controle. Em outras palavras, os componentes observáveis influenciam a seleção para o tratamento (auto-seleção) e o resultado ($Y$).\n",
    "\n",
    "* **Seleção em Não-Observáveis (Selection on Unobservables):** A seleção em não-observáveis ocorre quando a seleção das unidades para o tratamento é influenciada por variáveis não observadas que não estão disponíveis para o pesquisador. Essas variáveis não observadas podem estar correlacionadas tanto com a seleção para o tratamento quanto com o resultado, levando a um viés não observável. Em outras palavras, algum(s) componente(s) do termo não observado ($U$) influencia tanto a seleção para o tratamento (auto-seleção) quanto o resultado ($Y$). Nesse cenário, não é possível controlar o viés resultante, mesmo que todas as variáveis observáveis sejam levadas em consideração e ajustadas.\n",
    "\n",
    "Nessa aula vamos assumir a hipótese de **seleção em observáveis**. E vamos discutir estratégias para controlar o viés de seleção em variáveis observáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hipóteses de Identificação para o Matching\n",
    "\n",
    "Ao realizar o procedimento de correspondência, fazemos três suposições importantes. \n",
    "\n",
    "* **Independência condicional** (*unconfoundedness*, *ignorability*, ou *selection on observables*): \n",
    "$$ (Y^{1}, Y^{0}) \\perp D | X$$\n",
    "\n",
    "Ou seja, condicional nas covariáveis, a atribuição do tratamento é tão boa quanto um experimento aleatório. Essa é uma suposição forte, que tem maior probabilidade de ser verdadeira quando temos um grande número de covariáveis. Principalmente, na linguagem de Judea Pearl, aquelas que cumprem o critério de *backdoor*.\n",
    "\n",
    "* **Suporte Comum** (sobreposição, *common support*):\t\n",
    "$$ 0  \\leqslant  Pr(D=1|X)  \\leqslant  1 $$\n",
    "\n",
    "Ou seja, para cada valor de $X$, a probabilidade de tratamento deve estar entre 0 e 1. Nenhuma unidade é atribuída a um tratamento ou controle de forma determinística. Significa que, para cada valor de $X$, temos unidades tratadas e não tratadas. A figura a seguir mostra um exemplo possível de área de suporte comum.\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\suportecomum.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "* **Valor de Tratamento Unitário Estável - SUTVA** (*SUTVA - Stable Unit Treatment Value Assumption*):\n",
    "\n",
    "$$ Y_{i}^{d} \\perp D $$\n",
    "\n",
    "O Valor de Tratamento Unitário Estável (SUTVA - Stable Unit Treatment Value Assumption) é uma das suposições fundamentais em modelos de inferência causal. Ela garante que possamos identificar efeitos causais de forma clara e não enviesada. \n",
    "\n",
    "A suposição do SUTVA é composta por dois componentes principais:\n",
    "\n",
    "* **Não interferência entre unidades:** Isso significa que o resultado de uma unidade (por exemplo, um indivíduo ou uma empresa) não é afetado pelo tratamento que outras unidades recebem. Ou seja, o tratamento de uma unidade não pode interferir no resultado de outra.\n",
    "* **Valor do tratamento é único:** Significa que o tratamento é bem definido e aplicável da mesma maneira a todas as unidades. Não há variações ou ambiguidade no tipo ou na intensidade do tratamento aplicado.\n",
    "\n",
    "Quando o SUTVA é válido, podemos dizer que o efeito do tratamento em uma unidade *i* só depende de se a própria unidade *i* recebeu ou não o tratamento, e não de como o tratamento foi aplicado a outras unidades.\n",
    "\n",
    "Ou seja, o resultado potencial não depende do estado do tratamento. A configuração mais comum do SUTVA é violado quando há vazamento de tratamento, ou seja, quando o tratamento de uma unidade afeta o resultado de outra unidade (Efeitos de *spillover*, ou de rede)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare na tabela:\n",
    "\n",
    "\n",
    "| Unidade (Estagiários) | Idade | Ganhos  | Unidade (Não-estagiários) | Idade | Ganhos  |\n",
    "|-----------------------|-------|---------|--------------------------|-------|---------|\n",
    "| 1                     | 18    | 9500    | 1                        | 20    | 8500    |\n",
    "| 2                     | 29    | 12250   | 2                        | 27    | 10075   |\n",
    "| 3                     | 24    | 11000   | 3                        | 21    | 8725    |\n",
    "| 4                     | 27    | 11750   | 4                        | 39    | 12775   |\n",
    "| 5                     | 33    | 13250   | 5                        | 38    | 12550   |\n",
    "| 6                     | 22    | 10500   | 6                        | 29    | 10525   |\n",
    "| 7                     | 19    | 9750    | 7                        | 39    | 12775   |\n",
    "| 8                     | 20    | 10000   | 8                        | 33    | 11425   |\n",
    "| 9                     | 21    | 10250   | 9                        | 24    | 9400    |\n",
    "| 10                    | 30    | 12500   | 10                       | 30    | 10750   |\n",
    "| 11                    | 33    | 11425   |                          |       |         |\n",
    "| 12                    | 36    | 12100   |                          |       |         |\n",
    "| 13                    | 22    | 8950    |                          |       |         |\n",
    "| 14                    | 18    | 8050    |                          |       |         |\n",
    "| 15                    | 43    | 13675   |                          |       |         |\n",
    "| 16                    | 39    | 12775   |                          |       |         |\n",
    "| 17                    | 19    | 8275    |                          |       |         |\n",
    "| 18                    | 30    | 9000    |                          |       |         |\n",
    "| 19                    | 51    | 15475   |                          |       |         |\n",
    "| 20                    | 48    | 14800   |                          |       |         |\n",
    "| **Média**             | **24,3** | **11.075** | **Média**                | **31,95** | **11.101,25** |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Hipóteses de Identificação para o Matching\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aumentando a Dimensão do Espaço de Características\n",
    "\n",
    "A correspondência em uma única covariável é simples porque a distância é medida em termos dos próprios valores da covariável ($X$). Por exemplo, a distância em idade é simplesmente o quão perto em anos, meses ou dias uma pessoa está de outra pessoa. Mas e se tivermos várias covariáveis ​​necessárias para a correspondência? Digamos, idade e renda. Uma mudança de 1 ponto na idade é muito diferente de uma mudança de 1 ponto no logaritmo da renda, sem mencionar que agora estamos medindo a distância em duas, e não em uma, dimensões. **Quando o número de covariáveis ​​correspondentes é maior que um, precisamos de uma nova definição de distância para medir a proximidade**. \n",
    "\n",
    "\n",
    "#### Mahalanobis Distance Matching (MDM)\n",
    "\n",
    "**Distância Euclidiana**\n",
    "\n",
    "Começamos com a medida de distância mais simples, a **distância euclidiana**.\n",
    "\n",
    "$$ || X_{i} - X_{j} || = \\sqrt{(X_{i}- X_{j})´(X_{i}- X_{j})} $$\n",
    "\n",
    "$$ || X_{i} - X_{j} || = \\sqrt{\\sum_{k=1}^{K}(X_{i,k}- X_{j,k})^{2}} $$\n",
    "\n",
    "O problema com esta medida de distância é que a própria medida de distância depende da escala das próprias variáveis. Por esta razão, os pesquisadores normalmente usarão alguma modificação da distância euclidiana, como a distância euclidiana normalizada , ou usarão uma distância alternativa totalmente diferente. \n",
    "\n",
    "**Distância Euclidiana Normalizada**\n",
    "\n",
    "A distância euclidiana normalizada é uma distância comumente usada, e o que a torna diferente é que a distância de cada variável é dimensionada pela variância da variável. A distância é medida como:\n",
    "\n",
    "$$ || X_{i} - X_{j} || = \\sqrt{(X_{i}- X_{j})´ \\hat{V}^{-1} (X_{i}- X_{j})} $$\n",
    "\n",
    "onde \n",
    "\n",
    "$$ \\hat{V}^{-1} = \\left [ \\begin{array}{ccc}\n",
    "\\hat{\\sigma}_{1}^{2} & 0 & \\dots & 0 \\\\\n",
    "0 & \\hat{\\sigma}_{2}^{2} & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & \\hat{\\sigma}_{K}^{2} \\\\\n",
    "\\end{array} \\right ] $$\n",
    "\n",
    "Observe que a distância euclidiana normalizada é igual a:\n",
    "\n",
    "$$ || X_{i} - X_{j} || = \\sqrt{\\sum_{k=1}^{K}\\left ( \\frac{X_{i,k}- X_{j,k}}{\\hat{\\sigma}_{k}^{2}} \\right )} $$\n",
    "\n",
    "Assim, se houver mudanças na escala de $X$, essas mudanças também afetam sua variância e, portanto, a distância euclidiana normalizada não muda.\n",
    "\n",
    "\n",
    "**Distância de Mahalanobis**\n",
    "\n",
    "Finalmente, existe a distância de Mahalanobis , que, como a medida de distância euclidiana normalizada, é uma métrica de distância invariante à escala. Isso é:\n",
    "\n",
    "$$ || X_{i} - X_{j} || = \\sqrt{(X_{i}- X_{j})´ \\hat{\\Sigma}_{X}^{-1} (X_{i}- X_{j})} $$\n",
    "\n",
    "onde $\\Sigma_{X}^{-1}$ é a matriz de covariância da amostra de $X$.\n",
    "\n",
    "Basicamente, mais de uma covariável cria o problema da maldição da dimensionalidade, e, também torna a medição da distância mais difícil. Tudo isso cria alguns desafios para encontrar uma boa correspondência nos dados. Como você pode ver em cada uma dessas fórmulas de distância, às vezes haverá discrepâncias de correspondência.\n",
    "\n",
    "Às vezes $ X_{i} \\neq X_{j} $. O que isto significa? Isso significa que alguma unidade $i$ foi combinado com alguma unidade $j$ com base em um valor de covariável semelhante de $X=x$. Talvez unidade $i$ tem 25 anos, mas unidade $j$ tem 26 anos. A diferença é 1. Às vezes as discrepâncias são pequenas, às vezes zero, às vezes grandes. Mas, à medida que se afastam de zero, tornam-se mais problemáticos para a nossa estimativa e introduzem enviesamentos.\n",
    "\n",
    "**Quanto maior a dimensão, maior a probabilidade de discrepâncias correspondentes e mais dados serão necessários. Então você pode levar isso ao banco – muito provavelmente, seu problema de correspondência requer um grande conjunto de dados para minimizar as discrepâncias de correspondência.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Ideia do Estimador de Mahalanobis Distance Matching (MDM)**\n",
    "\n",
    "O MDM funciona emparelhando unidades próximas com base em uma distância chamada distância de Mahalanobis, que você pode imaginar como uma distância euclidiana sem escala. \n",
    "\n",
    "Para que duas unidades tenham uma distância de Mahalanobis de 0, elas devem ter valores covariáveis ​​idênticos. Quanto mais diferentes os valores das covariáveis, maior a distância de Mahalanobis. \n",
    "\n",
    "A ideia é que, se você encontrar unidades de controle próximas às unidades tratadas na distância de Mahalanobis, cada par terá valores de covariáveis ​​semelhantes, e a distribuição das covariáveis ​​nos grupos de tratamento na amostra pareada será semelhante.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\maha1.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\maha2.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\maha3.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\maha4.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\maha5.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propensity Score Matching \n",
    "\n",
    "Existem várias maneiras de alcançar a estratégia de condicionamento implícita no critério backdoor, e discutimos várias delas. Mas um método popular foi desenvolvido por Donald Rubin em meados da década de 1970 até o início da década de 1980, chamado **método de escore de propensão** (*Propensity Score Matching* - Rubin 1977 ; Rosenbaum e Rubin 1983 ).\n",
    "\n",
    "O escore de propensão é semelhante em muitos aspectos ao emparelhamento de covariáveis ​​do vizinho mais próximo de Abadie e Imbens (2006) e à subclassificação. É um método muito popular, especialmente nas ciências médicas, para abordar a seleção em observáveis, e também ganhou uso entre os economistas ( Dehejia e Wahba 2002 ) .\n",
    "\n",
    "Apesar da excitação inicial causada por Dehejia e Wahba ( 2002 ) , o entusiasmo subsequente foi mais moderado ( Smith e Todd 2001 , 2005 ; King e Nielsen 2019 ). Como tal, a correspondência do escore de propensão não tem sido tão amplamente adotada entre os economistas como em outros métodos não experimentais, como a descontinuidade de regressão ou a diferença em diferenças. A razão mais comum apresentada para isto é que os economistas são muitas vezes céticos de que a CIA possa ser alcançada em qualquer conjunto de dados – quase como um artigo de fé. \n",
    "\n",
    "Isto ocorre porque, para muitas aplicações, os economistas, como grupo, **estão geralmente mais preocupados com a seleção de inobserváveis ​​do que com a seleção de observáveis** ​​e, como tal, recorrem a métodos de correspondência com menos frequência. Mas sou agnóstico quanto à questão de saber se a CIA detém ou não a sua aplicação específica. Não há razão teórica para rejeitar um procedimento concebido para estimar efeitos causais sobre algum princípio ad hoc que se sustenta devido a um palpite. \n",
    "\n",
    "Somente o conhecimento prévio e a profunda familiaridade com os detalhes institucionais da sua aplicação podem lhe dizer qual é a estratégia de identificação apropriada e, na medida em que o critério backdoor pode ser atendido, então os métodos de correspondência podem ser perfeitamente apropriados. E se não for possível, então a correspondência é inadequada. \n",
    "\n",
    "**Propensity Score**\n",
    "\n",
    "O \"escore de propensão\" ou \"índice de propensão\" é a probabilidade de um indivíduo ser tratado, dado um conjunto de covariáveis. O escore de propensão é uma pontuação que resume as covariáveis ​​em um único número. A ideia é que, se você conhece o escore de propensão de um indivíduo, você conhece todas as informações relevantes sobre as covariáveis ​​que determinam a probabilidade de tratamento.\n",
    "\n",
    "\n",
    "**Hipóteses de Identificação**\n",
    "\n",
    "* **Independência condicional** (*unconfoundedness*, *ignorability*, ou *selection on observables*).\n",
    "  * $(Y(0), Y(1)) \\perp D_{i} | X_{i}$ não é testável. Como vimos anteriormente, a suposição de independência condicional significa simplesmente que o critério backdoor é atendido nos dados por meio do condicionamento em um vetor $X$.\n",
    "\n",
    "* **Suporte Comum** (sobreposição, common support):\t\n",
    "  * $0 < Pr(D=1|X) < 1$ para todo $X$. Isto significa simplesmente que, para qualquer probabilidade, deve haver unidades tanto no grupo de tratamento como no grupo de controle.\n",
    "\n",
    "* **Valor de Tratamento Unitário Estável** (SUTVA - Stable Unit Treatment Value Assumption):\n",
    "  * $ Y_{i}^{d} \\perp D $\n",
    "\n",
    "\n",
    "**Teorema do escore de propensão**\n",
    "\n",
    "A partir das hipóteses de identificação, obtemos o **teorema do escore de propensão**, que afirma que sob a CIA, \n",
    "\n",
    "$$(Y(0), Y(1)) \\perp D_{i} | X_{i}$$\n",
    "\n",
    "se a suposição de ignorabilidade forte for válida, é suficiente condicionar a análise à probabilidade de tratamento, o escore de propensão , para ter independência condicional:\n",
    "\n",
    "$$(Y(0), Y(1)) \\perp D_{i} | p(X)$$\n",
    "\n",
    "onde $p(X)$ é o indice de propensão. Isso significa que para alcançar a independência, assumindo a CIA, basta condicionar no escore de propensão. O condicionamento no escore de propensão é suficiente para haver independência entre o tratamento e os resultados potenciais.\n",
    "\n",
    "O resultado de Rosenbaum e Rubin (1983) é incrivelmente poderoso e prático, uma vez que o índice de propensão é uma variável unidimensional , enquanto $X$\n",
    "pode ter muitas dimensões.\n",
    "\n",
    "O teorema do escore de propensão diz que **você só precisa controlar as covariáveis ​​que determinam a probabilidade de uma unidade receber o tratamento**. Mas também diz algo mais do que isso. Tecnicamente, diz que a única covariável à qual você precisa condicionar é o índice de propensão. Todas as informações do $X$. A matriz foi resumida em um único número: o índice de propensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"92pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 92.11 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 88.11,-256 88.11,4 -4,4\"/>\n",
       "<!-- D -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"55\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>D&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.36,-72.41C45.23,-64.57 41.4,-54.99 37.85,-46.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"41.11,-44.86 34.15,-36.88 34.61,-47.46 41.11,-44.86\"/>\n",
       "</g>\n",
       "<!-- p(X) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>p(X)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56\" cy=\"-162\" rx=\"28.11\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-156.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">p(X)</text>\n",
       "</g>\n",
       "<!-- p(X)&#45;&gt;D -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>p(X)&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M55.75,-143.7C55.65,-136.41 55.52,-127.73 55.41,-119.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.91,-119.57 55.27,-109.62 51.91,-119.67 58.91,-119.57\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"28\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"28\" y=\"-228.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M24.35,-215.91C22.32,-205.57 20.02,-192.09 19,-180 14.97,-132.17 15.41,-119.87 19,-72 19.6,-63.99 20.71,-55.35 21.91,-47.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"25.35,-48.04 23.51,-37.61 18.45,-46.91 25.35,-48.04\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;p(X) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>X&#45;&gt;p(X)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.64,-216.41C37.73,-208.68 41.49,-199.27 44.99,-190.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.19,-191.95 48.66,-181.36 41.69,-189.35 48.19,-191.95\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x23df1abde90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando o pacote\n",
    "import graphviz as gr\n",
    "\n",
    "# Gráfico indicando as variáveis e suas relações\n",
    "g = gr.Digraph()\n",
    "g.edge(\"D\", \"Y\")\n",
    "g.edge(\"p(X)\", \"D\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"X\", \"p(X)\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então ao condicionarmos no escore de propensão fechamos um caminho de porta dos fundos e obtemos estimativas não enviesadas do efeito causal. Mas como podemos estimar o escore de propensão?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Ideia do Estimador de Correspondência pelo Escore de Propensão**\n",
    "\n",
    "As versões de amostra do ATE e do ATT são obtidas por um procedimento de estimativa em duas etapas. Na primeira etapa, o pesquisador estima o escore de propensão usando logit ou probit. Na segunda etapa, o pesquisador utiliza a pontuação estimada para produzir versões amostrais de um dos estimadores médios do efeito do tratamento.\n",
    "\n",
    "Podemos utilizar algumas estratégias a partir do escore de propensão:\n",
    "* Aproximar os indivíduos do grupo de controle aos indivíduos do grupo de tratados.\n",
    "* Aproximar apenas um indivíduo do grupo de controle para cada indivíduo do grupo de tratados.\n",
    "* Utilizar o escore de propensão como um peso para estimar o ATT e o ATE (Propensity Score Weighting).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo**\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\psm1.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\psm2.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\psm3.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\psm4.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\psm5.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\psm6.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O PSM funciona emparelhando unidades que possuem escores de propensão semelhantes (probabilidades). \n",
    "\n",
    "Os escores de propensão reduzem toda a distribuição de covariáveis ​​em uma única dimensão; isso significa que duas unidades com escores de propensão semelhantes não necessariamente terão valores de covariáveis ​​semelhantes. \n",
    "No entanto, devido às propriedades teóricas de equilíbrio do escore de propensão, o PSM ainda pode produzir amostras equilibradas, mesmo que qualquer par de unidades combinadas individuais possa não ter valores covariáveis ​​semelhantes.\n",
    "\n",
    "Segundo King e Nielsen (2019), o procedimento de escore de propensão aproximou a amostra observacional inicial à uma amostra randomizada.\n",
    "\n",
    "**É importante notar que dependendo da métrica de aproximação do escore de propensão, temos uma redução maior ou menor na nossa base de dados.**\n",
    "\n",
    "Existem várias métricas para limitar a redução da base de dados, como:\n",
    "* Nearest Neighbor Matching (NN): É possível limitar a redução da base de dados ao escolher o número de vizinhos mais próximos que serão utilizados para a correspondência.\n",
    "* Caliper Matching: É possível limitar a redução da base de dados ao escolher o caliper de correspondência. O caliper é uma restrição que impede que as unidades sejam emparelhadas se a diferença entre os escores de propensão for muito grande.\n",
    "* Kernel Matching: É possível limitar a redução da base de dados ao escolher o tamanho da janela de kernel.\n",
    "* Radius Matching: É possível limitar a redução da base de dados ao escolher o raio de correspondência.\n",
    "\n",
    "\n",
    "Mesmo que a amostra de grupo de controle fosse muito superior aos tratados, o procedimento não garante que serão escolhidos os indivíduos com matching perfeito, entretanto será escolhida a amostra que aproxima à aleatorização.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDM vs PSM?**\n",
    "\n",
    "King & Nielsen (2019) argumentam que o PSM pode produzir estimativas frágeis e não robustas que podem variar muito dependendo do modelo usado. \n",
    "Em particular, se você descartar progressivamente unidades que estão distantes umas das outras (ou seja, impondo um calibre cada vez mais apertado), eventualmente o equilíbrio começa a piorar com o PSM, mesmo que as unidades próximas no PS permaneçam. \n",
    "Eles chamam isso de paradoxo do propensity score, que é a motivação para recomendar métodos potencialmente mais robustos como MDM que aproximam diretamente no espaço de covariáveis. \n",
    "\n",
    "Então, devemos evitar o PSM e manter o MDM? \n",
    "\n",
    "Não. \n",
    "\n",
    "Rippolone et al. (2018) investigaram o impacto do paradoxo do propensity score em dados epidemiológicos reais. Eles descobriram que, embora o paradoxo ocorresse com alguns dados, não era problemático até que valores extremos de calibre fossem usados, muito além do que seria recomendado. \n",
    "O PSM geralmente rendeu bom equilíbrio nas covariáveis. Em contraste, o MDM produziu um equilíbrio ruim em um conjunto de dados, às vezes até pior com nenhuma correspondência.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação na Literatura\n",
    "\n",
    "Vejamos um artigo recente que aplica PSM: MARQUES, M. L. V. ; UHR, D. A. P. ; BENEVIT, B. ; UHR, J. G. Z. An analysis of the relationship between rental housing and adoption of self-generating energy sources in Brazil using matching methodology. **Journal of International Development**, v. 36, p. 1570-1592, 2024.\n",
    "\n",
    "É importante verificar a estrutura de apresentação do artigo, como a metodologia e explorada, e posteriormente a apresentação dos resultados e estratégia de Robustez. Entendo que esse artigo é um ótimo modelo de como apresentar um estudo que utiliza o PSM.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\Artigo_PSM.png\"  alt=\"Imagem\" style=\"width: 500px;\"/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação em Python\n",
    "\n",
    "#### PSM\n",
    "\n",
    "Vamos utilizar o Python, e entender um pouco sobre possíveis aplicações do PSM. Vamos utilizar nosso exemplo das gestantes que fumam e não fumam. A ideia é entender como o PSM pode ser utilizado para estimar o efeito do tratamento. As aplicações aqui não são exaustivas, e a ideia é apenas ilustrar como o PSM pode ser utilizado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar o data frame e construir algumas variáveis para a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from causalinference import CausalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"https://github.com/Daniel-Uhr/data/raw/main/cattaneo2.dta\")\n",
    "\n",
    "# Criar a variável de resultado\n",
    "df['Y'] = df['bweight']\n",
    "\n",
    "# Crie a variável 'Treated' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'Treated' para 1 se 'mbsmoke' for igual a 'smoker'\n",
    "df.loc[df['mbsmoke'] == 'smoker', 'Treated'] = 1\n",
    "\n",
    "df['casada'] = 0\n",
    "df.loc[df['mmarried']=='married', 'casada'] = 1\n",
    "\n",
    "# gerar uma variável de contagem de linhas iniciando em 1\n",
    "df['id'] = np.arange(len(df)) + 1\n",
    "\n",
    "# Conjunto de Covariáveis X\n",
    "X = ['casada', 'mage', 'medu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CausalModel(\n",
    "    Y=df[\"Y\"].values, \n",
    "    D=df[\"Treated\"].values, \n",
    "    X=df[['casada', 'mage', 'medu']].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treatment Effect Estimates: OLS\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE   -219.323     22.438     -9.775      0.000   -263.302   -175.345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.est_via_ols(adj=1)\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics\n",
      "\n",
      "                      Controls (N_c=3778)         Treated (N_t=864)             \n",
      "       Variable         Mean         S.d.         Mean         S.d.     Raw-diff\n",
      "--------------------------------------------------------------------------------\n",
      "              Y     3412.912      570.687     3137.660      560.893     -275.252\n",
      "\n",
      "                      Controls (N_c=3778)         Treated (N_t=864)             \n",
      "       Variable         Mean         S.d.         Mean         S.d.     Nor-diff\n",
      "--------------------------------------------------------------------------------\n",
      "             X0        0.751        0.432        0.473        0.500       -0.595\n",
      "             X1       26.810        5.645       25.167        5.301       -0.300\n",
      "             X2       12.930        2.534       11.639        2.168       -0.547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm.summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propensity Score Matching** - nearest-neighborhood matching\n",
    "\n",
    "* 'inv' (variância inversa): Especifica que a matriz de ponderação usada para calcular as distâncias é a inversa da matriz de covariância. Isso significa que variáveis com maior variância têm menor peso no cálculo da distância, e variáveis com menor variância têm maior peso.\n",
    "* 1 (um match por tratado): Isso significa que cada indivíduo tratado será pareado com exatamente um indivíduo do grupo de controle (não tratado).\n",
    "* Se definido como True, o método tentará ajustar o viés residual através de uma regressão linear adicional. Isso pode ser útil se houver preocupação de que o matching não tenha balanceado completamente as covariáveis entre os grupos tratado e controle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treatment Effect Estimates: OLS\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE   -219.323     22.438     -9.775      0.000   -263.302   -175.345\n",
      "\n",
      "Treatment Effect Estimates: Matching\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE   -203.744     34.020     -5.989      0.000   -270.424   -137.064\n",
      "           ATC   -199.569     37.967     -5.256      0.000   -273.984   -125.154\n",
      "           ATT   -222.002     30.031     -7.393      0.000   -280.862   -163.142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimates average treatment effects using nearest-neighborhood matching.\n",
    "cm.est_via_matching(weights='inv', matches=1, bias_adj=False)\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bias_adj=True: O método realiza um ajuste adicional após o matching para corrigir possíveis vieses remanescentes que surgem devido a essas diferenças residuais nas covariáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treatment Effect Estimates: OLS\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE   -219.323     22.438     -9.775      0.000   -263.302   -175.345\n",
      "\n",
      "Treatment Effect Estimates: Matching\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE   -219.043     28.612     -7.655      0.000   -275.123   -162.962\n",
      "           ATC   -217.321     31.351     -6.932      0.000   -278.768   -155.874\n",
      "           ATT   -226.572     25.105     -9.025      0.000   -275.777   -177.366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimates average treatment effects using 5 nearest-neighborhood matching.\n",
    "cm.est_via_matching(weights='inv', matches=5, bias_adj=True)\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis Distance Matching (MDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treatment Effect Estimates: OLS\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE   -219.323     22.438     -9.775      0.000   -263.302   -175.345\n",
      "\n",
      "Treatment Effect Estimates: Matching\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE   -201.341     34.026     -5.917      0.000   -268.032   -134.651\n",
      "           ATC   -196.748     37.985     -5.180      0.000   -271.199   -122.297\n",
      "           ATT   -221.426     29.996     -7.382      0.000   -280.218   -162.633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.est_via_matching(matches=1, weights='maha')\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações Finais\t\n",
    "\n",
    "Nessa aula vimos como o PSM pode ser utilizado para estimar o efeito do tratamento. A ideia é que o PSM pode ser utilizado para aproximar a amostra observacional à uma amostra randomizada. Aplicamos o PSM em um exemplo de gestantes que fumam e não fumam, e vimos como o PSM pode ser utilizado para estimar o efeito do tratamento. Além disso vimos que é um método utilizado na literatura recente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
