{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference-in-Differences with Covariates\n",
    "Prof. Daniel de Abreu Pereira Uhr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo\n",
    "\n",
    "* Difference-in-Differences com Covariáveis.\n",
    "* Difference in Difference Outcome Regression (Regression Adjustment) - Heckman et al (1997).\n",
    "* IPW Difference in Difference Approach - Abadie (2005)\n",
    "* Doubly Robust Difference in Difference - Sant'Anna e Zhao (2020)\n",
    "\n",
    "## Referências\n",
    "\n",
    "**Principais**\n",
    "\n",
    "* Heckman, J., Ichimura, Smith, J. and Todd, P. 1998. Characterizing Selection Bias Using Experimental Data. Econometrica 66(5): 1017--1098 \n",
    "* James J. Heckman, Hidehiko Ichimura, Petra E. Todd, 1997. The Review of Economic Studies, Volume 64, Issue 4, October 1997, Pages 605–654, https://doi.org/10.2307/2971733 \n",
    "* Abadie, A. 2005. Semiparametric Difference-in-Differences Estimators. Review of Economic Studies 72: 1--19 \n",
    "* Sant'Anna e Zhao (2020) Doubly robust difference-in-differences estimators. Journal of Econometrics, Volume 219, Issue 1, November 2020.  https://doi.org/10.1016/j.jeconom.2020.06.003 \n",
    "\n",
    "**Complementares**\n",
    "\n",
    "* Heckman, Ichimura e Todd (1998) - Matching as an Econometric Evaluation Estimator: Evidence from Evaluating a Job Training Programme\n",
    "* Hirano, K., Imbens, G.W. and Ridder, G. 2003.  Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score. Econometrica 71(4): 1161--1189\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Observações:** O material apresentado aqui é uma adaptação do material de aula do Prof. Daniel de Abreu Pereira Uhr, e não deve ser utilizado para fins comerciais. O material é disponibilizado para fins educacionais e de pesquisa, e não deve ser reproduzido sem a devida autorização do autor. Este material pode conter erros e imprecisões. O autor não se responsabiliza por quaisquer danos ou prejuízos decorrentes do uso deste material. O uso deste material é de responsabilidade exclusiva do usuário. Caso você encontre erros ou imprecisões neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer *feedback* ou sugestão de melhoria.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference-in-Differences com Covariáveis\n",
    "\n",
    "Vimos que o DD apresenta as seguintes hipóteses de identificação:\n",
    "\n",
    "* **Parallel Trends**: As tendências dos grupos tratado e controle são paralelas antes do tratamento.\n",
    "* **No anticipation**: O tratamento não pode ser antecipado.\n",
    "* **Distribuição dos dados**: Seja $W_{i}=(Y_{i,2}, Y_{i,1}, D_{i})´$ o vetor das variáveis de resultados e do status do tratamento para a unidade $i$. Nós observamos uma amostra de N *i.i.d.* com $W_{i}$~$F$ para alguma distribuição F (desconhecida) satisfazendo as tendências paralelas. Em outras palavras, os dados observados são amostrados de uma população maior de forma independente e identicamente distribuída, onde cada observação segue a mesma distribuição.\n",
    "\n",
    "E nosso interesse é identificar o **Average Treatment Effect on the Treated** (ATT), para o caso 2x2:\n",
    "\n",
    "$$ \\delta_{ATT}= E[Y_{i,2}(1)-Y_{i,2}(0)|D_{i}=1] $$\n",
    "\n",
    "Sob as hipóteses de identificação, o estimador de DD 2x2 é dado por:\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = (\\overline{Y}_{i,t=2}(1) - \\overline{Y}_{i,t=1}(1)) - (\\overline{Y}_{i,t=2}(0) - \\overline{Y}_{i,t=1}(0)) $$\n",
    "\n",
    "Vamos representar em termos de esperanças condicionais (assumindo uma amostragem de uma população grande):\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = (E[Y_{i,t=2}(1)|D_{i}=1] - E[Y_{i,t=1}(1)|D_{i}=1]) - (E[Y_{i,t=2}(0)|D_{i}=0] - E[Y_{i,t=1}(0)|D_{i}=0]) $$\n",
    "\n",
    "\n",
    "**Motivação para adicionar covariáveis**\n",
    "\n",
    "Para muitos pesquisadores, a hipótese de **Parallel Trends** não é plausível em muitos casos, mas poderia ser ao condicionarmos em algumas covariáveis. Por exemplo, se a variável de resultado de interesse são os salários, o grupo de tratamento e controle diferem em níveis de escolaridade, e as tendências para os níveis de educação que afetam os salários diferem entre os trabalhadores. Então, o condicionamento na covariável parece ser plausível.\n",
    "\n",
    "Nesse contexto as hipóteses de identificação são alteradas e ampliadas:\n",
    "\n",
    "* 1: Conditional Parallel Trends (porque condicionamos nas covariáveis)\n",
    "* 2: No anticipation\n",
    "* 3: Distribuição dos dados (Segue conforme anteriormente, considerando a estrutura de Panel-Data, ou repeated Cross-secion data, satisfazendo as tendências paralelas condicionais)\n",
    "* 4: Common Suport (Overlap) Ao menos uma fração da população que é tratada e para cada valor de X há ao menos uma chance de uma unidade ser não tratada.\n",
    "* 5: Efeito Homogêneo do Tratameto em X\n",
    "* 6: Não há tendências específicas em X em ambos os grupos tratado e controle\n",
    "\n",
    "Observação: Convem salientar que **a suposição de tendência paralela condicional não é nem mais forte nem mais fraca do que a tendência paralela incondicional.** A tendência paralela condicional não implica tendência paralela incondicional e a tendência paralela incondicional não implica tendência paralela condicional;\n",
    "\n",
    "Considerando $X_{i}$ um vetor de covariáveis que **Não varia no tempo**:\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = (E[Y_{i,t=2}|D_{i}=1, X_{i}] - E[Y_{i,t=1}|D_{i}=1, X_{i}]) - (E[Y_{i,t=2}|D_{i}=0, X_{i}] - E[Y_{i,t=1}|D_{i}=0, X_{i}]) $$\n",
    "\n",
    "\n",
    "Para identificar o efeito causal, os pesquisadores aplicados costumavam utilizar a especificação TWFE, apenas com a adição das covariáveis na regressão:\n",
    "\n",
    "$$ Y_{i,t} = \\alpha + \\beta_{1} T_{t} + \\beta_{2}D_{i} + \\delta (T_{t}.D_{i}) + \\gamma X_{i} + \\epsilon_{i,t} $$\n",
    "\n",
    "Ao adicionar as covariáveis na regressão significa que estamos **impondo uma estrutura paramétrica** para a relação entre as covariáveis e o resultado (é uma hipótese de estrutura paramétrica da relação). Essa regressão identifica o efeito causal se isso corresponde ao verdadeiro modelo que gera os resultados potenciais. O efeito do tratamento é **constante e aditivo**.\n",
    "\n",
    "Entretanto, **mesmo condicionando nas covariáveis, o modelo não permite que diferentes grupos tenham trajetórias diferentes ao longo do tempo. Ou seja, as trajetórias são as mesmas para todos os grupos.** Mas a razão pela qual se desejava incluir covariáveis no modelo era justamente para permitir que diferentes grupos tivessem trajetórias distintas ao longo do tempo. No entanto, a restrição do modelo impede que essa variação seja capturada, o que contradiz o objetivo original de incluir as covariáveis.\n",
    "\n",
    "Vamos tomar as expectativas condicionais do TWFE proposto (considerando os períodos 0 e 1):\n",
    "\n",
    "* Tratados (Post e Pre):\n",
    "$$E[Y_{1,1}|D_{i}=1] = \\alpha + \\beta_{1} + \\beta_{2} + \\delta + \\gamma X_{11}$$\n",
    "$$E[Y_{1,0}|D_{i}=1] = \\alpha + \\beta_{2} + \\gamma X_{10}$$\n",
    "* Controles (Post e Pre):\n",
    "$$E[Y_{0,1}|D_{i}=0] = \\alpha + \\beta_{1} + \\gamma X_{01}$$\n",
    "$$E[Y_{0,0}|D_{i}=0] = \\alpha + \\gamma X_{00}$$\n",
    "\n",
    "Tomando o DD:\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = ( (\\alpha + \\beta_{1} + \\beta_{2} + \\delta + \\gamma X_{11}) - (\\alpha + \\beta_{2} + \\gamma X_{10}) ) - ( (\\alpha + \\beta_{1} + \\gamma X_{01}) - (\\alpha + \\gamma X_{00}) ) $$\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = ( \\beta_{1} + \\delta + \\gamma X_{11} - \\gamma X_{10} ) - ( \\beta_{1} + \\gamma X_{01} - \\gamma X_{00} ) $$\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = \\delta + ( \\gamma X_{11} - \\gamma X_{10} ) - ( \\gamma X_{01} - \\gamma X_{00} ) $$\n",
    "\n",
    "\n",
    "Repare que a segunda parte da igualdade requer que as tendências de cada X do grupo tratado seja igual a tendência das variáveis X do grupo de controle. (hipóteses 5 e 6). Por isso que, normalmente o TWFE com covariáveis não irá identificar o efeito causal ($\\delta$) corretamente.\n",
    "\n",
    "Vejamos como a literatura propõe a inclusão de covariáveis no modelo de DD com menos hipóteses restritivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimação do DD sob Hipótese de Tendências Paralelas Condicionais\n",
    "\n",
    "Funciona se ambas as **unidades tratadas e de controle tiverem aproximadamente a mesma distribuição de covariáveis ​​(sobreposição forte)** e se o **efeito do tratamento for homogêneo**.\n",
    "\n",
    "Em termos de estratégia de identificação, a literatura se desenvolveu apresentando as seguintes abordagens:\n",
    "* Outcome Regression DD (Regression Adjustment DD - Heckman et al. 1997, 1998)\n",
    "* Propensity score com DD (Abadie, 2005)\n",
    "* Doubly Robust DD (Sant'Anna e Zhao, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome Regression DD\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\heckmanetal1998.png\"  alt=\"Imagem\" style=\"width: 700px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Uma forma de identificar o efeito causal através do método de Diferença em Diferenças e incorporar covariáveis se dá através do Outcome Regression. A ideia é realizar a diferença entre as médias dos resultados potenciais para o grupo tratado e controle, entretanto, **utilizar como ajuste do contrafactual a trajetória do grupo de controle com a distribuição de covariáveis do grupo tratado.**\n",
    "\n",
    "1. **Modelo de Regressão Linear:**\n",
    "\n",
    "   $$ Y_{i,t} = \\alpha + \\beta D_{i,t} + \\gamma X_{i} + \\epsilon_{i,t} $$\n",
    "\n",
    "   onde $ Y $ é a variável dependente, $ D $ é a variável indicadora de tratamento (1 se o tratamento foi aplicado, 0 caso contrário), $ X $ são as covariáveis constantes observáveis, e $ \\epsilon $ é o termo de erro.\n",
    "\n",
    "2. **Expectativas Condicionais:**\n",
    "   \n",
    "   Definimos os resultados da expectativa condicional (para o período 1 e 2):\n",
    "\n",
    "   $$ \\mu_{0,1}(X) = E[Y | X, D=0, t=1] $$\n",
    "   $$ \\mu_{0,2}(X) = E[Y | X, D=0, t=2] $$\n",
    "   \n",
    "   Então, $\\mu_{0,1}(X) $ e $ \\mu_{0,2}(X) $ **representam as médias dos resultados potenciais para os não tratados dado suas características observáveis $ X $**.\n",
    "\n",
    "3. **DD e as Expectativas Condicionais:**\n",
    "   \n",
    "   Retomando a equação do DD, temos:\n",
    "\n",
    "   $$ \\beta^{DD} = (E[Y|X, D=1, t=2] - E[Y|X, D=1, t=1]) - (E[Y|X, D=0, t=2] - E[Y|X, D=0, t=1]) $$\n",
    "\n",
    "4. **Substituição das Definições:**\n",
    "\n",
    "   A ideia dos autores é construir um contrafactual adequado, que considere a trajetória do grupo de controle com a distribuição de covariáveis do grupo tratado. Logo:\n",
    "\n",
    "   $$ \\beta^{OR-DD} = (E[Y|X, D=1, t=2] - E[Y|X, D=1, t=1]) - (\\mu_{02}(X) - \\mu_{01}(X) ) $$\n",
    "\n",
    "  Considerando que queremos construir o contrafactual considerando a trajetória do grupo de controle com a distribuição de covariáveis do grupo tratado ($X^{T}$), obtemos:\n",
    "\n",
    "   $$ \\hat{\\beta}_{ATT}^{OR-DD} = (E[Y|X, D=1, t=2] - E[Y|X, D=1, t=1]) - [\\mu_{1}(X^{T}) - \\mu_{0}(X^{T})]  $$\n",
    "\n",
    "   Simplificando a notação, com $ \\bar{Y}_{1,1} $ representando $ E[Y|X, D=1, t=1] $ e $ \\bar{Y}_{1,2} $ representando $ E[Y|X, D=1, t=2] $, temos:\n",
    "\n",
    "   $$ \\hat{\\beta}_{ATT}^{OR-DD} = (\\bar{Y}_{1,2} - \\bar{Y}_{1,1}) - [\\mu_{1}(X^{T}) - \\mu_{0}(X^{T})]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar o método de Outcome Regression DD em um exemplo prático em python. Com os dados de Card and Krueger (1994), vamos estimar o efeito do salário mínimo no emprego, só que com o OR-DD.\n",
    "\n",
    "Começamos carregando os pacotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "from differences import ATTgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"http://fmwww.bc.edu/repec/bocode/c/CardKrueger1994.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre que os dados não estão corretos, então precisamos corrigir o erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Há problemas na base que precisam ser ajustados\n",
    "df.loc[(df['id'] == 407) & (df['kfc'] == 1), 'id'] = 408\n",
    "# Crie a variável 'tratado' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'tratado' para 1 se 'treated' for igual a 1\n",
    "df.loc[df['treated'] == 'NJ', 'Treated'] = 1\n",
    "# Crie a variável 'effect' como o produto entre 'tratado' e 't'\n",
    "df['Effect'] = df['Treated'] * df['t']\n",
    "# Remover lojas sem informação em ambos os anos\n",
    "df['cont'] = df['fte'].notna().groupby(df['id']).cumsum()\n",
    "df['media'] = df.groupby('id')['cont'].transform('mean')\n",
    "df = df[df['media'] == 1.5]\n",
    "df['y'] = df['fte']\n",
    "\n",
    "df['pre'] = 0\n",
    "df.loc[df['t'] == 0, 'pre'] = 1\n",
    "df['pos'] = 0\n",
    "df.loc[df['t'] == 1, 'pos'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando a base em csv para usar no exemplo em R que realizaremos no final dessa aula.\n",
    "# df.to_csv('card_krueger.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DD Canônico\n",
    "\n",
    "Vamos começar com o DD canônico, sem covariáveis, para entender o efeito do salário mínimo no emprego. Para ter um valor de referência para o efeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     2.195\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):             0.0873\n",
      "Time:                        19:58:45   Log-Likelihood:                -2831.8\n",
      "No. Observations:                 782   AIC:                             5672.\n",
      "Df Residuals:                     778   BIC:                             5690.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     20.0132      1.040     19.238      0.000      17.971      22.055\n",
      "Treated       -2.9663      1.159     -2.559      0.011      -5.242      -0.691\n",
      "t             -2.4901      1.471     -1.693      0.091      -5.378       0.398\n",
      "Effect         2.9425      1.639      1.795      0.073      -0.275       6.160\n",
      "==============================================================================\n",
      "Omnibus:                      240.424   Durbin-Watson:                   1.389\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              952.495\n",
      "Skew:                           1.395   Prob(JB):                    1.47e-207\n",
      "Kurtosis:                       7.631   Cond. No.                         11.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# regressão DD canônico sem covariáveis:\n",
    "DD1 = smf.ols('y ~ Treated + t + Effect', data=df).fit()\n",
    "print(DD1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DD Canônico com Covariáveis\n",
    "\n",
    "Vamos adicionar covariáveis constantes no tempo e verificar se o efeito do salário mínimo no emprego se mantém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.190\n",
      "Model:                            OLS   Adj. R-squared:                  0.184\n",
      "Method:                 Least Squares   F-statistic:                     30.26\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):           1.06e-32\n",
      "Time:                        19:58:47   Log-Likelihood:                -2752.8\n",
      "No. Observations:                 782   AIC:                             5520.\n",
      "Df Residuals:                     775   BIC:                             5552.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     21.2079      1.181     17.950      0.000      18.889      23.527\n",
      "Treated       -2.3752      1.051     -2.259      0.024      -4.439      -0.312\n",
      "t             -2.4901      1.332     -1.869      0.062      -5.106       0.125\n",
      "Effect         2.9425      1.485      1.982      0.048       0.028       5.857\n",
      "bk             1.0109      0.919      1.100      0.272      -0.793       2.815\n",
      "kfc           -9.1680      1.031     -8.892      0.000     -11.192      -7.144\n",
      "roys          -0.8918      0.997     -0.894      0.371      -2.849       1.065\n",
      "==============================================================================\n",
      "Omnibus:                      298.310   Durbin-Watson:                   1.556\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1795.640\n",
      "Skew:                           1.606   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.693   Cond. No.                         12.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# regressão DD canônico com covariáveis:\n",
    "DD2 = smf.ols('y ~ Treated + t + Effect + bk + kfc + roys', data=df).fit()\n",
    "print(DD2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre que sob a hipótese de tendências paralelas condicionais, o estimador de DD apenas adicionando as covariáveis pode apresentar viés se as tendências não forem paralelas nas prórias covariáveis. \n",
    "\n",
    "Os resultados foram de $2.9425$ em ambos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome Regression DD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos realizar o OR-DD \"na mão\" para verificar a magnitude do efeito a ser estimado, e entender o mecânismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Regression DD (ATT): 2.6757034544143536\n"
     ]
    }
   ],
   "source": [
    "def OR_DD(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time):\n",
    "    # Separar dados por grupo e período\n",
    "    df_pre = df[df[Time_col] == pre_time]\n",
    "    df_post = df[df[Time_col] == post_time]\n",
    "\n",
    "    X_pre_treated = df_pre[df_pre[T_col] == 1][X_cols]\n",
    "    Y_pre_treated = df_pre[df_pre[T_col] == 1][Y_col]\n",
    "    X_post_treated = df_post[df_post[T_col] == 1][X_cols]\n",
    "    Y_post_treated = df_post[df_post[T_col] == 1][Y_col]\n",
    "\n",
    "    X_pre_control = df_pre[df_pre[T_col] == 0][X_cols]\n",
    "    Y_pre_control = df_pre[df_pre[T_col] == 0][Y_col]\n",
    "    X_post_control = df_post[df_post[T_col] == 0][X_cols]\n",
    "    Y_post_control = df_post[df_post[T_col] == 0][Y_col]\n",
    "\n",
    "    # Ajustar modelos de regressão linear para os períodos pré e pós\n",
    "    model_pre_control = LinearRegression().fit(X_pre_control, Y_pre_control)\n",
    "    model_post_control = LinearRegression().fit(X_post_control, Y_post_control)\n",
    "\n",
    "    # Previsões para o grupo controle nos períodos pré e pós\n",
    "    mu0_X_pre = model_pre_control.predict(X_pre_treated)\n",
    "    mu0_X_post = model_post_control.predict(X_post_treated)\n",
    "\n",
    "    # Calcular a Diferença em Diferenças\n",
    "    ORdid = (Y_post_treated.mean() - Y_pre_treated.mean()) - (mu0_X_post.mean() - mu0_X_pre.mean()) \n",
    "\n",
    "    return ORdid\n",
    "\n",
    "# Exemplo de uso\n",
    "T_col = 'Treated'\n",
    "Y_col = 'y'\n",
    "X_cols = ['bk', 'kfc', 'roys']\n",
    "Time_col = 't'\n",
    "pre_time = 0\n",
    "post_time = 1\n",
    "\n",
    "result_OR_DiD = OR_DD(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time)\n",
    "print(\"Outcome Regression DD (ATT):\", result_OR_DiD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que o resultado é distinto do valor canônico. Fazendo manualmente, encontramos um efeito de $2.6757$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos aplicar o pacote `differences` do Python. Nesse pacote conseguimos estimar o OR-DD de forma mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"http://fmwww.bc.edu/repec/bocode/c/CardKrueger1994.dta\")\n",
    "# Há problemas na base que precisam ser ajustados\n",
    "df.loc[(df['id'] == 407) & (df['kfc'] == 1), 'id'] = 408\n",
    "# Crie a variável 'tratado' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'tratado' para 1 se 'treated' for igual a 1\n",
    "df.loc[df['treated'] == 'NJ', 'Treated'] = 1\n",
    "# Crie a variável 'effect' como o produto entre 'tratado' e 't'\n",
    "df['Effect'] = df['Treated'] * df['t']\n",
    "# Remover lojas sem informação em ambos os anos\n",
    "df['cont'] = df['fte'].notna().groupby(df['id']).cumsum()\n",
    "df['media'] = df.groupby('id')['cont'].transform('mean')\n",
    "df = df[df['media'] == 1.5]\n",
    "df['Y'] = df['fte']\n",
    "\n",
    "df['pre'] = 0\n",
    "df.loc[df['t'] == 0, 'pre'] = 1\n",
    "df['pos'] = 0\n",
    "df.loc[df['t'] == 1, 'pos'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rodar o pacote precisamos definir o Grupo de tratamento, isto é, precisamos criar uma variável nova \"Group\" que identifica o grupo tratado e controle. Em outras palavras, o grupo de tratamento é definido como o ano (período) em que ocorreu o início do tratamento para as unidades tratadas. Como em nossa base de dados todos os tratados iniciaram o tratamento quando time é 1, então definimos Group=1 para os tratados e Group com NaN para os controles (NaN é um valor nulo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Group'] = df['Treated']\n",
    "df.loc[df['Treated'] == 0, 'Group'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro ponto importante para rodar esse pacote, temos que identificar a estrutura de painel de dados para o python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar duas variáveis de identificação de individuos e tempo para indicar a estrutura de painel.\n",
    "df['id1'] = df['id']\n",
    "df['t1'] = df['t'].astype(int)\n",
    "\n",
    "# Definir os indices (estrutura de painel)\n",
    "df.set_index(['id1', 't1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_gt = ATTgt(data=df, cohort_name=\"Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao entrar no \"help(Attgt)\", vemos que o pacote possui diversas opções de estimação, como o OR-DD, IPW-DD, e DR-DD.\n",
    "\n",
    "est_method: *str*, default: ``\"dr-mle\"``\n",
    " |      \n",
    " |          - ``\"dr-mle\"`` or ``\"dr\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated\n",
    " |      \n",
    " |          - ``\"dr-ipt\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with propensity score estimated using the inverse probability tilting\n",
    " |      \n",
    " |          - ``\"reg\"``\n",
    " |              for outcome regression DiD estimator\n",
    " |      \n",
    " |          - ``\"std_ipw-mle\"`` or ``\"std_ipw\"``\n",
    " |              for standardized inverse probability weighted DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated\n",
    "\n",
    "\n",
    " Vamos rodar o pacote para estimar o OR-DD, então precisamos definir o método de estimação como \"reg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 199.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">ATTgtResult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>base_period</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>2.675703</td>\n",
       "      <td>1.217264</td>\n",
       "      <td>0.289911</td>\n",
       "      <td>5.061496</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ATTgtResult                                           \\\n",
       "                                     analytic pointwise conf. band             \n",
       "                                ATT std_error                lower     upper   \n",
       "cohort base_period time                                                        \n",
       "1      0           1       2.675703  1.217264             0.289911  5.061496   \n",
       "\n",
       "                                           \n",
       "                                           \n",
       "                        zero_not_in_cband  \n",
       "cohort base_period time                    \n",
       "1      0           1                    *  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos salvar os resultados dentro em uma variável \"results\". E calcular suas estatísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 125.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa do ATT: 2.6757032727620924\n",
      "Estatística de Teste (t): 2.198129841848015\n",
      "Valor-p: 0.027939854480739434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"reg\")\n",
    "\n",
    "# Acessar o coeficiente e o erro padrão\n",
    "coef = results[('ATTgtResult', '', 'ATT')].iloc[0]\n",
    "std_error = results[('ATTgtResult', 'analytic', 'std_error')].iloc[0]\n",
    "\n",
    "# Calcular a estatística de teste\n",
    "t_stat = coef / std_error\n",
    "\n",
    "# Calcular o valor-p (para um teste bilateral)\n",
    "import scipy.stats as stats\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
    "\n",
    "print(f\"Estimativa do ATT: {coef}\")\n",
    "print(f\"Estatística de Teste (t): {t_stat}\")\n",
    "print(f\"Valor-p: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  IPW Difference in Difference Approach - Abadie (2005) \n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\Abadie2005.png\"  alt=\"Imagem\" style=\"width: 700px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "**Resumo em português**: O estimador de diferenças em diferenças (DID) é uma das ferramentas mais populares na pesquisa aplicada em economia para avaliar os efeitos de intervenções públicas e outros tratamentos de interesse em variáveis de resultado relevantes. No entanto, é amplamente conhecido que o estimador DID baseia-se em suposições fortes de identificação. Em particular, o estimador DID convencional exige que, na ausência do tratamento, os resultados médios para os grupos tratado e de controle teriam seguido trajetórias paralelas ao longo do tempo. Essa suposição pode ser implausível se as características pré-tratamento, que se acredita estarem associadas à dinâmica da variável de resultado, forem desbalanceadas entre os tratados e os não tratados. Esse seria o caso, por exemplo, se a seleção para o tratamento fosse influenciada por choques transitórios individuais em resultados passados (o chamado \"Ashenfelter's dip\"). Este artigo considera o caso em que diferenças nas características observadas criam dinâmicas não paralelas nos resultados entre tratados e controles. Demonstra-se que, nesse caso, uma estratégia simples em dois passos pode ser usada para estimar o efeito médio do tratamento para os tratados. Além disso, o framework de estimação proposto neste artigo permite o uso de covariáveis para descrever como o efeito médio do tratamento varia com mudanças nas características observadas.\n",
    "\n",
    "\n",
    "A abordagem proposta por Abadie (2005) é um estimador de diferenças em diferenças Semiparametrico. A abordagem de Abadie (2005) utiliza técnicas de *matching* para criar grupos de comparação potencialmente mais adequados, onde unidades de tratamento e controle são pareadas com base em características observáveis. Isso ajuda a reduzir o viés de seleção por características observáveis e aumenta a validade causal da estimativa.\n",
    "\n",
    "\n",
    "$$ \\delta^{IPW} = \\frac{1}{E_{N}[D]}E\\left [\\frac{D-\\hat{p}(X)}{1-\\hat{p}(X)}(Y_{1}-Y_{0})\\right ]  $$\n",
    "\n",
    "\n",
    "Onde $\\hat{p}(X)$  é um estimador para o verdadeiro escore de propensão (probabilidade do indivíduo ser tratado baseado nas características observáveis). O qual reduz a dimensão de X em um escalar.\n",
    "\n",
    "* $E_{N}[D]$ é a proporção média de unidades que receberam o tratamento na amostra\n",
    "* $Y_{1}$ e $Y_{0}$ são as médias das variáveis de resultado dos tratados e não tratados **no período de tratamento**\n",
    "\n",
    "Pode ser reescrito como:\n",
    "\n",
    "$$ \\delta^{IPW-DD} = \\frac{1}{E_{N}[D]} E\\left [(\\bar{Y}_{1,2} - \\bar{Y}_{1,1}) - \\frac{(1-D)\\hat{p}(X)}{1-\\hat{p}(X)}(\\bar{Y}_{0,2} - \\bar{Y}_{0,1}) \\right ]  $$\n",
    "\n",
    "A ideia da ponderação é atribuir mais peso para as observações nos grupos de controle que \"parecem\" mais com as unidades tratadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar essa abordagem em nosso exemplo prático. Aqui vou mostrar como fazer manualmente porque pode ser importante tanto para vocês entenderem o mecanismo, quanto para utilizarem em estratégias de pesquisa futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.489622\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Treated   No. Observations:                  782\n",
      "Model:                          Logit   Df Residuals:                      778\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 20 Nov 2024   Pseudo R-squ.:                0.005849\n",
      "Time:                        19:59:15   Log-Likelihood:                -382.88\n",
      "converged:                       True   LL-Null:                       -385.14\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2118\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1239      0.226      4.979      0.000       0.681       1.566\n",
      "bk             0.2095      0.264      0.795      0.427      -0.307       0.726\n",
      "kfc            0.6107      0.316      1.931      0.053      -0.009       1.230\n",
      "roys           0.3996      0.295      1.356      0.175      -0.178       0.977\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Propensity Score Weighting\n",
    "D = df['Treated']\n",
    "X = df[['bk', 'kfc', 'roys']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "reg_logit = sm.Logit(D, X).fit()\n",
    "df['peso_logit'] = reg_logit.predict()\n",
    "\n",
    "print(reg_logit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a medida de média dos tratados 'ED'\n",
    "df['ED'] = df['Treated'].mean()\n",
    "ED = df['ED'].mean()\n",
    "\n",
    "# Criando os pesos e adicionando ao DataFrame\n",
    "df['W_ATT'] = (df['peso_logit'] / (1 - df['peso_logit']))/ED\n",
    "df.loc[df['Treated'] == 1, 'W_ATT'] = 1/ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.008\n",
      "Model:                            WLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     2.143\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):             0.0934\n",
      "Time:                        19:59:23   Log-Likelihood:                -2942.2\n",
      "No. Observations:                 782   AIC:                             5892.\n",
      "Df Residuals:                     778   BIC:                             5911.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         18.9768      0.674     28.135      0.000      17.653      20.301\n",
      "Treated       -1.9299      0.954     -2.023      0.043      -3.802      -0.057\n",
      "t             -2.2233      0.954     -2.331      0.020      -4.096      -0.351\n",
      "Effect         2.6757      1.349      1.984      0.048       0.028       5.324\n",
      "==============================================================================\n",
      "Omnibus:                      327.394   Durbin-Watson:                   1.373\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2743.448\n",
      "Skew:                           1.672   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.545   Cond. No.                         6.85\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Aplicando regressão ponderada\n",
    "Y1 = df[['Y']]  # Selecionando a variável dependente\n",
    "X1 = df[['Treated', 't', 'Effect']]  # Selecionando as variáveis independentes\n",
    "X1 = sm.add_constant(X1)  # Adicionando uma constante (intercepto)\n",
    "\n",
    "# Ajustando o modelo de regressão ponderada\n",
    "dd_ipw = sm.WLS(Y1, X1, weights=df['W_ATT']).fit()\n",
    "\n",
    "# Imprimindo o resumo\n",
    "print(dd_ipw.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado para o DD-IPW foi de $2.6757$. O mesmo econtrado anteriormente pelo OR-DD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubly Robust DD (DRDID)\n",
    "\n",
    "O modelo Doubly Robust Difference in Differences (DRDID) de Sant'Anna e Zhao (2020) é uma extensão do método de diferenças em diferenças (DD). Ele usa **uma abordagem duplamente robusta**, que combina os dois modelos vistos anteriormente: um modelo de Outcome Regression e um modelo de probabilidade de receber o tratamento para o caso de diferença em diferenças.\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\SantannaZhao.png\"  alt=\"Imagem\" style=\"width: 700px;\"/>\n",
    "</div>\n",
    "\n",
    "**Resumo em português**: Este artigo propõe estimadores duplamente robustos para o efeito médio do tratamento sobre os tratados (ATT) em desenhos de pesquisa baseados em diferenças em diferenças (DID). Em contraste com outros estimadores DID alternativos, os estimadores propostos são consistentes se pelo menos um dos modelos de escore de propensão ou de regressão do resultado for corretamente especificado (mas não necessariamente ambos). Também derivamos o limite de eficiência semiparamétrica para o ATT em desenhos DID quando dados de painel ou de seções transversais repetidas estão disponíveis, e mostramos que os estimadores propostos atingem esse limite de eficiência semiparamétrica quando os modelos utilizados estão corretamente especificados. Além disso, quantificamos os possíveis ganhos de eficiência ao se utilizar dados de painel em vez de dados de seções transversais repetidas. Por fim, ao focar especialmente no método de estimação usado para os parâmetros auxiliares, mostramos que, em alguns casos, é possível construir estimadores DID duplamente robustos para o ATT que também são duplamente robustos para inferência. Estudos de simulação e uma aplicação empírica ilustram o desempenho desejável dos estimadores propostos em amostras finitas. Um software de código aberto para implementar as ferramentas propostas de avaliação de políticas está disponível.\n",
    "\n",
    "\n",
    "\n",
    "O modelo DRDID combina esses dois modelos para produzir estimativas do efeito causal que são consistentes mesmo que um dos modelos seja mal especificado. Essa abordagem pode melhorar a precisão da estimativa do efeito causal em comparação com o método DID padrão, especialmente quando há variáveis de controle que afetam tanto a probabilidade de tratamento quanto o resultado de interesse.\n",
    "\n",
    "$$  \\beta^{DRDID}= E\\left[ \\left ( \\frac{D}{E[D]} - \\frac{\\frac{p(X)(1-D)}{(1-p(X))}}{E[\\frac{p(X)(1-D)}{(1-p(X))}]} \\right ) (\\Delta Y - \\mu_{0,\\Delta (X)} )   \\right ]  $$\n",
    "\n",
    "Podemos reescrever a equação acima como:\n",
    "\n",
    "$$ \\beta^{DRDID}= E\\left[ \\frac{D}{E[D]}(\\bar{Y}_{1,2} - \\bar{Y}_{1,1}) - \\frac{\\frac{p(X)(1-D)}{(1-p(X))}}{E[\\frac{p(X)(1-D)}{(1-p(X))}]} (\\mu_{1}(X^{T}) - \\mu_{0}(X^{T})) \\right ]  $$\n",
    "\n",
    "\n",
    "Observe como o modelo controla para $X$ você está ponderando o ajuste resultados usando o escore de propensão. \n",
    "\n",
    "A razão pela qual você controla $X$ duas vezes é porque você não sabe qual modelo está certo. DRDiD libera você de fazer uma escolha sem fazer você pagar muito por isso.\n",
    "\n",
    "Novamente, podemos fazer manualmente para entender o mecanismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplamente Robusto DiD (ATT): 2.6757034544143536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "def DD_DR(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time):\n",
    "    # Separar dados por grupo e período\n",
    "    df_pre = df[df[Time_col] == pre_time]\n",
    "    df_post = df[df[Time_col] == post_time]\n",
    "\n",
    "    X_pre_treated = df_pre[df_pre[T_col] == 1][X_cols]\n",
    "    Y_pre_treated = df_pre[df_pre[T_col] == 1][Y_col]\n",
    "    X_post_treated = df_post[df_post[T_col] == 1][X_cols]\n",
    "    Y_post_treated = df_post[df_post[T_col] == 1][Y_col]\n",
    "\n",
    "    X_pre_control = df_pre[df_pre[T_col] == 0][X_cols]\n",
    "    Y_pre_control = df_pre[df_pre[T_col] == 0][Y_col]\n",
    "    X_post_control = df_post[df_post[T_col] == 0][X_cols]\n",
    "    Y_post_control = df_post[df_post[T_col] == 0][Y_col]\n",
    "    \n",
    "    # Ajustar modelos de regressão linear para os períodos pré e pós\n",
    "    model_pre_control = LinearRegression().fit(X_pre_control, Y_pre_control)\n",
    "    model_post_control = LinearRegression().fit(X_post_control, Y_post_control)\n",
    "\n",
    "    # Previsões para o grupo controle nos períodos pré e pós\n",
    "    mu0_X_pre = model_pre_control.predict(X_pre_treated)\n",
    "    mu0_X_post = model_post_control.predict(X_post_treated)\n",
    "    \n",
    "    X_pre = df_pre[X_cols]\n",
    "    Y_pre = df_pre[Y_col]\n",
    "    T_pre = df_pre[T_col]\n",
    "        \n",
    "    # Estimativa da probabilidade de tratamento p(X) no período pré\n",
    "    model_logistic = LogisticRegression(solver='liblinear').fit(X_pre, T_pre)\n",
    "    p_X_pre = model_logistic.predict_proba(X_pre)[:, 1]\n",
    "    \n",
    "    # Criar os pesos para o período pré\n",
    "    weight_treated_pre = T_pre / T_pre.mean()\n",
    "    weight_control_pre = ((1 - p_X_pre) / p_X_pre) / ((1 - p_X_pre) / p_X_pre).mean()\n",
    "    \n",
    "    # Calcular a Diferença em Diferenças com os pesos\n",
    "    term_treated = (Y_post_treated.mean() - Y_pre_treated.mean()) * weight_treated_pre.mean()\n",
    "    term_control = (mu0_X_post.mean() - mu0_X_pre.mean()) * weight_control_pre.mean()\n",
    "\n",
    "    DR_DiD = term_treated - term_control \n",
    "\n",
    "    return DR_DiD\n",
    "\n",
    "# Exemplo de uso\n",
    "T_col = 'Treated'\n",
    "Y_col = 'Y'\n",
    "X_cols = ['bk', 'kfc', 'roys']\n",
    "Time_col = 't'\n",
    "pre_time = 0\n",
    "post_time = 1\n",
    "\n",
    "\n",
    "result_DD_DR = DD_DR(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time)\n",
    "print(\"Duplamente Robusto DiD (ATT):\", result_DD_DR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação Dobly Robust Difference in Differences (DRDID) - Sant'Anna e Zhao (2020) em Python\n",
    "\n",
    "Vamos aplicar o DRDD com pacote `differences`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacotes\n",
    "import pandas as pd\n",
    "from differences import ATTgt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"http://fmwww.bc.edu/repec/bocode/c/CardKrueger1994.dta\")\n",
    "# Há problemas na base que precisam ser ajustados\n",
    "df.loc[(df['id'] == 407) & (df['kfc'] == 1), 'id'] = 408\n",
    "# Crie a variável 'tratado' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'tratado' para 1 se 'treated' for igual a 1\n",
    "df.loc[df['treated'] == 'NJ', 'Treated'] = 1\n",
    "# Crie a variável 'effect' como o produto entre 'tratado' e 't'\n",
    "df['Effect'] = df['Treated'] * df['t']\n",
    "# Remover lojas sem informação em ambos os anos\n",
    "df['cont'] = df['fte'].notna().groupby(df['id']).cumsum()\n",
    "df['media'] = df.groupby('id')['cont'].transform('mean')\n",
    "df = df[df['media'] == 1.5]\n",
    "df['Y'] = df['fte']\n",
    "\n",
    "df['pre'] = 0\n",
    "df.loc[df['t'] == 0, 'pre'] = 1\n",
    "df['pos'] = 0\n",
    "df.loc[df['t'] == 1, 'pos'] = 1\n",
    "\n",
    "df['Group'] = df['Treated']\n",
    "df.loc[df['Treated'] == 0, 'Group'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os indices (estrutura de painel)\n",
    "df.set_index(['id', 't'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_gt = ATTgt(data=df, cohort_name=\"Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "est_method: *str*, default: ``\"dr-mle\"``\n",
    " |      \n",
    " |          - ``\"dr-mle\"`` or ``\"dr\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated\n",
    " |      \n",
    " |          - ``\"dr-ipt\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with propensity score estimated using the inverse probability tilting\n",
    " |      \n",
    " |          - ``\"reg\"``\n",
    " |              for outcome regression DiD estimator\n",
    " |      \n",
    " |          - ``\"std_ipw-mle\"`` or ``\"std_ipw\"``\n",
    " |              for standardized inverse probability weighted DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 90.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">ATTgtResult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>base_period</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>2.675703</td>\n",
       "      <td>1.217264</td>\n",
       "      <td>0.289911</td>\n",
       "      <td>5.061496</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ATTgtResult                                           \\\n",
       "                                     analytic pointwise conf. band             \n",
       "                                ATT std_error                lower     upper   \n",
       "cohort base_period time                                                        \n",
       "1      0           1       2.675703  1.217264             0.289911  5.061496   \n",
       "\n",
       "                                           \n",
       "                                           \n",
       "                        zero_not_in_cband  \n",
       "cohort base_period time                    \n",
       "1      0           1                    *  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"dr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 125.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa do ATT: 2.6757032727620964\n",
      "Estatística de Teste (t): 2.198129841848017\n",
      "Valor-p: 0.027939854480739212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"dr\")\n",
    "\n",
    "# Acessar o coeficiente e o erro padrão\n",
    "coef = results2[('ATTgtResult', '', 'ATT')].iloc[0]\n",
    "std_error = results2[('ATTgtResult', 'analytic', 'std_error')].iloc[0]\n",
    "\n",
    "# Calcular a estatística de teste\n",
    "t_stat = coef / std_error\n",
    "\n",
    "# Calcular o valor-p (para um teste bilateral)\n",
    "import scipy.stats as stats\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
    "\n",
    "print(f\"Estimativa do ATT: {coef}\")\n",
    "print(f\"Estatística de Teste (t): {t_stat}\")\n",
    "print(f\"Valor-p: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do DRDID de Sant'Anna e Zhao (2020) no R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível utilizar também o Sant’Anna and Zhao (2020) doubly robust DiD estimator based on stabilized inverse probability weighting and ordinary least squares [dripw].\n",
    "\n",
    "Para isso precisamos recalcular o peso e utilizar as métricas estabilizadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos utilizar o pacote do R e calcular diretamente o DRDID\n",
    "\n",
    "Lembre-se de alterar o kernell de Python para R.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using GitHub PAT from the git credential store.\n",
      "\n",
      "Skipping install of 'DRDID' from a github remote, the SHA1 (8a1c09f9) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"remotes\")\n",
    "remotes::install_github(\"pedrohcgs/DRDID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "library(DRDID)\n",
    "data <- read.csv(\"https://github.com/Daniel-Uhr/data/raw/main/card_krueger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Call:\n",
      "drdid(yname = \"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", \n",
      "    xformla = ~bk + kfc + roys, data = data, panel = TRUE)\n",
      "------------------------------------------------------------------\n",
      " Further improved locally efficient DR DID estimator for the ATT:\n",
      " \n",
      "   ATT     Std. Error  t value    Pr(>|t|)  [95% Conf. Interval] \n",
      "  2.6757     1.2188     2.1953     0.0281     0.2868     5.0646  \n",
      "------------------------------------------------------------------\n",
      " Estimator based on panel data.\n",
      " Outcome regression est. method: weighted least squares.\n",
      " Propensity score est. method: inverse prob. tilting.\n",
      " Analytical standard error.\n",
      "------------------------------------------------------------------\n",
      " See Sant'Anna and Zhao (2020) for details."
     ]
    }
   ],
   "source": [
    "# Implement improved locally efficient DR DID:\n",
    "out <- drdid(yname = \"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", xformla= ~ bk + kfc + roys, data = data, panel = TRUE)\n",
    "summary(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Call:\n",
      "ordid(yname = \"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", \n",
      "    xformla = ~bk + kfc + roys, data = data, panel = TRUE)\n",
      "------------------------------------------------------------------\n",
      " Outcome-Regression DID estimator for the ATT:\n",
      " \n",
      "   ATT     Std. Error  t value    Pr(>|t|)  [95% Conf. Interval] \n",
      "  2.6757     1.2188     2.1953     0.0281     0.2868     5.0646  \n",
      "------------------------------------------------------------------\n",
      " Estimator based on panel data.\n",
      " Outcome regression est. method: OLS.\n",
      " Analytical standard error.\n",
      "------------------------------------------------------------------\n",
      " See Sant'Anna and Zhao (2020) for details."
     ]
    }
   ],
   "source": [
    "library(DRDID)\n",
    "data <- read.csv(\"https://github.com/Daniel-Uhr/data/raw/main/card_krueger.csv\")\n",
    "out2 <- ordid(yname=\"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", xformla= ~ bk + kfc + roys, data = data, panel = TRUE)\n",
    "summary(out2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
