{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference-in-Differences with Covariates\n",
    "Prof. Daniel de Abreu Pereira Uhr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo\n",
    "\n",
    "* Difference-in-Differences com Covariáveis.\n",
    "* Difference in Difference Outcome Regression (Regression Adjustment) - Heckman et al (1997).\n",
    "* IPW Difference in Difference Approach - Abadie (2005)\n",
    "* Doubly Robust Difference in Difference - Sant'Anna e Zhao (2020)\n",
    "\n",
    "## Referências\n",
    "\n",
    "**Principais**\n",
    "\n",
    "* Heckman, J., Ichimura, Smith, J. and Todd, P. 1998. Characterizing Selection Bias Using Experimental Data. Econometrica 66(5): 1017--1098\n",
    "* Abadie, A. 2005. Semiparametric Difference-in-Differences Estimators. Review of Economic Studies 72: 1--19\n",
    "* Sant'Anna e Zhao (2020) Doubly robust difference-in-differences estimators. Journal of Econometrics, Volume 219, Issue 1, November 2020.  https://doi.org/10.1016/j.jeconom.2020.06.003 \n",
    "\n",
    "**Complementares**\n",
    "\n",
    "* Heckman, Ichimura e Todd (1998) - Matching as an Econometric Evaluation Estimator: Evidence from Evaluating a Job Training Programme\n",
    "* Hirano, K., Imbens, G.W. and Ridder, G. 2003.  Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score. Econometrica 71(4): 1161--1189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference-in-Differences com Covariáveis\n",
    "\n",
    "Vimos que o DD apresenta as seguintes hipóteses de identificação:\n",
    "\n",
    "* **Parallel Trends**: As tendências dos grupos tratado e controle são paralelas antes do tratamento.\n",
    "* **No anticipation**: O tratamento não pode ser antecipado.\n",
    "* **Distribuição dos dados**: Seja $W_{i}=(Y_{i,2}, Y_{i,1}, D_{i})´$ o vetor das variáveis de resultados e do status do tratamento para a unidade $i$. Nós observamos uma amostra de N *i.i.d.* com $W_{i}$~$F$ para alguma distribuição F (desconhecida) satisfazendo as tendências paralelas. Em outras palavras, os dados observados são amostrados de uma população maior de forma independente e identicamente distribuída, onde cada observação segue a mesma distribuição.\n",
    "\n",
    "E nosso interesse é identificar o **Average Treatment Effect on the Treated** (ATT), para o caso 2x2:\n",
    "\n",
    "$$ \\delta_{ATT}= E[Y_{i,2}(1)-Y_{i,2}(0)|D_{i}=1] $$\n",
    "\n",
    "Sob as hipóteses de identificação, o estimador de DD 2x2 é dado por:\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = (\\overline{Y}_{i,t=2}(1) - \\overline{Y}_{i,t=1}(1)) - (\\overline{Y}_{i,t=2}(0) - \\overline{Y}_{i,t=1}(0)) $$\n",
    "\n",
    "Vamos representar em termos de esperanças condicionais (assumindo uma amostragem de uma população grande):\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = (E[Y_{i,t=2}(1)|D_{i}=1] - E[Y_{i,t=1}(1)|D_{i}=1]) - (E[Y_{i,t=2}(0)|D_{i}=0] - E[Y_{i,t=1}(0)|D_{i}=0]) $$\n",
    "\n",
    "\n",
    "**Motivação para adicionar covariáveis**\n",
    "\n",
    "Para muitos pesquisadores, a hipótese de **Parallel Trends** não é plausível em muitos casos, mas poderia ser ao condicionarmos em algumas covariáveis. Por exemplo, se a variável de resultado de interesse são os salários, o grupo de tratamento e controle diferem em níveis de escolaridade, e as tendências para os níveis de educação que afetam os salários diferem entre os trabalhadores. Então, o condicionamento na covariável parece ser plausível.\n",
    "\n",
    "Nesse contexto as hipóteses de identificação são alteradas e ampliadas:\n",
    "\n",
    "* 1: Conditional Parallel Trends (porque condicionamos nas covariáveis)\n",
    "* 2: No anticipation\n",
    "* 3: Distribuição dos dados (Segue conforme anteriormente, considerando a estrutura de Panel-Data, ou repeated Cross-secion data, satisfazendo as tendências paralelas condicionais)\n",
    "* 4: Common Suport (Overlap) Ao menos uma fração da população que é tratada e para cada valor de X há ao menos uma chance de uma unidade ser não tratada.\n",
    "* 5: Efeito Homogêneo do Tratameto em X\n",
    "* 6: Não há tendências específicas em X em ambos os grupos tratado e controle\n",
    "\n",
    "Observação: Convem salientar que **a suposição de tendência paralela condicional não é nem mais forte nem mais fraca do que a tendência paralela incondicional.** A tendência paralela condicional não implica tendência paralela incondicional e a tendência paralela incondicional não implica tendência paralela condicional;\n",
    "\n",
    "Considerando $X_{i}$ um vetor de covariáveis que **Não varia no tempo**:\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = (E[Y_{i,t=2}|D_{i}=1, X_{i}] - E[Y_{i,t=1}|D_{i}=1, X_{i}]) - (E[Y_{i,t=2}|D_{i}=0, X_{i}] - E[Y_{i,t=1}|D_{i}=0, X_{i}]) $$\n",
    "\n",
    "\n",
    "Para identificar o efeito causal, os pesquisadores aplicados costumavam utilizar a especificação TWFE, apenas com a adição das covariáveis na regressão:\n",
    "\n",
    "$$ Y_{i,t} = \\alpha + \\beta_{1} T_{t} + \\beta_{2}D_{i} + \\delta (T_{t}.D_{i}) + \\gamma X_{i} + \\epsilon_{i,t} $$\n",
    "\n",
    "Ao adicionar as covariáveis na regressão significa que estamos **impondo uma estrutura paramétrica** para a relação entre as covariáveis e o resultado (é uma hipótese de estrutura paramétrica da relação). Essa regressão identifica o efeito causal se isso corresponde ao verdadeiro modelo que gera os resultados potenciais. O efeito do tratamento é **constante e aditivo**.\n",
    "\n",
    "Entretanto, **mesmo condicionando nas covariáveis, o modelo não permite que diferentes grupos tenham trajetórias diferentes ao longo do tempo. Ou seja, as trajetórias são as mesmas para todos os grupos.** Mas a razão pela qual se desejava incluir covariáveis no modelo era justamente para permitir que diferentes grupos tivessem trajetórias distintas ao longo do tempo. No entanto, a restrição do modelo impede que essa variação seja capturada, o que contradiz o objetivo original de incluir as covariáveis.\n",
    "\n",
    "Vamos tomar as expectativas condicionais do TWFE proposto (considerando os períodos 0 e 1):\n",
    "\n",
    "* Tratados (Post e Pre):\n",
    "$$E[Y_{1,1}|D_{i}=1] = \\alpha + \\beta_{1} + \\beta_{2} + \\delta + \\gamma X_{11}$$\n",
    "$$E[Y_{1,0}|D_{i}=1] = \\alpha + \\beta_{2} + \\gamma X_{10}$$\n",
    "* Controles (Post e Pre):\n",
    "$$E[Y_{0,1}|D_{i}=0] = \\alpha + \\beta_{1} + \\gamma X_{01}$$\n",
    "$$E[Y_{0,0}|D_{i}=0] = \\alpha + \\gamma X_{00}$$\n",
    "\n",
    "Tomando o DD:\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = ( (\\alpha + \\beta_{1} + \\beta_{2} + \\delta + \\gamma X_{11}) - (\\alpha + \\beta_{2} + \\gamma X_{10}) ) - ( (\\alpha + \\beta_{1} + \\gamma X_{01}) - (\\alpha + \\gamma X_{00}) ) $$\n",
    "\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = ( \\beta_{1} + \\delta + \\gamma X_{11} - \\gamma X_{10} ) - ( \\beta_{1} + \\gamma X_{01} - \\gamma X_{00} ) $$\n",
    "$$ \\hat{\\delta}_{ATT}^{2x2} = \\delta + ( \\gamma X_{11} - \\gamma X_{10} ) - ( \\gamma X_{01} - \\gamma X_{00} ) $$\n",
    "\n",
    "\n",
    "Repare que a segunda parte da igualdade requer que as tendências de cada X do grupo tratado seja igual a tendência das variáveis X do grupo de controle. (hipóteses 5 e 6). Por isso que, normalmente o TWFE com covariáveis não irá identificar o efeito causal ($\\delta$) corretamente.\n",
    "\n",
    "Vejamos como a literatura propõe a inclusão de covariáveis no modelo de DD com menos hipóteses restritivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimação do DD sob Hipótese de Tendências Paralelas Condicionais\n",
    "\n",
    "Funciona se ambas as **unidades tratadas e de controle tiverem aproximadamente a mesma distribuição de covariáveis ​​(sobreposição forte)** e se o **efeito do tratamento for homogêneo**.\n",
    "\n",
    "Em termos de estratégia de identificação, a literatura se desenvolveu apresentando as seguintes abordagens:\n",
    "* Outcome Regression DD (Regression Adjustment DD - Heckman et al. 1997, 1998)\n",
    "* Propensity score com DD (Abadie, 2005)\n",
    "* Doubly Robust DD (Sant'Anna e Zhao, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome Regression DD\n",
    "\n",
    "Uma forma de identificar o efeito causal através do método de Diferença em Diferenças e incorporar covariáveis se dá através do Outcome Regression. A ideia é realizar a diferença entre as médias dos resultados potenciais para o grupo tratado e controle, entretanto, **utilizar como ajuste do contrafactual a trajetória do grupo de controle com a distribuição de covariáveis do grupo tratado.**\n",
    "\n",
    "1. **Modelo de Regressão Linear:**\n",
    "\n",
    "   $$ Y_{i,t} = \\alpha + \\beta D_{i,t} + \\gamma X_{i} + \\epsilon_{i,t} $$\n",
    "\n",
    "   onde $ Y $ é a variável dependente, $ D $ é a variável indicadora de tratamento (1 se o tratamento foi aplicado, 0 caso contrário), $ X $ são as covariáveis constantes observáveis, e $ \\epsilon $ é o termo de erro.\n",
    "\n",
    "2. **Expectativas Condicionais:**\n",
    "   \n",
    "   Definimos os resultados da expectativa condicional (para o período 1 e 2):\n",
    "\n",
    "   $$ \\mu_{0,1}(X) = E[Y | X, D=0, t=1] $$\n",
    "   $$ \\mu_{0,2}(X) = E[Y | X, D=0, t=2] $$\n",
    "   \n",
    "   Então, $\\mu_{0,1}(X) $ e $ \\mu_{0,2}(X) $ **representam as médias dos resultados potenciais para os não tratados dado suas características observáveis $ X $**.\n",
    "\n",
    "3. **DD e as Expectativas Condicionais:**\n",
    "   \n",
    "   Retomando a equação do DD, temos:\n",
    "\n",
    "   $$ \\beta^{DD} = (E[Y|X, D=1, t=2] - E[Y|X, D=1, t=1]) - (E[Y|X, D=0, t=2] - E[Y|X, D=0, t=1]) $$\n",
    "\n",
    "4. **Substituição das Definições:**\n",
    "\n",
    "   A ideia dos autores é construir um contrafactual adequado, que considere a trajetória do grupo de controle com a distribuição de covariáveis do grupo tratado. Logo:\n",
    "\n",
    "   $$ \\beta^{OR-DD} = (E[Y|X, D=1, t=2] - E[Y|X, D=1, t=1]) - (\\mu_{02}(X) - \\mu_{01}(X) ) $$\n",
    "\n",
    "  Considerando que queremos construir o contrafactual considerando a trajetória do grupo de controle com a distribuição de covariáveis do grupo tratado ($X^{T}$), obtemos:\n",
    "\n",
    "   $$ \\hat{\\beta}_{ATT}^{OR-DD} = (E[Y|X, D=1, t=2] - E[Y|X, D=1, t=1]) - [\\mu_{1}(X^{T}) - \\mu_{0}(X^{T})]  $$\n",
    "\n",
    "   Simplificando a notação, com $ \\bar{Y}_{1,1} $ representando $ E[Y|X, D=1, t=1] $ e $ \\bar{Y}_{1,2} $ representando $ E[Y|X, D=1, t=2] $, temos:\n",
    "\n",
    "   $$ \\hat{\\beta}_{ATT}^{OR-DD} = (\\bar{Y}_{1,2} - \\bar{Y}_{1,1}) - [\\mu_{1}(X^{T}) - \\mu_{0}(X^{T})]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar o método de Outcome Regression DD em um exemplo prático em python. Com os dados de Card and Krueger (1994), vamos estimar o efeito do salário mínimo no emprego, só que com o OR-DD.\n",
    "\n",
    "Começamos carregando os pacotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "from differences import ATTgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"http://fmwww.bc.edu/repec/bocode/c/CardKrueger1994.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre que os dados não estão corretos, então precisamos corrigir o erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Há problemas na base que precisam ser ajustados\n",
    "df.loc[(df['id'] == 407) & (df['kfc'] == 1), 'id'] = 408\n",
    "# Crie a variável 'tratado' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'tratado' para 1 se 'treated' for igual a 1\n",
    "df.loc[df['treated'] == 'NJ', 'Treated'] = 1\n",
    "# Crie a variável 'effect' como o produto entre 'tratado' e 't'\n",
    "df['Effect'] = df['Treated'] * df['t']\n",
    "# Remover lojas sem informação em ambos os anos\n",
    "df['cont'] = df['fte'].notna().groupby(df['id']).cumsum()\n",
    "df['media'] = df.groupby('id')['cont'].transform('mean')\n",
    "df = df[df['media'] == 1.5]\n",
    "df['y'] = df['fte']\n",
    "\n",
    "df['pre'] = 0\n",
    "df.loc[df['t'] == 0, 'pre'] = 1\n",
    "df['pos'] = 0\n",
    "df.loc[df['t'] == 1, 'pos'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando a base em csv para usar no exemplo em R que realizaremos no final dessa aula.\n",
    "# df.to_csv('card_krueger.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DD Canônico\n",
    "\n",
    "Vamos começar com o DD canônico, sem covariáveis, para entender o efeito do salário mínimo no emprego. Para ter um valor de referência para o efeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     2.195\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):             0.0873\n",
      "Time:                        19:58:45   Log-Likelihood:                -2831.8\n",
      "No. Observations:                 782   AIC:                             5672.\n",
      "Df Residuals:                     778   BIC:                             5690.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     20.0132      1.040     19.238      0.000      17.971      22.055\n",
      "Treated       -2.9663      1.159     -2.559      0.011      -5.242      -0.691\n",
      "t             -2.4901      1.471     -1.693      0.091      -5.378       0.398\n",
      "Effect         2.9425      1.639      1.795      0.073      -0.275       6.160\n",
      "==============================================================================\n",
      "Omnibus:                      240.424   Durbin-Watson:                   1.389\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              952.495\n",
      "Skew:                           1.395   Prob(JB):                    1.47e-207\n",
      "Kurtosis:                       7.631   Cond. No.                         11.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# regressão DD canônico sem covariáveis:\n",
    "DD1 = smf.ols('y ~ Treated + t + Effect', data=df).fit()\n",
    "print(DD1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DD Canônico com Covariáveis\n",
    "\n",
    "Vamos adicionar covariáveis constantes no tempo e verificar se o efeito do salário mínimo no emprego se mantém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.190\n",
      "Model:                            OLS   Adj. R-squared:                  0.184\n",
      "Method:                 Least Squares   F-statistic:                     30.26\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):           1.06e-32\n",
      "Time:                        19:58:47   Log-Likelihood:                -2752.8\n",
      "No. Observations:                 782   AIC:                             5520.\n",
      "Df Residuals:                     775   BIC:                             5552.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     21.2079      1.181     17.950      0.000      18.889      23.527\n",
      "Treated       -2.3752      1.051     -2.259      0.024      -4.439      -0.312\n",
      "t             -2.4901      1.332     -1.869      0.062      -5.106       0.125\n",
      "Effect         2.9425      1.485      1.982      0.048       0.028       5.857\n",
      "bk             1.0109      0.919      1.100      0.272      -0.793       2.815\n",
      "kfc           -9.1680      1.031     -8.892      0.000     -11.192      -7.144\n",
      "roys          -0.8918      0.997     -0.894      0.371      -2.849       1.065\n",
      "==============================================================================\n",
      "Omnibus:                      298.310   Durbin-Watson:                   1.556\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1795.640\n",
      "Skew:                           1.606   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.693   Cond. No.                         12.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# regressão DD canônico com covariáveis:\n",
    "DD2 = smf.ols('y ~ Treated + t + Effect + bk + kfc + roys', data=df).fit()\n",
    "print(DD2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre que sob a hipótese de tendências paralelas condicionais, o estimador de DD apenas adicionando as covariáveis pode apresentar viés se as tendências não forem paralelas nas prórias covariáveis. \n",
    "\n",
    "Os resultados foram de $2.9425$ em ambos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome Regression DD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos realizar o OR-DD \"na mão\" para verificar a magnitude do efeito a ser estimado, e entender o mecânismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Regression DD (ATT): 2.6757034544143536\n"
     ]
    }
   ],
   "source": [
    "def OR_DD(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time):\n",
    "    # Separar dados por grupo e período\n",
    "    df_pre = df[df[Time_col] == pre_time]\n",
    "    df_post = df[df[Time_col] == post_time]\n",
    "\n",
    "    X_pre_treated = df_pre[df_pre[T_col] == 1][X_cols]\n",
    "    Y_pre_treated = df_pre[df_pre[T_col] == 1][Y_col]\n",
    "    X_post_treated = df_post[df_post[T_col] == 1][X_cols]\n",
    "    Y_post_treated = df_post[df_post[T_col] == 1][Y_col]\n",
    "\n",
    "    X_pre_control = df_pre[df_pre[T_col] == 0][X_cols]\n",
    "    Y_pre_control = df_pre[df_pre[T_col] == 0][Y_col]\n",
    "    X_post_control = df_post[df_post[T_col] == 0][X_cols]\n",
    "    Y_post_control = df_post[df_post[T_col] == 0][Y_col]\n",
    "\n",
    "    # Ajustar modelos de regressão linear para os períodos pré e pós\n",
    "    model_pre_control = LinearRegression().fit(X_pre_control, Y_pre_control)\n",
    "    model_post_control = LinearRegression().fit(X_post_control, Y_post_control)\n",
    "\n",
    "    # Previsões para o grupo controle nos períodos pré e pós\n",
    "    mu0_X_pre = model_pre_control.predict(X_pre_treated)\n",
    "    mu0_X_post = model_post_control.predict(X_post_treated)\n",
    "\n",
    "    # Calcular a Diferença em Diferenças\n",
    "    ORdid = (Y_post_treated.mean() - Y_pre_treated.mean()) - (mu0_X_post.mean() - mu0_X_pre.mean()) \n",
    "\n",
    "    return ORdid\n",
    "\n",
    "# Exemplo de uso\n",
    "T_col = 'Treated'\n",
    "Y_col = 'y'\n",
    "X_cols = ['bk', 'kfc', 'roys']\n",
    "Time_col = 't'\n",
    "pre_time = 0\n",
    "post_time = 1\n",
    "\n",
    "result_OR_DiD = OR_DD(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time)\n",
    "print(\"Outcome Regression DD (ATT):\", result_OR_DiD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que o resultado é distinto do valor canônico. Fazendo manualmente, encontramos um efeito de $2.6757$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos aplicar o pacote `differences` do Python. Nesse pacote conseguimos estimar o OR-DD de forma mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"http://fmwww.bc.edu/repec/bocode/c/CardKrueger1994.dta\")\n",
    "# Há problemas na base que precisam ser ajustados\n",
    "df.loc[(df['id'] == 407) & (df['kfc'] == 1), 'id'] = 408\n",
    "# Crie a variável 'tratado' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'tratado' para 1 se 'treated' for igual a 1\n",
    "df.loc[df['treated'] == 'NJ', 'Treated'] = 1\n",
    "# Crie a variável 'effect' como o produto entre 'tratado' e 't'\n",
    "df['Effect'] = df['Treated'] * df['t']\n",
    "# Remover lojas sem informação em ambos os anos\n",
    "df['cont'] = df['fte'].notna().groupby(df['id']).cumsum()\n",
    "df['media'] = df.groupby('id')['cont'].transform('mean')\n",
    "df = df[df['media'] == 1.5]\n",
    "df['Y'] = df['fte']\n",
    "\n",
    "df['pre'] = 0\n",
    "df.loc[df['t'] == 0, 'pre'] = 1\n",
    "df['pos'] = 0\n",
    "df.loc[df['t'] == 1, 'pos'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rodar o pacote precisamos definir o Grupo de tratamento, isto é, precisamos criar uma variável nova \"Group\" que identifica o grupo tratado e controle. Em outras palavras, o grupo de tratamento é definido como o ano (período) em que ocorreu o início do tratamento para as unidades tratadas. Como em nossa base de dados todos os tratados iniciaram o tratamento quando time é 1, então definimos Group=1 para os tratados e Group com NaN para os controles (NaN é um valor nulo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Group'] = df['Treated']\n",
    "df.loc[df['Treated'] == 0, 'Group'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro ponto importante para rodar esse pacote, temos que identificar a estrutura de painel de dados para o python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar duas variáveis de identificação de individuos e tempo para indicar a estrutura de painel.\n",
    "df['id1'] = df['id']\n",
    "df['t1'] = df['t'].astype(int)\n",
    "\n",
    "# Definir os indices (estrutura de painel)\n",
    "df.set_index(['id1', 't1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_gt = ATTgt(data=df, cohort_name=\"Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao entrar no \"help(Attgt)\", vemos que o pacote possui diversas opções de estimação, como o OR-DD, IPW-DD, e DR-DD.\n",
    "\n",
    "est_method: *str*, default: ``\"dr-mle\"``\n",
    " |      \n",
    " |          - ``\"dr-mle\"`` or ``\"dr\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated\n",
    " |      \n",
    " |          - ``\"dr-ipt\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with propensity score estimated using the inverse probability tilting\n",
    " |      \n",
    " |          - ``\"reg\"``\n",
    " |              for outcome regression DiD estimator\n",
    " |      \n",
    " |          - ``\"std_ipw-mle\"`` or ``\"std_ipw\"``\n",
    " |              for standardized inverse probability weighted DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated\n",
    "\n",
    "\n",
    " Vamos rodar o pacote para estimar o OR-DD, então precisamos definir o método de estimação como \"reg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 199.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">ATTgtResult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>base_period</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>2.675703</td>\n",
       "      <td>1.217264</td>\n",
       "      <td>0.289911</td>\n",
       "      <td>5.061496</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ATTgtResult                                           \\\n",
       "                                     analytic pointwise conf. band             \n",
       "                                ATT std_error                lower     upper   \n",
       "cohort base_period time                                                        \n",
       "1      0           1       2.675703  1.217264             0.289911  5.061496   \n",
       "\n",
       "                                           \n",
       "                                           \n",
       "                        zero_not_in_cband  \n",
       "cohort base_period time                    \n",
       "1      0           1                    *  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos salvar os resultados dentro em uma variável \"results\". E calcular suas estatísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 125.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa do ATT: 2.6757032727620924\n",
      "Estatística de Teste (t): 2.198129841848015\n",
      "Valor-p: 0.027939854480739434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"reg\")\n",
    "\n",
    "# Acessar o coeficiente e o erro padrão\n",
    "coef = results[('ATTgtResult', '', 'ATT')].iloc[0]\n",
    "std_error = results[('ATTgtResult', 'analytic', 'std_error')].iloc[0]\n",
    "\n",
    "# Calcular a estatística de teste\n",
    "t_stat = coef / std_error\n",
    "\n",
    "# Calcular o valor-p (para um teste bilateral)\n",
    "import scipy.stats as stats\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
    "\n",
    "print(f\"Estimativa do ATT: {coef}\")\n",
    "print(f\"Estatística de Teste (t): {t_stat}\")\n",
    "print(f\"Valor-p: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  IPW Difference in Difference Approach - Abadie (2005) \n",
    "\n",
    "A abordagem proposta por Abadie (2005) é um estimador de diferenças em diferenças Semiparametrico. A abordagem de Abadie (2005) utiliza técnicas de *matching* para criar grupos de comparação potencialmente mais adequados, onde unidades de tratamento e controle são pareadas com base em características observáveis. Isso ajuda a reduzir o viés de seleção por características observáveis e aumenta a validade causal da estimativa.\n",
    "\n",
    "\n",
    "$$ \\delta^{IPW} = \\frac{1}{E_{N}[D]}E\\left [\\frac{D-\\hat{p}(X)}{1-\\hat{p}(X)}(Y_{1}-Y_{0})\\right ]  $$\n",
    "\n",
    "\n",
    "Onde $\\hat{p}(X)$  é um estimador para o verdadeiro escore de propensão (probabilidade do indivíduo ser tratado baseado nas características observáveis). O qual reduz a dimensão de X em um escalar.\n",
    "\n",
    "* $E_{N}[D]$ é a proporção média de unidades que receberam o tratamento na amostra\n",
    "* $Y_{1}$ e $Y_{0}$ são as médias das variáveis de resultado dos tratados e não tratados **no período de tratamento**\n",
    "\n",
    "Pode ser reescrito como:\n",
    "\n",
    "$$ \\delta^{IPW-DD} = \\frac{1}{E_{N}[D]} E\\left [(\\bar{Y}_{1,2} - \\bar{Y}_{1,1}) - \\frac{(1-D)\\hat{p}(X)}{1-\\hat{p}(X)}(\\bar{Y}_{0,2} - \\bar{Y}_{0,1}) \\right ]  $$\n",
    "\n",
    "A ideia da ponderação é atribuir mais peso para as observações nos grupos de controle que \"parecem\" mais com as unidades tratadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aplicar essa abordagem em nosso exemplo prático. Aqui vou mostrar como fazer manualmente porque pode ser importante tanto para vocês entenderem o mecanismo, quanto para utilizarem em estratégias de pesquisa futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.489622\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Treated   No. Observations:                  782\n",
      "Model:                          Logit   Df Residuals:                      778\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 20 Nov 2024   Pseudo R-squ.:                0.005849\n",
      "Time:                        19:59:15   Log-Likelihood:                -382.88\n",
      "converged:                       True   LL-Null:                       -385.14\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2118\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1239      0.226      4.979      0.000       0.681       1.566\n",
      "bk             0.2095      0.264      0.795      0.427      -0.307       0.726\n",
      "kfc            0.6107      0.316      1.931      0.053      -0.009       1.230\n",
      "roys           0.3996      0.295      1.356      0.175      -0.178       0.977\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Propensity Score Weighting\n",
    "D = df['Treated']\n",
    "X = df[['bk', 'kfc', 'roys']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "reg_logit = sm.Logit(D, X).fit()\n",
    "df['peso_logit'] = reg_logit.predict()\n",
    "\n",
    "print(reg_logit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a medida de média dos tratados 'ED'\n",
    "df['ED'] = df['Treated'].mean()\n",
    "ED = df['ED'].mean()\n",
    "\n",
    "# Criando os pesos e adicionando ao DataFrame\n",
    "df['W_ATT'] = (df['peso_logit'] / (1 - df['peso_logit']))/ED\n",
    "df.loc[df['Treated'] == 1, 'W_ATT'] = 1/ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.008\n",
      "Model:                            WLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     2.143\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):             0.0934\n",
      "Time:                        19:59:23   Log-Likelihood:                -2942.2\n",
      "No. Observations:                 782   AIC:                             5892.\n",
      "Df Residuals:                     778   BIC:                             5911.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         18.9768      0.674     28.135      0.000      17.653      20.301\n",
      "Treated       -1.9299      0.954     -2.023      0.043      -3.802      -0.057\n",
      "t             -2.2233      0.954     -2.331      0.020      -4.096      -0.351\n",
      "Effect         2.6757      1.349      1.984      0.048       0.028       5.324\n",
      "==============================================================================\n",
      "Omnibus:                      327.394   Durbin-Watson:                   1.373\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2743.448\n",
      "Skew:                           1.672   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.545   Cond. No.                         6.85\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Aplicando regressão ponderada\n",
    "Y1 = df[['Y']]  # Selecionando a variável dependente\n",
    "X1 = df[['Treated', 't', 'Effect']]  # Selecionando as variáveis independentes\n",
    "X1 = sm.add_constant(X1)  # Adicionando uma constante (intercepto)\n",
    "\n",
    "# Ajustando o modelo de regressão ponderada\n",
    "dd_ipw = sm.WLS(Y1, X1, weights=df['W_ATT']).fit()\n",
    "\n",
    "# Imprimindo o resumo\n",
    "print(dd_ipw.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado para o DD-IPW foi de $2.6757$. O mesmo econtrado anteriormente pelo OR-DD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubly Robust DD (DRDID)\n",
    "\n",
    "O modelo Doubly Robust Difference in Differences (DRDID) de Sant'Anna e Zhao (2020) é uma extensão do método de diferenças em diferenças (DD). Ele usa **uma abordagem duplamente robusta**, que combina os dois modelos vistos anteriormente: um modelo de Outcome Regression e um modelo de probabilidade de receber o tratamento para o caso de diferença em diferenças.\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\SantannaZhao.png\"  alt=\"Imagem\" style=\"width: 700px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "O modelo DRDID combina esses dois modelos para produzir estimativas do efeito causal que são consistentes mesmo que um dos modelos seja mal especificado. Essa abordagem pode melhorar a precisão da estimativa do efeito causal em comparação com o método DID padrão, especialmente quando há variáveis de controle que afetam tanto a probabilidade de tratamento quanto o resultado de interesse.\n",
    "\n",
    "$$  \\beta^{DRDID}= E\\left[ \\left ( \\frac{D}{E[D]} - \\frac{\\frac{p(X)(1-D)}{(1-p(X))}}{E[\\frac{p(X)(1-D)}{(1-p(X))}]} \\right ) (\\Delta Y - \\mu_{0,\\Delta (X)} )   \\right ]  $$\n",
    "\n",
    "Podemos reescrever a equação acima como:\n",
    "\n",
    "$$ \\beta^{DRDID}= E\\left[ \\frac{D}{E[D]}(\\bar{Y}_{1,2} - \\bar{Y}_{1,1}) - \\frac{\\frac{p(X)(1-D)}{(1-p(X))}}{E[\\frac{p(X)(1-D)}{(1-p(X))}]} (\\mu_{1}(X^{T}) - \\mu_{0}(X^{T})) \\right ]  $$\n",
    "\n",
    "\n",
    "Observe como o modelo controla para $X$ você está ponderando o ajuste resultados usando o escore de propensão. \n",
    "\n",
    "A razão pela qual você controla $X$ duas vezes é porque você não sabe qual modelo está certo. DRDiD libera você de fazer uma escolha sem fazer você pagar muito por isso.\n",
    "\n",
    "Novamente, podemos fazer manualmente para entender o mecanismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplamente Robusto DiD (ATT): 2.6757034544143536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "def DD_DR(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time):\n",
    "    # Separar dados por grupo e período\n",
    "    df_pre = df[df[Time_col] == pre_time]\n",
    "    df_post = df[df[Time_col] == post_time]\n",
    "\n",
    "    X_pre_treated = df_pre[df_pre[T_col] == 1][X_cols]\n",
    "    Y_pre_treated = df_pre[df_pre[T_col] == 1][Y_col]\n",
    "    X_post_treated = df_post[df_post[T_col] == 1][X_cols]\n",
    "    Y_post_treated = df_post[df_post[T_col] == 1][Y_col]\n",
    "\n",
    "    X_pre_control = df_pre[df_pre[T_col] == 0][X_cols]\n",
    "    Y_pre_control = df_pre[df_pre[T_col] == 0][Y_col]\n",
    "    X_post_control = df_post[df_post[T_col] == 0][X_cols]\n",
    "    Y_post_control = df_post[df_post[T_col] == 0][Y_col]\n",
    "    \n",
    "    # Ajustar modelos de regressão linear para os períodos pré e pós\n",
    "    model_pre_control = LinearRegression().fit(X_pre_control, Y_pre_control)\n",
    "    model_post_control = LinearRegression().fit(X_post_control, Y_post_control)\n",
    "\n",
    "    # Previsões para o grupo controle nos períodos pré e pós\n",
    "    mu0_X_pre = model_pre_control.predict(X_pre_treated)\n",
    "    mu0_X_post = model_post_control.predict(X_post_treated)\n",
    "    \n",
    "    X_pre = df_pre[X_cols]\n",
    "    Y_pre = df_pre[Y_col]\n",
    "    T_pre = df_pre[T_col]\n",
    "        \n",
    "    # Estimativa da probabilidade de tratamento p(X) no período pré\n",
    "    model_logistic = LogisticRegression(solver='liblinear').fit(X_pre, T_pre)\n",
    "    p_X_pre = model_logistic.predict_proba(X_pre)[:, 1]\n",
    "    \n",
    "    # Criar os pesos para o período pré\n",
    "    weight_treated_pre = T_pre / T_pre.mean()\n",
    "    weight_control_pre = ((1 - p_X_pre) / p_X_pre) / ((1 - p_X_pre) / p_X_pre).mean()\n",
    "    \n",
    "    # Calcular a Diferença em Diferenças com os pesos\n",
    "    term_treated = (Y_post_treated.mean() - Y_pre_treated.mean()) * weight_treated_pre.mean()\n",
    "    term_control = (mu0_X_post.mean() - mu0_X_pre.mean()) * weight_control_pre.mean()\n",
    "\n",
    "    DR_DiD = term_treated - term_control \n",
    "\n",
    "    return DR_DiD\n",
    "\n",
    "# Exemplo de uso\n",
    "T_col = 'Treated'\n",
    "Y_col = 'Y'\n",
    "X_cols = ['bk', 'kfc', 'roys']\n",
    "Time_col = 't'\n",
    "pre_time = 0\n",
    "post_time = 1\n",
    "\n",
    "\n",
    "result_DD_DR = DD_DR(df, X_cols, T_col, Y_col, Time_col, pre_time, post_time)\n",
    "print(\"Duplamente Robusto DiD (ATT):\", result_DD_DR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação Dobly Robust Difference in Differences (DRDID) - Sant'Anna e Zhao (2020) em Python\n",
    "\n",
    "Vamos aplicar o DRDD com pacote `differences`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacotes\n",
    "import pandas as pd\n",
    "from differences import ATTgt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.read_stata(\"http://fmwww.bc.edu/repec/bocode/c/CardKrueger1994.dta\")\n",
    "# Há problemas na base que precisam ser ajustados\n",
    "df.loc[(df['id'] == 407) & (df['kfc'] == 1), 'id'] = 408\n",
    "# Crie a variável 'tratado' com valor inicial de 0\n",
    "df['Treated'] = 0\n",
    "# Recodifique 'tratado' para 1 se 'treated' for igual a 1\n",
    "df.loc[df['treated'] == 'NJ', 'Treated'] = 1\n",
    "# Crie a variável 'effect' como o produto entre 'tratado' e 't'\n",
    "df['Effect'] = df['Treated'] * df['t']\n",
    "# Remover lojas sem informação em ambos os anos\n",
    "df['cont'] = df['fte'].notna().groupby(df['id']).cumsum()\n",
    "df['media'] = df.groupby('id')['cont'].transform('mean')\n",
    "df = df[df['media'] == 1.5]\n",
    "df['Y'] = df['fte']\n",
    "\n",
    "df['pre'] = 0\n",
    "df.loc[df['t'] == 0, 'pre'] = 1\n",
    "df['pos'] = 0\n",
    "df.loc[df['t'] == 1, 'pos'] = 1\n",
    "\n",
    "df['Group'] = df['Treated']\n",
    "df.loc[df['Treated'] == 0, 'Group'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os indices (estrutura de painel)\n",
    "df.set_index(['id', 't'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_gt = ATTgt(data=df, cohort_name=\"Group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "est_method: *str*, default: ``\"dr-mle\"``\n",
    " |      \n",
    " |          - ``\"dr-mle\"`` or ``\"dr\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated\n",
    " |      \n",
    " |          - ``\"dr-ipt\"``\n",
    " |              for locally efficient doubly robust DiD estimator,\n",
    " |              with propensity score estimated using the inverse probability tilting\n",
    " |      \n",
    " |          - ``\"reg\"``\n",
    " |              for outcome regression DiD estimator\n",
    " |      \n",
    " |          - ``\"std_ipw-mle\"`` or ``\"std_ipw\"``\n",
    " |              for standardized inverse probability weighted DiD estimator,\n",
    " |              with logistic propensity score model for the probability of being treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 90.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">ATTgtResult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>analytic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pointwise conf. band</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ATT</th>\n",
       "      <th>std_error</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>zero_not_in_cband</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohort</th>\n",
       "      <th>base_period</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>2.675703</td>\n",
       "      <td>1.217264</td>\n",
       "      <td>0.289911</td>\n",
       "      <td>5.061496</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ATTgtResult                                           \\\n",
       "                                     analytic pointwise conf. band             \n",
       "                                ATT std_error                lower     upper   \n",
       "cohort base_period time                                                        \n",
       "1      0           1       2.675703  1.217264             0.289911  5.061496   \n",
       "\n",
       "                                           \n",
       "                                           \n",
       "                        zero_not_in_cband  \n",
       "cohort base_period time                    \n",
       "1      0           1                    *  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"dr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing ATTgt [workers=1]   100%|████████████████████| 1/1 [00:00<00:00, 125.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa do ATT: 2.6757032727620964\n",
      "Estatística de Teste (t): 2.198129841848017\n",
      "Valor-p: 0.027939854480739212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = att_gt.fit(\"Y ~ bk + kfc + roys\", est_method=\"dr\")\n",
    "\n",
    "# Acessar o coeficiente e o erro padrão\n",
    "coef = results2[('ATTgtResult', '', 'ATT')].iloc[0]\n",
    "std_error = results2[('ATTgtResult', 'analytic', 'std_error')].iloc[0]\n",
    "\n",
    "# Calcular a estatística de teste\n",
    "t_stat = coef / std_error\n",
    "\n",
    "# Calcular o valor-p (para um teste bilateral)\n",
    "import scipy.stats as stats\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(t_stat)))\n",
    "\n",
    "print(f\"Estimativa do ATT: {coef}\")\n",
    "print(f\"Estatística de Teste (t): {t_stat}\")\n",
    "print(f\"Valor-p: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do DRDID de Sant'Anna e Zhao (2020) no R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível utilizar também o Sant’Anna and Zhao (2020) doubly robust DiD estimator based on stabilized inverse probability weighting and ordinary least squares [dripw].\n",
    "\n",
    "Para isso precisamos recalcular o peso e utilizar as métricas estabilizadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos utilizar o pacote do R e calcular diretamente o DRDID\n",
    "\n",
    "Lembre-se de alterar o kernell de Python para R.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using GitHub PAT from the git credential store.\n",
      "\n",
      "Skipping install of 'DRDID' from a github remote, the SHA1 (8a1c09f9) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"remotes\")\n",
    "remotes::install_github(\"pedrohcgs/DRDID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "library(DRDID)\n",
    "data <- read.csv(\"https://github.com/Daniel-Uhr/data/raw/main/card_krueger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Call:\n",
      "drdid(yname = \"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", \n",
      "    xformla = ~bk + kfc + roys, data = data, panel = TRUE)\n",
      "------------------------------------------------------------------\n",
      " Further improved locally efficient DR DID estimator for the ATT:\n",
      " \n",
      "   ATT     Std. Error  t value    Pr(>|t|)  [95% Conf. Interval] \n",
      "  2.6757     1.2188     2.1953     0.0281     0.2868     5.0646  \n",
      "------------------------------------------------------------------\n",
      " Estimator based on panel data.\n",
      " Outcome regression est. method: weighted least squares.\n",
      " Propensity score est. method: inverse prob. tilting.\n",
      " Analytical standard error.\n",
      "------------------------------------------------------------------\n",
      " See Sant'Anna and Zhao (2020) for details."
     ]
    }
   ],
   "source": [
    "# Implement improved locally efficient DR DID:\n",
    "out <- drdid(yname = \"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", xformla= ~ bk + kfc + roys, data = data, panel = TRUE)\n",
    "summary(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Call:\n",
      "ordid(yname = \"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", \n",
      "    xformla = ~bk + kfc + roys, data = data, panel = TRUE)\n",
      "------------------------------------------------------------------\n",
      " Outcome-Regression DID estimator for the ATT:\n",
      " \n",
      "   ATT     Std. Error  t value    Pr(>|t|)  [95% Conf. Interval] \n",
      "  2.6757     1.2188     2.1953     0.0281     0.2868     5.0646  \n",
      "------------------------------------------------------------------\n",
      " Estimator based on panel data.\n",
      " Outcome regression est. method: OLS.\n",
      " Analytical standard error.\n",
      "------------------------------------------------------------------\n",
      " See Sant'Anna and Zhao (2020) for details."
     ]
    }
   ],
   "source": [
    "library(DRDID)\n",
    "data <- read.csv(\"https://github.com/Daniel-Uhr/data/raw/main/card_krueger.csv\")\n",
    "out2 <- ordid(yname=\"y\", tname = \"t\", idname = \"id\", dname = \"Treated\", xformla= ~ bk + kfc + roys, data = data, panel = TRUE)\n",
    "summary(out2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
